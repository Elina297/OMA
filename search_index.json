[["index.html", "Orchestrating Microbiome Analysis Welcome", " Orchestrating Microbiome Analysis Authors: Leo Lahti [aut], Tuomas Borman [aut, cre], Henrik Eckermann [ctb], Sudarshan Shetty [aut], Felix GM Ernst [aut] Version: 0.98.14 Modified: 2023-04-10 Compiled: 2023-04-11 Environment: R version 4.2.1 (2022-06-23), Bioconductor 3.15 License: CC BY-NC-SA 3.0 US Copyright: Source: https://github.com/microbiome/OMA Welcome You are reading the online book, Orchestrating Microbiome Analysis with R and Bioconductor (Leo Lahti et al. 2021), where we walk through common strategies and workflows in microbiome data science. The book shows through concrete examples how you can take advantage of the latest developments in R/Bioconductor for the manipulation, analysis, and reproducible reporting of hierarchical and heterogeneous microbiome profiling data sets. The book was borne out of necessity, while updating microbiome analysis tools to work with Bioconductor classes that provide support for multi-modal data collections. Many of these techniques are generic and widely applicable in other contexts as well. This work has been heavily influenced by other similar resources, in particular the Orchestrating Single-Cell Analysis with Bioconductor (R. Amezquita et al. 2020), phyloseq tutorials (Ben J. Callahan et al. 2016) and microbiome tutorials (Shetty and Lahti 2019). This book extends these resources to teach the grammar of Bioconductor workflows in the context of microbiome data science. As such, it supports the adoption of general skills in the analysis of large, hierarchical, and multi-modal data collections. We focus on microbiome analysis tools, including entirely new, partially updated as well as previously established methods. This online resource and its associated ecosystem of microbiome data science tools are a result of a community-driven development process, and welcoming new contributors. Several individuals have contributed methods, workflows and improvements as acknowledged in the Introduction. You can find more information on how to find us online and join the developer community through the project homepage at microbiome.github.io. This online resource has been written in RMarkdown with the bookdown R package. The material is free to use with the Creative Commons Attribution-NonCommercial 3.0 License. Bibliography "],["intro.html", "Chapter 1 Introduction", " Chapter 1 Introduction .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } This work - Orchestrating Microbiome Analysis with R and Bioconductor (Leo Lahti et al. 2021) - contributes novel methods and educational resources for microbiome data science. It aims to teach the grammar of Bioconductor workflows in the context of microbiome data science. We show through concrete examples how to use the latest developments and data analytical strategies in R/Bioconductor for the manipulation, analysis, and reproducible reporting of hierarchical, heterogeneous, and multi-modal microbiome profiling data. The data science methodology is tightly integrated with the broader R/Bioconductor ecosystem that focuses on the development of high-quality open research software for life sciences (R. C. Gentleman et al. (2004), Huber et al. (2015)). The support for modularity and interoperability is a key to efficient resource sharing and collaborative development both within and across research fields. The central data infrastructure, the SummarizedExperiment data container and its derivatives, have already been widely adopted in microbiome research, single cell sequencing, and in other fields, allowing a rapid adoption and extensions of emerging data science techniques across application domains. We assume that the reader is already familiar with R programming. For references and tips on introductory material for R and Bioconductor, see Chapter 16. This online resource and its associated ecosystem of microbiome data science tools are a result of a community-driven development process, and welcoming new users and contributors. You can find more information on how to find us online and join the developer community through the project homepage at microbiome.github.io. The book is organized into three parts. We start by introducing the material and link to further resources for learning R and Bioconductor. We describe the key data infrastructure, the TreeSummarizedExperiment class that provides a container for microbiome data, and how to get started by loading microbiome data set in the context of this new framework. The second section, Focus Topics, covers the common steps in microbiome data analysis, beginning with the most common steps and progressing to more specialized methods in subsequent sections. Third, Workflows, provides case studies for the various datasets used throughout the book. Finally, Appendix, links to further resources and acknowledgments. Bibliography "],["containers.html", "Chapter 2 Microbiome Data 2.1 Data science framework 2.2 Data containers 2.3 Loading experimental microbiome data 2.4 Demonstration data Session Info", " Chapter 2 Microbiome Data .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 2.1 Data science framework The building blocks of the framework are data container (SummarizedExperiment and its derivatives), packages from various developers using the TreeSE container, open demonstration data sets, in a separate chapter 2.4, and online tutorials including this online book as well as the various package vignettes and other material. 2.2 Data containers SummarizedExperiment (SE) (Morgan et al. 2020) is a generic and highly optimized container for complex data structures. It has become a common choice for analysing various types of biomedical profiling data, such as RNAseq, ChIp-Seq, microarrays, flow cytometry, proteomics, and single-cell sequencing. [TreeSummarizedExperiment] (TreeSE) (Huang 2020) was developed as an extension to incorporate hierarchical information (such as phylogenetic trees and sample hierarchies) and reference sequences. [MultiAssayExperiment] (MAE) (Ramos et al. 2017) provides an organized way to bind several different data structures together in a single object. For example, we can bind microbiome data (in TreeSE format) with metabolomic profiling data (in SE) format, with shared sample metadata. This is convenient and robust for instance in subsetting and other data manipulation tasks. Microbiome data can be part of multiomics experiments and analysis strategies and we want to outline the understanding in which we think the packages explained and used in this book relate to these experiment layouts using the TreeSummarizedExperiment and classes beyond. This section provides an introductions to these data containers. In microbiome data science, these containers link taxonomic abundance tables with rich side information on the features and samples. Taxonomic abundance data can be obtained by 16S rRNA amplicon or metagenomic sequencing, phylogenetic microarrays, or by other means. Many microbiome experiments include multiple versions and types of data generated independently or derived from each other through transformation or agglomeration. We start by providing recommendations on how to represent different varieties of multi-table data within the TreeSummarizedExperiment class. The options and recommendations are summarized in Table 2.1. 2.2.1 Assay data The original count-based taxonomic abundance tables may have different transformations, such as logarithmic, Centered Log-Ratio (CLR), or relative abundance. These are typically stored in assays. library(mia) data(GlobalPatterns, package=&quot;mia&quot;) tse &lt;- GlobalPatterns assays(tse) ## List of length 1 ## names(1): counts The assays slot contains the experimental data as count matrices. Multiple matrices can be stored the result of assays is actually a list of matrices. assays(tse) ## List of length 1 ## names(1): counts Individual assays can be accessed via assay assay(tse, &quot;counts&quot;)[1:5,1:7] ## CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr ## 549322 0 0 0 0 0 0 0 ## 522457 0 0 0 0 0 0 0 ## 951 0 0 0 0 0 0 1 ## 244423 0 0 0 0 0 0 0 ## 586076 0 0 0 0 0 0 0 To illustrate the use of multiple assays, the relative abundance data can be calcualted and stored along the original count data using relAbundanceCounts. tse &lt;- relAbundanceCounts(tse) assays(tse) ## List of length 2 ## names(2): counts relabundance Now there are two assays available in the tse object, counts and relabundance. assay(tse, &quot;relabundance&quot;)[1:5,1:7] ## CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr ## 549322 0 0 0 0 0 0 0.000e+00 ## 522457 0 0 0 0 0 0 0.000e+00 ## 951 0 0 0 0 0 0 2.305e-06 ## 244423 0 0 0 0 0 0 0.000e+00 ## 586076 0 0 0 0 0 0 0.000e+00 Here the dimension of the count data remains unchanged. This is in fact a requirement for any SummarizedExperiment object. 2.2.2 colData colData contains data on the samples. colData(tse) ## DataFrame with 26 rows and 7 columns ## X.SampleID Primer Final_Barcode Barcode_truncated_plus_T ## &lt;factor&gt; &lt;factor&gt; &lt;factor&gt; &lt;factor&gt; ## CL3 CL3 ILBC_01 AACGCA TGCGTT ## CC1 CC1 ILBC_02 AACTCG CGAGTT ## SV1 SV1 ILBC_03 AACTGT ACAGTT ## M31Fcsw M31Fcsw ILBC_04 AAGAGA TCTCTT ## M11Fcsw M11Fcsw ILBC_05 AAGCTG CAGCTT ## ... ... ... ... ... ## TS28 TS28 ILBC_25 ACCAGA TCTGGT ## TS29 TS29 ILBC_26 ACCAGC GCTGGT ## Even1 Even1 ILBC_27 ACCGCA TGCGGT ## Even2 Even2 ILBC_28 ACCTCG CGAGGT ## Even3 Even3 ILBC_29 ACCTGT ACAGGT ## Barcode_full_length SampleType ## &lt;factor&gt; &lt;factor&gt; ## CL3 CTAGCGTGCGT Soil ## CC1 CATCGACGAGT Soil ## SV1 GTACGCACAGT Soil ## M31Fcsw TCGACATCTCT Feces ## M11Fcsw CGACTGCAGCT Feces ## ... ... ... ## TS28 GCATCGTCTGG Feces ## TS29 CTAGTCGCTGG Feces ## Even1 TGACTCTGCGG Mock ## Even2 TCTGATCGAGG Mock ## Even3 AGAGAGACAGG Mock ## Description ## &lt;factor&gt; ## CL3 Calhoun South Carolina Pine soil, pH 4.9 ## CC1 Cedar Creek Minnesota, grassland, pH 6.1 ## SV1 Sevilleta new Mexico, desert scrub, pH 8.3 ## M31Fcsw M3, Day 1, fecal swab, whole body study ## M11Fcsw M1, Day 1, fecal swab, whole body study ## ... ... ## TS28 Twin #1 ## TS29 Twin #2 ## Even1 Even1 ## Even2 Even2 ## Even3 Even3 2.2.3 rowData rowData contains data on the features of the analyzed samples. Of particular interest for the microbiome field this is used to store taxonomic information. rowData(tse) ## DataFrame with 19216 rows and 7 columns ## Kingdom Phylum Class Order Family ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; ## 549322 Archaea Crenarchaeota Thermoprotei NA NA ## 522457 Archaea Crenarchaeota Thermoprotei NA NA ## 951 Archaea Crenarchaeota Thermoprotei Sulfolobales Sulfolobaceae ## 244423 Archaea Crenarchaeota Sd-NA NA NA ## 586076 Archaea Crenarchaeota Sd-NA NA NA ## ... ... ... ... ... ... ## 278222 Bacteria SR1 NA NA NA ## 463590 Bacteria SR1 NA NA NA ## 535321 Bacteria SR1 NA NA NA ## 200359 Bacteria SR1 NA NA NA ## 271582 Bacteria SR1 NA NA NA ## Genus Species ## &lt;character&gt; &lt;character&gt; ## 549322 NA NA ## 522457 NA NA ## 951 Sulfolobus Sulfolobusacidocalda.. ## 244423 NA NA ## 586076 NA NA ## ... ... ... ## 278222 NA NA ## 463590 NA NA ## 535321 NA NA ## 200359 NA NA ## 271582 NA NA 2.2.4 rowTree Phylogenetic trees also play an important role for the microbiome field. The TreeSummarizedExperiment class is able to keep track of feature and node relations via two functions, rowTree and rowLinks. A tree can be accessed via rowTree as phylo object. rowTree(tse) ## ## Phylogenetic tree with 19216 tips and 19215 internal nodes. ## ## Tip labels: ## 549322, 522457, 951, 244423, 586076, 246140, ... ## Node labels: ## , 0.858.4, 1.000.154, 0.764.3, 0.995.2, 1.000.2, ... ## ## Rooted; includes branch lengths. The links to the individual features are available through rowLinks. rowLinks(tse) ## LinkDataFrame with 19216 rows and 5 columns ## nodeLab nodeNum nodeLab_alias isLeaf whichTree ## &lt;character&gt; &lt;integer&gt; &lt;character&gt; &lt;logical&gt; &lt;character&gt; ## 1 549322 1 alias_1 TRUE phylo ## 2 522457 2 alias_2 TRUE phylo ## 3 951 3 alias_3 TRUE phylo ## 4 244423 4 alias_4 TRUE phylo ## 5 586076 5 alias_5 TRUE phylo ## ... ... ... ... ... ... ## 19212 278222 19212 alias_19212 TRUE phylo ## 19213 463590 19213 alias_19213 TRUE phylo ## 19214 535321 19214 alias_19214 TRUE phylo ## 19215 200359 19215 alias_19215 TRUE phylo ## 19216 271582 19216 alias_19216 TRUE phylo Please note that there can be a 1:1 relationship between tree nodes and features, but this is not a must have. This means there can be features, which are not linked to nodes, and nodes, which are not linked to features. To change the links in an existing object, the changeTree function is available. 2.2.5 Alternative experiments Alternative experiments differ from transformations as they can contain complementary data, which is no longer tied to the same dimensions as the assay data. However, the number of samples (columns) must be the same. This can come into play for instance when one has taxonomic abundance profiles quantified with different measurement technologies, such as phylogenetic microarrays, amplicon sequencing, or metagenomic sequencing. Such alternative experiments that concern the same samples can be stored as Separate assays assuming that the taxonomic information can be mapped between feature directly 1:1; or data in the altExp slot of the TreeSummarizedExperiment, if the feature dimensions differ. Each element of the altExp slot is a SummarizedExperiment or an object from a derived class with independent feature data. As an example, we show how to store taxonomic abundance tables agglomerated at different taxonomic levels. However, the data could as well originate from entirely different measurement sources as long as the samples are matched. # Agglomerate the data to Phylym level tse_phylum &lt;- agglomerateByRank(tse, &quot;Phylum&quot;) # both have the same number of columns (samples) dim(tse) ## [1] 19216 26 dim(tse_phylum) ## [1] 67 26 # Add the new table as an alternative experiment altExp(tse, &quot;Phylum&quot;) &lt;- tse_phylum altExpNames(tse) ## [1] &quot;Phylum&quot; # Pick a sample subset: this acts on both altExp and assay data tse[,1:10] ## class: TreeSummarizedExperiment ## dim: 19216 10 ## metadata(0): ## assays(2): counts relabundance ## rownames(19216): 549322 522457 ... 200359 271582 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(10): CL3 CC1 ... M31Tong M11Tong ## colData names(7): X.SampleID Primer ... SampleType Description ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(1): Phylum ## rowLinks: a LinkDataFrame (19216 rows) ## rowTree: 1 phylo tree(s) (19216 leaves) ## colLinks: NULL ## colTree: NULL dim(altExp(tse[,1:10],&quot;Phylum&quot;)) ## [1] 67 10 For more details of altExp have a look at the Intro vignette of the SingleCellExperiment package (Lun and Risso 2020). 2.2.6 MultiAssayExperiments Multiple experiments relate to complementary measurement types, such as transcriptomic or metabolomic profiling of the microbiome or the host. Multiple experiments can be represented using the same options as alternative experiments, or by using the MultiAssayExperiment class (Ramos et al. 2017). Depending on how the datasets relate to each other the data can be stored as: Separate altExp if the samples can be matched directly 1:1; or As MultiAssayExperiment objects, in which the connections between samples are defined through a sampleMap. Each element on the experimentsList of an MultiAssayExperiment is matrix or matrix-like object including SummarizedExperiment objects, and the number of samples can differ between the elements. #TODO: Find the right dataset to explain a non 1:1 sample relationship For information have a look at the intro vignette of the MultiAssayExperiment package. Table 2.1: Recommended options for storing multiple data tables in microbiome studies The assays are best suited for data transformations (one-to-one match between samples and columns across the assays). The alternative experiments are particularly suitable for alternative versions of the data that are of same type but may have a different number of features (e.g. taxonomic groups); this is for instance the case with taxonomic abundance tables agglomerated at different levels (e.g. genus vs. phyla) or alternative profiling technologies (e.g. amplicon sequencing vs. shallow shotgun metagenomics). For alternative experiments one-to-one match between samples (cols) is required but the alternative experiment tables can have different numbers of features (rows). Finally, elements of the MultiAssayExperiment provide the most flexible way to incorporate multi-omic data tables with flexible numbers of samples and features. We recommend these conventions as the basis for methods development and application in microbiome studies. Option Rows (features) Cols (samples) Recommended assays match match Data transformations altExp free match Alternative experiments MultiAssay free free (mapping) Multi-omic experiments 2.3 Loading experimental microbiome data 2.3.1 16S workflow Result of amplicon sequencing is large number of files that include all the sequences that were read from samples. Those sequences need to be matched with taxa. Additionally, we need to know how many times each taxa were found from each sample. There are several algorithms to do that, and DADA2 is one of the most common. You can find DADA2 pipeline tutorial for example from here. After DADA2 portion of the tutorial is the data is stored into phyloseq object (Bonus: Handoff to phyloseq). To store the data to TreeSummarizedExperiment, follow the example below. You can find full workflow script without further explanations and comments from here Load required packages. library(mia) library(ggplot2) if( !require(&quot;BiocManager&quot;) ){ install.packages(&quot;BiocManager&quot;) library(&quot;BiocManager&quot;) } if( !require(&quot;Biostrings&quot;) ){ BiocManager::install(&quot;Biostrings&quot;) library(&quot;Biostrings&quot;) } library(Biostrings) Create arbitrary example sample metadata like it was done in tutorial. Usually, sample metadata is imported as a file. samples.out &lt;- rownames(seqtab.nochim) subject &lt;- sapply(strsplit(samples.out, &quot;D&quot;), `[`, 1) gender &lt;- substr(subject,1,1) subject &lt;- substr(subject,2,999) day &lt;- as.integer(sapply(strsplit(samples.out, &quot;D&quot;), `[`, 2)) samdf &lt;- data.frame(Subject=subject, Gender=gender, Day=day) samdf$When &lt;- &quot;Early&quot; samdf$When[samdf$Day&gt;100] &lt;- &quot;Late&quot; rownames(samdf) &lt;- samples.out Convert data into right format and create TreeSE object. # Create a list that contains assays counts &lt;- t(seqtab.nochim) counts &lt;- as.matrix(counts) assays &lt;- SimpleList(counts = counts) # Convert colData and rowData into DataFrame samdf &lt;- DataFrame(samdf) taxa &lt;- DataFrame(taxa) # Create TreeSE tse &lt;- TreeSummarizedExperiment(assays = assays, colData = samdf, rowData = taxa ) # Remove mock sample like it is also done in DADA2 pipeline tutorial tse &lt;- tse[ , colnames(tse) != &quot;mock&quot;] Add sequences into referenceSeq slot and convert rownames into simpler format. # Convert sequences into right format dna &lt;- Biostrings::DNAStringSet( rownames(tse) ) # Add sequences into referenceSeq slot referenceSeq(tse) &lt;- dna # Convert rownames into ASV_number format rownames(tse) &lt;- paste0(&quot;ASV&quot;, seq( nrow(tse) )) tse ## class: TreeSummarizedExperiment ## dim: 232 20 ## metadata(0): ## assays(1): counts ## rownames(232): ASV1 ASV2 ... ASV231 ASV232 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(20): F3D0 F3D1 ... F3D9 Mock ## colData names(4): Subject Gender Day When ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: NULL ## rowTree: NULL ## colLinks: NULL ## colTree: NULL ## referenceSeq: a DNAStringSet (232 sequences) 2.3.2 Import from external files Microbiome (taxonomic) profiling data is commonly distributed in various file formats. You can import such external data files as a (Tree)SummarizedExperiment object but the details depend on the file format. Here, we provide examples for common formats. CSV data tables can be imported with the standard R functions, then converted to the desired format. For detailed examples, you can check the Bioconductor course material by Martin Morgan. The following example reads abundance tables, taxonomic mapping tables, and sample metadata, assuming that the input data files are properly prepared with appropriate row and column names. count_file &lt;- &quot;data/assay_taxa.csv&quot; tax_file &lt;- &quot;data/rowdata_taxa.csv&quot; sample_file &lt;- &quot;data/coldata.csv&quot; # Load files counts &lt;- read.csv(count_file) # Abundance table (e.g. ASV data; to assay data) tax &lt;- read.csv(tax_file) # Taxonomy table (to rowData) samples &lt;- read.csv(sample_file) # Sample data (to colData) Always ensure that the tables have rownames! The TreeSE constructor compares rownames and makes sure that, for example, right samples are linked with right patient. # Add rownames and remove an additional column rownames(counts) &lt;- counts$X counts$X &lt;- NULL # Add rownames and remove an additional column rownames(samples) &lt;- samples$X samples$X &lt;- NULL # Add rownames and remove an additional column rownames(tax) &lt;- tax$X tax$X &lt;- NULL # As an example: # If e.g. samples do not match between colData and counts table, you must order # counts based on colData if( any( colnames(counts) != rownames(samples) ) ){ counts &lt;- counts[ , rownames(samples) ] } # And same with rowData and counts... if( any( rownames(counts) != rownames(tax) ) ){ counts &lt;- counts[ rownames(tax), ] } The tables must be in correct format: counts –&gt; matrix rowData –&gt; DataFrame colData –&gt; DataFrame # Ensure that the data is in correct format # counts should be in matrix format counts &lt;- as.matrix(counts) # And it should be added to a SimpleList assays &lt;- SimpleList(counts = counts) # colData and rowData should be in DataFrame format colData &lt;- DataFrame(colData) rowData &lt;- DataFrame(rowData) # Create a TreeSE tse_taxa &lt;- TreeSummarizedExperiment(assays = assays, colData = samples, rowData = tax) tse_taxa ## class: TreeSummarizedExperiment ## dim: 12706 40 ## metadata(0): ## assays(1): counts ## rownames(12706): GAYR01026362.62.2014 CVJT01000011.50.2173 ... ## JRJTB:03787:02429 JRJTB:03787:02478 ## rowData names(7): Phylum Class ... Species OTU ## colnames(40): C1 C2 ... C39 C40 ## colData names(6): Sample Rat ... Fat XOS ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: NULL ## rowTree: NULL ## colLinks: NULL ## colTree: NULL To construct a MultiAssayExperiment object, just combine multiple TreeSE data containers. Here we import metabolite data from the same study. count_file &lt;- &quot;data/assay_metabolites.csv&quot; sample_file &lt;- &quot;data/coldata.csv&quot; # Load files counts &lt;- read.csv(count_file) samples &lt;- read.csv(sample_file) # Add rownames and remove an additional column rownames(counts) &lt;- counts$X counts$X &lt;- NULL rownames(samples) &lt;- samples$X samples$X &lt;- NULL # Convert into right format counts &lt;- as.matrix(counts) assays &lt;- SimpleList(concs = counts) colData &lt;- DataFrame(colData) # Create a TreeSE tse_metabolite &lt;- TreeSummarizedExperiment(assays = assays, colData = samples) tse_metabolite ## class: TreeSummarizedExperiment ## dim: 38 40 ## metadata(0): ## assays(1): concs ## rownames(38): Butyrate Acetate ... Malonate 1,3-dihydroxyacetone ## rowData names(0): ## colnames(40): C1 C2 ... C39 C40 ## colData names(6): Sample Rat ... Fat XOS ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: NULL ## rowTree: NULL ## colLinks: NULL ## colTree: NULL Now we can combine these two experiments into MAE. # Create an ExperimentList that includes experiments experiments &lt;- ExperimentList(microbiome = tse_taxa, metabolite = tse_metabolite) # Create a MAE mae &lt;- MultiAssayExperiment(experiments = experiments) mae ## A MultiAssayExperiment object of 2 listed ## experiments with user-defined names and respective classes. ## Containing an ExperimentList class object of length 2: ## [1] microbiome: TreeSummarizedExperiment with 12706 rows and 40 columns ## [2] metabolite: TreeSummarizedExperiment with 38 rows and 40 columns ## Functionality: ## experiments() - obtain the ExperimentList instance ## colData() - the primary/phenotype DataFrame ## sampleMap() - the sample coordination DataFrame ## `$`, `[`, `[[` - extract colData columns, subset, or experiment ## *Format() - convert into a long or wide DataFrame ## assays() - convert ExperimentList to a SimpleList of matrices ## exportClass() - save data to flat files Specific import functions are provided for: Biom files (see help(mia::loadFromBiom)) QIIME2 files (see help(mia::loadFromQIIME2)) Mothur files (see help(mia::loadFromMothur)) 2.3.2.1 Biom example This example shows how Biom files are imported into a TreeSummarizedExperiment object. The data is from following publication: Tengeler AC et al. (2020) Gut microbiota from persons with attention-deficit/hyperactivity disorder affects the brain in mice. The data set consists of 3 files: biom file: abundance table and taxonomy information csv file: sample metadata tree file: phylogenetic tree Store the data in your desired local directory (for instance, data/ under the working directory), and define source file paths biom_file_path &lt;- &quot;data/Aggregated_humanization2.biom&quot; sample_meta_file_path &lt;- &quot;data/Mapping_file_ADHD_aggregated.csv&quot; tree_file_path &lt;- &quot;data/Data_humanization_phylo_aggregation.tre&quot; Now we can load the biom data into a SummarizedExperiment (SE) object. library(mia) # Imports the data se &lt;- loadFromBiom(biom_file_path) # Check se ## class: TreeSummarizedExperiment ## dim: 151 27 ## metadata(0): ## assays(1): counts ## rownames(151): 1726470 1726471 ... 17264756 17264757 ## rowData names(6): taxonomy1 taxonomy2 ... taxonomy5 taxonomy6 ## colnames(27): A110 A111 ... A38 A39 ## colData names(0): ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: NULL ## rowTree: NULL ## colLinks: NULL ## colTree: NULL The assays slot includes a list of abundance tables. The imported abundance table is named as “counts”. Let us inspect only the first cols and rows. assays(se)$counts[1:3, 1:3] ## A110 A111 A12 ## 1726470 17722 11630 0 ## 1726471 12052 0 2679 ## 17264731 0 970 0 The rowdata includes taxonomic information from the biom file. The head() command shows just the beginning of the data table for an overview. knitr::kable() is for printing the information more nicely. head(rowData(se)) ## DataFrame with 6 rows and 6 columns ## taxonomy1 taxonomy2 taxonomy3 ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## 1726470 &quot;k__Bacteria p__Bacteroidetes c__Bacteroidia ## 1726471 &quot;k__Bacteria p__Bacteroidetes c__Bacteroidia ## 17264731 &quot;k__Bacteria p__Bacteroidetes c__Bacteroidia ## 17264726 &quot;k__Bacteria p__Bacteroidetes c__Bacteroidia ## 1726472 &quot;k__Bacteria p__Verrucomicrobia c__Verrucomicrobiae ## 17264724 &quot;k__Bacteria p__Bacteroidetes c__Bacteroidia ## taxonomy4 taxonomy5 taxonomy6 ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## 1726470 o__Bacteroidales f__Bacteroidaceae g__Bacteroides&quot; ## 1726471 o__Bacteroidales f__Bacteroidaceae g__Bacteroides&quot; ## 17264731 o__Bacteroidales f__Porphyromonadaceae g__Parabacteroides&quot; ## 17264726 o__Bacteroidales f__Bacteroidaceae g__Bacteroides&quot; ## 1726472 o__Verrucomicrobiales f__Verrucomicrobiaceae g__Akkermansia&quot; ## 17264724 o__Bacteroidales f__Bacteroidaceae g__Bacteroides&quot; These taxonomic rank names (column names) are not real rank names. Let’s replace them with real rank names. In addition to that, the taxa names include, e.g., ’“k__’ before the name, so let’s make them cleaner by removing them. names(rowData(se)) &lt;- c(&quot;Kingdom&quot;, &quot;Phylum&quot;, &quot;Class&quot;, &quot;Order&quot;, &quot;Family&quot;, &quot;Genus&quot;) # Goes through the whole DataFrame. Removes &#39;.*[kpcofg]__&#39; from strings, where [kpcofg] # is any character from listed ones, and .* any character. rowdata_modified &lt;- BiocParallel::bplapply(rowData(se), FUN = stringr::str_remove, pattern = &#39;.*[kpcofg]__&#39;) # Genus level has additional &#39;\\&quot;&#39;, so let&#39;s delete that also rowdata_modified &lt;- BiocParallel::bplapply(rowdata_modified, FUN = stringr::str_remove, pattern = &#39;\\&quot;&#39;) # rowdata_modified is a list, so it is converted back to DataFrame format. rowdata_modified &lt;- DataFrame(rowdata_modified) # And then assigned back to the SE object rowData(se) &lt;- rowdata_modified # Now we have a nicer table head(rowData(se)) ## DataFrame with 6 rows and 6 columns ## Kingdom Phylum Class Order ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; ## 1726470 Bacteria Bacteroidetes Bacteroidia Bacteroidales ## 1726471 Bacteria Bacteroidetes Bacteroidia Bacteroidales ## 17264731 Bacteria Bacteroidetes Bacteroidia Bacteroidales ## 17264726 Bacteria Bacteroidetes Bacteroidia Bacteroidales ## 1726472 Bacteria Verrucomicrobia Verrucomicrobiae Verrucomicrobiales ## 17264724 Bacteria Bacteroidetes Bacteroidia Bacteroidales ## Family Genus ## &lt;character&gt; &lt;character&gt; ## 1726470 Bacteroidaceae Bacteroides ## 1726471 Bacteroidaceae Bacteroides ## 17264731 Porphyromonadaceae Parabacteroides ## 17264726 Bacteroidaceae Bacteroides ## 1726472 Verrucomicrobiaceae Akkermansia ## 17264724 Bacteroidaceae Bacteroides We notice that the imported biom file did not contain the sample meta data yet, so it includes an empty data frame. head(colData(se)) ## DataFrame with 6 rows and 0 columns Let us add a sample metadata file. # We use this to check what type of data it is # read.table(sample_meta_file_path) # It seems like a comma separated file and it does not include headers # Let us read it and then convert from data.frame to DataFrame # (required for our purposes) sample_meta &lt;- DataFrame(read.table(sample_meta_file_path, sep = &quot;,&quot;, header = FALSE)) # Add sample names to rownames rownames(sample_meta) &lt;- sample_meta[,1] # Delete column that included sample names sample_meta[,1] &lt;- NULL # We can add headers colnames(sample_meta) &lt;- c(&quot;patient_status&quot;, &quot;cohort&quot;, &quot;patient_status_vs_cohort&quot;, &quot;sample_name&quot;) # Then it can be added to colData colData(se) &lt;- sample_meta Now colData includes the sample metadata. head(colData(se)) ## DataFrame with 6 rows and 4 columns ## patient_status cohort patient_status_vs_cohort sample_name ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; ## A110 ADHD Cohort_1 ADHD_Cohort_1 A110 ## A12 ADHD Cohort_1 ADHD_Cohort_1 A12 ## A15 ADHD Cohort_1 ADHD_Cohort_1 A15 ## A19 ADHD Cohort_1 ADHD_Cohort_1 A19 ## A21 ADHD Cohort_2 ADHD_Cohort_2 A21 ## A23 ADHD Cohort_2 ADHD_Cohort_2 A23 Now, let’s add a phylogenetic tree. The current data object, se, is a SummarizedExperiment object. This does not include a slot for adding a phylogenetic tree. In order to do this, we can convert the SE object to an extended TreeSummarizedExperiment object which includes also a rowTree slot. TreeSummarizedExperiment contains also other additional slots and features which is why we recommend to use TreeSE. tse &lt;- as(se, &quot;TreeSummarizedExperiment&quot;) # tse includes same data as se tse ## class: TreeSummarizedExperiment ## dim: 151 27 ## metadata(0): ## assays(1): counts ## rownames(151): 1726470 1726471 ... 17264756 17264757 ## rowData names(6): Kingdom Phylum ... Family Genus ## colnames(27): A110 A12 ... A35 A38 ## colData names(4): patient_status cohort patient_status_vs_cohort ## sample_name ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: NULL ## rowTree: NULL ## colLinks: NULL ## colTree: NULL Next, let us read the tree data file and add it to the R data object (tse). # Reads the tree file tree &lt;- ape::read.tree(tree_file_path) # Add tree to rowTree rowTree(tse) &lt;- tree # Check tse ## class: TreeSummarizedExperiment ## dim: 151 27 ## metadata(0): ## assays(1): counts ## rownames(151): 1726470 1726471 ... 17264756 17264757 ## rowData names(6): Kingdom Phylum ... Family Genus ## colnames(27): A110 A12 ... A35 A38 ## colData names(4): patient_status cohort patient_status_vs_cohort ## sample_name ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (151 rows) ## rowTree: 1 phylo tree(s) (151 leaves) ## colLinks: NULL ## colTree: NULL Now rowTree includes a phylogenetic tree: head(rowTree(tse)) 2.3.3 Conversions between data formats in R If the data has already been imported in R in another format, it can be readily converted into TreeSummarizedExperiment, as shown in our next example. Note that similar conversion functions to TreeSummarizedExperiment are available for multiple data formats via the mia package (see makeTreeSummarizedExperimentFrom* for phyloseq, Biom, and DADA2). library(mia) # phyloseq example data data(GlobalPatterns, package=&quot;phyloseq&quot;) GlobalPatterns_phyloseq &lt;- GlobalPatterns GlobalPatterns_phyloseq ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 19216 taxa and 26 samples ] ## sample_data() Sample Data: [ 26 samples by 7 sample variables ] ## tax_table() Taxonomy Table: [ 19216 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 19216 tips and 19215 internal nodes ] # convert phyloseq to TSE GlobalPatterns_TSE &lt;- makeTreeSummarizedExperimentFromPhyloseq(GlobalPatterns_phyloseq) GlobalPatterns_TSE ## class: TreeSummarizedExperiment ## dim: 19216 26 ## metadata(0): ## assays(1): counts ## rownames(19216): 549322 522457 ... 200359 271582 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(26): CL3 CC1 ... Even2 Even3 ## colData names(7): X.SampleID Primer ... SampleType Description ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (19216 rows) ## rowTree: 1 phylo tree(s) (19216 leaves) ## colLinks: NULL ## colTree: NULL We can also convert TreeSummarizedExperiment objects into phyloseq with respect to the shared components that are supported by both formats (i.e. taxonomic abundance table, sample metadata, taxonomic table, phylogenetic tree, sequence information). This is useful for instance when additional methods are available for phyloseq. # convert TSE to phyloseq GlobalPatterns_phyloseq2 &lt;- makePhyloseqFromTreeSummarizedExperiment(GlobalPatterns_TSE) GlobalPatterns_phyloseq2 ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 19216 taxa and 26 samples ] ## sample_data() Sample Data: [ 26 samples by 7 sample variables ] ## tax_table() Taxonomy Table: [ 19216 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 19216 tips and 19215 internal nodes ] Conversion is possible between other data formats. Interested readers can refer to the following functions: * makeTreeSummarizedExperimentFromDADA2 * makeSummarizedExperimentFromBiom * loadFromMetaphlan * readQZA 2.4 Demonstration data Open demonstration data for testing and benchmarking purposes is available from multiple locations. This chapter introduces some options. The other chapters of this book provide ample examples about the use of the data. 2.4.1 Package data The mia R package contains example data sets that are direct conversions from the alternative phyloseq container to the TreeSummarizedExperiment container. List the available datasets in the mia package: library(mia) data(package=&quot;mia&quot;) Load the GlobalPatterns data from the mia package: data(&quot;GlobalPatterns&quot;, package=&quot;mia&quot;) GlobalPatterns ## class: TreeSummarizedExperiment ## dim: 19216 26 ## metadata(0): ## assays(1): counts ## rownames(19216): 549322 522457 ... 200359 271582 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(26): CL3 CC1 ... Even2 Even3 ## colData names(7): X.SampleID Primer ... SampleType Description ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (19216 rows) ## rowTree: 1 phylo tree(s) (19216 leaves) ## colLinks: NULL ## colTree: NULL Check the documentation for this data set: ## Help on topic &#39;GlobalPatterns&#39; was found in the following packages: ## ## Package Library ## phyloseq /__w/_temp/Library ## mia /__w/_temp/Library ## ## ## Using the first match ... 2.4.2 ExperimentHub data ExperimentHub provides a variety of data resources, including the microbiomeDataSets package (Morgan and Shepherd 2021; Leo Lahti, Ernst, and Shetty 2021). A table of the available data sets is available through the availableDataSets function. library(microbiomeDataSets) availableDataSets() ## Dataset ## 1 GrieneisenTSData ## 2 HintikkaXOData ## 3 LahtiMLData ## 4 LahtiMData ## 5 LahtiWAData ## 6 OKeefeDSData ## 7 SilvermanAGutData ## 8 SongQAData ## 9 SprockettTHData All data are downloaded from ExperimentHub and cached for local re-use. Check the man pages of each function for a detailed documentation of the data contents and references. Let us retrieve a MultiAssayExperiment data set: # mae &lt;- HintikkaXOData() # Since HintikkaXOData is now added to mia, we can load it directly from there # We suggest to check other datasets from microbiomeDataSets data(HintikkaXOData) mae &lt;- HintikkaXOData Data is available in SummarizedExperiment, r Biocpkg(\"TreeSummarizedExperiment\") and r Biocpkg(\"MultiAssayExperiment\") data containers; see the separate page on alternative containers for more details. 2.4.3 Curated metagenomic data curatedMetagenomicData is a large collection of curated human microbiome data sets, provided as (Tree)SummarizedExperiment objects (Pasolli et al. 2017). The resource provides curated human microbiome data including gene families, marker abundance, marker presence, pathway abundance, pathway coverage, and relative abundance for samples from different body sites. See the package homepage for more details on data availability and access. As one example, let us retrieve the Vatanen (2016) (Vatanen et al. 2016) data set. This is a larger collection with a bit longer download time. library(curatedMetagenomicData) tse &lt;- curatedMetagenomicData(&quot;Vatanen*&quot;, dryrun = FALSE, counts = TRUE) 2.4.4 Other data sources The current collections provide access to vast microbiome data resources. The output has to be converted into TreeSE/MAE separately. MGnifyR provides access to EBI/MGnify qiitr provides access to QIITA Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] microbiomeDataSets_1.1.7 phyloseq_1.40.0 [3] BiocManager_1.30.20 ggplot2_3.4.2 [5] mia_1.7.11 MultiAssayExperiment_1.24.0 [7] TreeSummarizedExperiment_2.1.4 Biostrings_2.66.0 [9] XVector_0.38.0 SingleCellExperiment_1.20.1 [11] SummarizedExperiment_1.28.0 Biobase_2.58.0 [13] GenomicRanges_1.50.2 GenomeInfoDb_1.34.9 [15] IRanges_2.32.0 S4Vectors_0.36.2 [17] BiocGenerics_0.44.0 MatrixGenerics_1.10.0 [19] matrixStats_0.63.0-9003 BiocStyle_2.24.0 [21] rebook_1.6.0 loaded via a namespace (and not attached): [1] AnnotationHub_3.4.0 BiocFileCache_2.4.0 [3] plyr_1.8.8 igraph_1.4.1 [5] lazyeval_0.2.2 splines_4.2.1 [7] BiocParallel_1.32.6 scater_1.26.1 [9] digest_0.6.31 foreach_1.5.2 [11] yulab.utils_0.0.6 htmltools_0.5.5 [13] viridis_0.6.2 fansi_1.0.4 [15] magrittr_2.0.3 memoise_2.0.1 [17] ScaledMatrix_1.6.0 cluster_2.1.4 [19] DECIPHER_2.26.0 colorspace_2.1-0 [21] blob_1.2.4 rappdirs_0.3.3 [23] ggrepel_0.9.3 xfun_0.38 [25] dplyr_1.1.1 crayon_1.5.2 [27] RCurl_1.98-1.12 jsonlite_1.8.4 [29] graph_1.74.0 survival_3.5-5 [31] iterators_1.0.14 ape_5.7-1 [33] glue_1.6.2 gtable_0.3.3 [35] zlibbioc_1.44.0 DelayedArray_0.24.0 [37] BiocSingular_1.14.0 Rhdf5lib_1.18.2 [39] scales_1.2.1 DBI_1.1.3 [41] Rcpp_1.0.10 xtable_1.8-4 [43] viridisLite_0.4.1 decontam_1.18.0 [45] tidytree_0.4.2 bit_4.0.5 [47] rsvd_1.0.5 httr_1.4.5 [49] dir.expiry_1.4.0 ellipsis_0.3.2 [51] pkgconfig_2.0.3 XML_3.99-0.14 [53] scuttle_1.8.4 CodeDepends_0.6.5 [55] sass_0.4.5 dbplyr_2.3.2 [57] utf8_1.2.3 AnnotationDbi_1.58.0 [59] later_1.3.0 tidyselect_1.2.0 [61] rlang_1.1.0 reshape2_1.4.4 [63] munsell_0.5.0 BiocVersion_3.15.2 [65] tools_4.2.1 cachem_1.0.7 [67] cli_3.6.1 DirichletMultinomial_1.40.0 [69] generics_0.1.3 RSQLite_2.3.1 [71] ExperimentHub_2.4.0 ade4_1.7-22 [73] evaluate_0.20 biomformat_1.24.0 [75] stringr_1.5.0 fastmap_1.1.1 [77] yaml_2.3.7 knitr_1.42 [79] bit64_4.0.5 purrr_1.0.1 [81] KEGGREST_1.36.3 nlme_3.1-162 [83] sparseMatrixStats_1.10.0 mime_0.12 [85] compiler_4.2.1 interactiveDisplayBase_1.34.0 [87] beeswarm_0.4.0 filelock_1.0.2 [89] curl_5.0.0 png_0.1-8 [91] treeio_1.22.0 tibble_3.2.1 [93] bslib_0.4.2 stringi_1.7.12 [95] highr_0.10 lattice_0.21-8 [97] Matrix_1.5-4 vegan_2.6-4 [99] permute_0.9-7 multtest_2.52.0 [101] vctrs_0.6.1 pillar_1.9.0 [103] lifecycle_1.0.3 rhdf5filters_1.8.0 [105] jquerylib_0.1.4 BiocNeighbors_1.16.0 [107] data.table_1.14.8 bitops_1.0-7 [109] irlba_2.3.5.1 httpuv_1.6.9 [111] R6_2.5.1 promises_1.2.0.1 [113] bookdown_0.33 gridExtra_2.3 [115] vipor_0.4.5 codetools_0.2-19 [117] MASS_7.3-58.3 rhdf5_2.40.0 [119] withr_2.5.0 GenomeInfoDbData_1.2.9 [121] mgcv_1.8-42 parallel_4.2.1 [123] grid_4.2.1 beachmat_2.14.0 [125] tidyr_1.3.0 rmarkdown_2.21 [127] DelayedMatrixStats_1.20.0 shiny_1.7.4 [129] ggbeeswarm_0.7.1 Bibliography "],["packages.html", "Chapter 3 Packages 3.1 Package installation 3.2 Package ecosystem 3.3 Data ecosystem Session Info", " Chapter 3 Packages .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 3.1 Package installation You can install all packages that are required to run every example in this book via the following command: source(&quot;https://raw.githubusercontent.com/microbiome/OMA/master/install_packages.R&quot;) 3.1.1 Installing specific packages You can install R packages of your choice with the following command line procedure. Bioconductor release version is the most stable and tested version but may miss some of the latest methods and updates. It can be installed with: BiocManager::install(&quot;microbiome/mia&quot;) Bioconductor development version requires the installation of the latest R beta version. This is primarily recommended for those who already have experience with R/Bioconductor and need access to the latest updates. BiocManager::install(&quot;microbiome/mia&quot;, version=&quot;devel&quot;) Github development version provides access to the latest but potentially unstable features. This is useful when you want access to all available tools. devtools::install_github(&quot;microbiome/mia&quot;) 3.2 Package ecosystem Methods for the analysis and manipulation of (Tree)SummarizedExperiment and MultiAssayExperiment data containers are available through a number of R packages. Some of these are listed below. If you know more tips on such packages, data sources, or other resources, kindly let us know through the issues, pull requests, or online channels. 3.2.1 mia family of methods mia: Microbiome analysis tools (Ernst, Shetty, and Lahti 2020) miaViz: Microbiome analysis specific visualization (Ernst, Borman, and Lahti 2022) miaSim: Microbiome data simulations (Simsek et al. 2021) miaTime: Microbiome time series analysis (L. Lahti 2021) 3.2.2 Tree-based methods philr (Silverman et al. (2017)) 3.2.3 Differential abundance ANCOMBC for differential abundance analysis benchdamic for benchmarking differential abundance methods 3.2.4 Manipulation MicrobiotaProcess for analyzing microbiome and other ecological data within the tidy framework 3.2.5 Further options Tools for Microbiome Analysis site listed over 130 R packages for microbiome data science in Many of these do not directly support the data containers used in this book but can be used with minor conversions between formats. 3.3 Data ecosystem Section 2.4 links to various open microbiome data resources that support this framework. Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] BiocStyle_2.24.0 rebook_1.6.0 loaded via a namespace (and not attached): [1] graph_1.74.0 knitr_1.42 BiocGenerics_0.44.0 [4] R6_2.5.1 rlang_1.1.0 fastmap_1.1.1 [7] tools_4.2.1 xfun_0.38 cli_3.6.1 [10] jquerylib_0.1.4 htmltools_0.5.5 CodeDepends_0.6.5 [13] yaml_2.3.7 digest_0.6.31 bookdown_0.33 [16] dir.expiry_1.4.0 BiocManager_1.30.20 sass_0.4.5 [19] codetools_0.2-19 cachem_1.0.7 evaluate_0.20 [22] rmarkdown_2.21 compiler_4.2.1 bslib_0.4.2 [25] filelock_1.0.2 stats4_4.2.1 XML_3.99-0.14 [28] jsonlite_1.8.4 Bibliography "],["datamanipulation.html", "Chapter 4 Data Manipulation 4.1 Tidying and subsetting 4.2 Add or modify data 4.3 Merge data", " Chapter 4 Data Manipulation .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 4.1 Tidying and subsetting 4.1.1 Tidy data For several custom analysis and visualization packages, such as those from tidyverse, the SE data can be converted to a long data.frame format with meltAssay. library(mia) data(GlobalPatterns, package=&quot;mia&quot;) tse &lt;- GlobalPatterns tse &lt;- transformCounts(tse, MARGIN = &quot;samples&quot;, method=&quot;relabundance&quot;) molten_tse &lt;- mia::meltAssay(tse, add_row_data = TRUE, add_col_data = TRUE, assay_name = &quot;relabundance&quot;) molten_tse ## # A tibble: 499,616 × 17 ## FeatureID SampleID relabundance Kingdom Phylum Class Order Family Genus ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 549322 CL3 0 Archaea Crenarchaeo… Ther… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 549322 CC1 0 Archaea Crenarchaeo… Ther… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 549322 SV1 0 Archaea Crenarchaeo… Ther… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 549322 M31Fcsw 0 Archaea Crenarchaeo… Ther… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 549322 M11Fcsw 0 Archaea Crenarchaeo… Ther… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 549322 M31Plmr 0 Archaea Crenarchaeo… Ther… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 549322 M11Plmr 0 Archaea Crenarchaeo… Ther… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 8 549322 F21Plmr 0 Archaea Crenarchaeo… Ther… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 9 549322 M31Tong 0 Archaea Crenarchaeo… Ther… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 10 549322 M11Tong 0 Archaea Crenarchaeo… Ther… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## # ℹ 499,606 more rows ## # ℹ 8 more variables: Species &lt;chr&gt;, X.SampleID &lt;fct&gt;, Primer &lt;fct&gt;, ## # Final_Barcode &lt;fct&gt;, Barcode_truncated_plus_T &lt;fct&gt;, ## # Barcode_full_length &lt;fct&gt;, SampleType &lt;fct&gt;, Description &lt;fct&gt; 4.1.2 Subsetting Subsetting data helps to draw the focus of analysis on particular sets of samples and / or features. When dealing with large data sets, the subset of interest can be extracted and investigated separately. This might improve performance and reduce the computational load. Load: mia dplyr knitr data GlobalPatterns Let us store GlobalPatterns into tse and check its original number of features (rows) and samples (columns). Note: when subsetting by sample, expect the number of columns to decrease; when subsetting by feature, expect the number of rows to decrease. # Store data into se and check dimensions data(&quot;GlobalPatterns&quot;, package=&quot;mia&quot;) tse &lt;- GlobalPatterns # Show dimensions (features x samples) dim(tse) ## [1] 19216 26 4.1.2.1 Subset by sample (column-wise) For the sake of demonstration, here we will extract a subset containing only the samples of human origin (feces, skin or tongue), stored as SampleType within colData(tse) and also in tse. First, we would like to see all the possible values that SampleType can take on and how frequent those are: # Inspect possible values for SampleType unique(tse$SampleType) ## [1] Soil Feces Skin Tongue ## [5] Freshwater Freshwater (creek) Ocean Sediment (estuary) ## [9] Mock ## 9 Levels: Feces Freshwater Freshwater (creek) Mock ... Tongue # Show the frequency of each value tse$SampleType %&gt;% table() . Freq Feces 4 Freshwater 2 Freshwater (creek) 3 Mock 3 Ocean 3 Sediment (estuary) 3 Skin 3 Soil 3 Tongue 2 Note: after subsetting, expect the number of columns to equal the sum of the frequencies of the samples that you are interested in. For instance, ncols = Feces + Skin + Tongue = 4 + 3 + 2 = 9. Next, we logical index across the columns of tse (make sure to leave the first index empty to select all rows) and filter for the samples of human origin. For this, we use the information on the samples from the meta data colData(tse). # Subset by sample tse_subset_by_sample &lt;- tse[ , tse$SampleType %in% c(&quot;Feces&quot;, &quot;Skin&quot;, &quot;Tongue&quot;)] # Show dimensions dim(tse_subset_by_sample) ## [1] 19216 9 As a sanity check, the new object tse_subset_by_sample should have the original number of features (rows) and a number of samples (columns) equal to the sum of the samples of interest (in this case 9). Several characteristics can be used to subset by sample: origin sampling time sequencing method DNA / RNA barcode cohort 4.1.2.2 Subset by feature (row-wise) Similarly, here we will extract a subset containing only the features that belong to the phyla Actinobacteria and Chlamydiae, stored as Phylum within rowData(tse). However, subsetting by feature implies a few more obstacles, such as the presence of NA elements and the possible need for agglomeration. As previously, we would first like to see all the possible values that Phylum can take on and how frequent those are: # Inspect possible values for phylum unique(rowData(tse)$Phylum) ## [1] &quot;Crenarchaeota&quot; &quot;Euryarchaeota&quot; &quot;Actinobacteria&quot; &quot;Spirochaetes&quot; ## [5] &quot;MVP-15&quot; &quot;Proteobacteria&quot; &quot;SBR1093&quot; &quot;Fusobacteria&quot; ## [9] &quot;Tenericutes&quot; &quot;ZB3&quot; &quot;Cyanobacteria&quot; &quot;GOUTA4&quot; ## [13] &quot;TG3&quot; &quot;Chlorobi&quot; &quot;Bacteroidetes&quot; &quot;Caldithrix&quot; ## [17] &quot;KSB1&quot; &quot;SAR406&quot; &quot;LCP-89&quot; &quot;Thermi&quot; ## [21] &quot;Gemmatimonadetes&quot; &quot;Fibrobacteres&quot; &quot;GN06&quot; &quot;AC1&quot; ## [25] &quot;TM6&quot; &quot;OP8&quot; &quot;Elusimicrobia&quot; &quot;NC10&quot; ## [29] &quot;SPAM&quot; NA &quot;Acidobacteria&quot; &quot;CCM11b&quot; ## [33] &quot;Nitrospirae&quot; &quot;NKB19&quot; &quot;BRC1&quot; &quot;Hyd24-12&quot; ## [37] &quot;WS3&quot; &quot;PAUC34f&quot; &quot;GN04&quot; &quot;GN12&quot; ## [41] &quot;Verrucomicrobia&quot; &quot;Lentisphaerae&quot; &quot;LD1&quot; &quot;Chlamydiae&quot; ## [45] &quot;OP3&quot; &quot;Planctomycetes&quot; &quot;Firmicutes&quot; &quot;OP9&quot; ## [49] &quot;WPS-2&quot; &quot;Armatimonadetes&quot; &quot;SC3&quot; &quot;TM7&quot; ## [53] &quot;GN02&quot; &quot;SM2F11&quot; &quot;ABY1_OD1&quot; &quot;ZB2&quot; ## [57] &quot;OP11&quot; &quot;Chloroflexi&quot; &quot;SC4&quot; &quot;WS1&quot; ## [61] &quot;GAL15&quot; &quot;AD3&quot; &quot;WS2&quot; &quot;Caldiserica&quot; ## [65] &quot;Thermotogae&quot; &quot;Synergistetes&quot; &quot;SR1&quot; # Show the frequency of each value rowData(tse)$Phylum %&gt;% table() . Freq ABY1_OD1 7 AC1 1 Acidobacteria 1021 Actinobacteria 1631 AD3 9 Armatimonadetes 61 Bacteroidetes 2382 BRC1 13 Caldiserica 3 Caldithrix 10 CCM11b 2 Chlamydiae 21 Chlorobi 64 Chloroflexi 437 Crenarchaeota 106 Cyanobacteria 393 Elusimicrobia 31 Euryarchaeota 102 Fibrobacteres 7 Firmicutes 4356 Fusobacteria 37 GAL15 2 Gemmatimonadetes 191 GN02 8 GN04 7 GN06 2 GN12 1 GOUTA4 11 Hyd24-12 4 KSB1 6 LCP-89 2 LD1 2 Lentisphaerae 21 MVP-15 5 NC10 9 Nitrospirae 74 NKB19 16 OP11 6 OP3 30 OP8 27 OP9 4 PAUC34f 3 Planctomycetes 638 Proteobacteria 6416 SAR406 21 SBR1093 9 SC3 8 SC4 8 SM2F11 5 SPAM 22 Spirochaetes 124 SR1 5 Synergistetes 7 Tenericutes 143 TG3 5 Thermi 46 Thermotogae 1 TM6 27 TM7 32 Verrucomicrobia 470 WPS-2 20 WS1 5 WS2 2 WS3 70 ZB2 2 ZB3 2 Note: after subsetting, expect the number of columns to equal the sum of the frequencies of the feature(s) that you are interested in. For instance, nrows = Actinobacteria + Chlamydiae = 1631 + 21 = 1652. Depending on your research question, you might or might not need to agglomerate the data in the first place: if you want to find the abundance of each and every feature that belongs to Actinobacteria and Chlamydiae, agglomeration is not needed; if you want to find the total abundance of all features that belong to Actinobacteria or Chlamydiae, agglomeration is recommended. 4.1.2.2.1 Non-agglomerated data Next, we logical index across the rows of tse (make sure to leave the second index empty to select all columns) and filter for the features that fall in either Actinobacteria or Chlamydiae group. For this, we use the information on the samples from the metadata rowData(tse). The first term with the %in% operator includes all the features of interest, whereas the second term after the AND operator &amp; filters out all features that have an NA in place of the phylum variable. # Subset by feature tse_subset_by_feature &lt;- tse[rowData(tse)$Phylum %in% c(&quot;Actinobacteria&quot;, &quot;Chlamydiae&quot;) &amp; !is.na(rowData(tse)$Phylum), ] # Show dimensions dim(tse_subset_by_feature) ## [1] 1652 26 As a sanity check, the new object, tse_subset_by_feature, should have the original number of samples (columns) and a number of features (rows) equal to the sum of the features of interest (in this case, 1652). 4.1.2.2.2 Agglomerated data When total abundances of certain phyla are of relevance, the data is initially agglomerated by Phylum. Then, similar steps as in the case of non-agglomerated data are followed. # Agglomerate by phylum tse_phylum &lt;- tse %&gt;% agglomerateByRank(rank = &quot;Phylum&quot;) # Subset by feature and remove NAs tse_phylum_subset_by_feature &lt;- tse_phylum[rowData(tse_phylum)$Phylum %in% c(&quot;Actinobacteria&quot;, &quot;Chlamydiae&quot;) &amp; !is.na(rowData(tse_phylum)$Phylum), ] # Show dimensions dim(tse_phylum_subset_by_feature) ## [1] 2 26 Note: as data was agglomerated, the number of rows should equal the number of phyla used to index (in this case, just 2). Alternatively: # Store features of interest into phyla phyla &lt;- c(&quot;Phylum:Actinobacteria&quot;, &quot;Phylum:Chlamydiae&quot;) # subset by feature tse_phylum_subset_by_feature &lt;- tse_phylum[phyla, ] # Show dimensions dim(tse_subset_by_feature) ## [1] 1652 26 The code above returns the non-agglomerated version of the data. Fewer characteristics can be used to subset by feature: Taxonomic rank Meta-taxonomic group For subsetting by kingdom, agglomeration does not apply, whereas for the other ranks it can be applied if necessary. 4.1.2.3 Subset by sample and feature Finally, we can subset data by sample and feature at once. The resulting subset contains all the samples of human origin and all the features of phyla Actinobacteria or Chlamydiae. # Subset by sample and feature and remove NAs tse_subset_by_sample_feature &lt;- tse[rowData(tse)$Phylum %in% c(&quot;Actinobacteria&quot;, &quot;Chlamydiae&quot;) &amp; !is.na(rowData(tse)$Phylum), tse$SampleType %in% c(&quot;Feces&quot;, &quot;Skin&quot;, &quot;Tongue&quot;)] # Show dimensions dim(tse_subset_by_sample_feature) ## [1] 1652 9 Note: the dimensions of tse_subset_by_sample_feature agree with those of the previous subsets (9 columns filtered by sample and 1652 rows filtered by feature). If a study was to consider and quantify the presence of Actinobacteria as well as Chlamydiae in different sites of the human body, tse_subset_by_sample_feature might be a suitable subset to start with. 4.1.2.4 Remove empty columns and rows Sometimes data might contain, e.g., features that are not present in any of the samples. This can occur, for example, after the data subsetting. In certain analyses, we might want to remove those instances. # Agglomerate data at Genus level tse_genus &lt;- agglomerateByRank(tse, rank = &quot;Genus&quot;) # List bacteria that we want to include genera &lt;- c(&quot;Class:Thermoprotei&quot;, &quot;Genus:Sulfolobus&quot;, &quot;Genus:Sediminicola&quot;) # Subset data tse_genus_sub &lt;- tse_genus[genera, ] tse_genus_sub ## class: TreeSummarizedExperiment ## dim: 3 26 ## metadata(1): agglomerated_by_rank ## assays(1): counts ## rownames(3): Class:Thermoprotei Genus:Sulfolobus Genus:Sediminicola ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(26): CL3 CC1 ... Even2 Even3 ## colData names(7): X.SampleID Primer ... SampleType Description ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (3 rows) ## rowTree: 1 phylo tree(s) (19216 leaves) ## colLinks: NULL ## colTree: NULL # List total counts of each sample colSums(assay(tse_genus_sub, &quot;counts&quot;)) ## CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr F21Plmr ## 1 0 0 1 1 0 4 1 ## M31Tong M11Tong LMEpi24M SLEpi20M AQC1cm AQC4cm AQC7cm NP2 ## 7 3 0 2 64 105 136 222 ## NP3 NP5 TRRsed1 TRRsed2 TRRsed3 TS28 TS29 Even1 ## 6433 1154 2 2 2 0 0 0 ## Even2 Even3 ## 2 0 Now we can see that certain samples do not include any bacteria. We can remove those. # Remove samples that do not contain any bacteria tse_genus_sub &lt;- tse_genus_sub[ , colSums(assay(tse_genus_sub, &quot;counts&quot;)) != 0 ] tse_genus_sub ## class: TreeSummarizedExperiment ## dim: 3 18 ## metadata(1): agglomerated_by_rank ## assays(1): counts ## rownames(3): Class:Thermoprotei Genus:Sulfolobus Genus:Sediminicola ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(18): CL3 M31Fcsw ... TRRsed3 Even2 ## colData names(7): X.SampleID Primer ... SampleType Description ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (3 rows) ## rowTree: 1 phylo tree(s) (19216 leaves) ## colLinks: NULL ## colTree: NULL The same action can also be applied to the features. # Take only those samples that are collected from feces, skin, or tongue tse_genus_sub &lt;- tse_genus[ , colData(tse_genus)$SampleType %in% c(&quot;Feces&quot;, &quot;Skin&quot;, &quot;Tongue&quot;)] tse_genus_sub ## class: TreeSummarizedExperiment ## dim: 1516 9 ## metadata(1): agglomerated_by_rank ## assays(1): counts ## rownames(1516): Class:Thermoprotei Genus:Sulfolobus ... ## Genus:Coprothermobacter Phylum:SR1 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(9): M31Fcsw M11Fcsw ... TS28 TS29 ## colData names(7): X.SampleID Primer ... SampleType Description ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (1516 rows) ## rowTree: 1 phylo tree(s) (19216 leaves) ## colLinks: NULL ## colTree: NULL # What is the number of bacteria that are not present? sum(rowSums(assay(tse_genus_sub, &quot;counts&quot;)) == 0) ## [1] 435 We can see that there are bacteria that are not present in these samples we chose. We can remove those bacteria from the data. # Take only those bacteria that are present tse_genus_sub &lt;- tse_genus_sub[rowSums(assay(tse_genus_sub, &quot;counts&quot;)) &gt; 0, ] tse_genus_sub ## class: TreeSummarizedExperiment ## dim: 1081 9 ## metadata(1): agglomerated_by_rank ## assays(1): counts ## rownames(1081): Genus:Sulfolobus Order:NRP-J ... ## Genus:Coprothermobacter Phylum:SR1 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(9): M31Fcsw M11Fcsw ... TS28 TS29 ## colData names(7): X.SampleID Primer ... SampleType Description ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (1081 rows) ## rowTree: 1 phylo tree(s) (19216 leaves) ## colLinks: NULL ## colTree: NULL 4.1.3 Splitting You can split the data based on variables by using the functions splitByRanks and splitOn. splitByRanks splits the data based on taxonomic ranks. Since the elements of the output list share columns, they can be stored into altExp. altExps(tse) &lt;- splitByRanks(tse) altExps(tse) ## List of length 7 ## names(7): Kingdom Phylum Class Order Family Genus Species If you want to split the data based on another variable than taxonomic rank, use splitOn. It works for row-wise and column-wise splitting. splitOn(tse, &quot;SampleType&quot;) ## List of length 9 ## names(9): Soil Feces Skin Tongue ... Ocean Sediment (estuary) Mock 4.2 Add or modify data The information contained by the colData of a TreeSE can be modified by accessing the desired variables. # modify the Description entries colData(tse)$Description &lt;- paste(colData(tse)$Description, &quot;modified description&quot;) # view modified variable head(tse$Description) ## [1] &quot;Calhoun South Carolina Pine soil, pH 4.9 modified description&quot; ## [2] &quot;Cedar Creek Minnesota, grassland, pH 6.1 modified description&quot; ## [3] &quot;Sevilleta new Mexico, desert scrub, pH 8.3 modified description&quot; ## [4] &quot;M3, Day 1, fecal swab, whole body study modified description&quot; ## [5] &quot;M1, Day 1, fecal swab, whole body study modified description&quot; ## [6] &quot;M3, Day 1, right palm, whole body study modified description&quot; New information can also be added to the experiment by creating a new variable. # simulate new data new_data &lt;- runif(ncol(tse)) # store new data as new variable in colData colData(tse)$NewVariable &lt;- new_data # view new variable head(tse$NewVariable) ## [1] 0.69830 0.02152 0.01484 0.58783 0.84836 0.61813 4.3 Merge data mia package has mergeSEs function that merges multiple SummarizedExperiment objects. For example, it is possible to combine multiple TreeSE objects which each includes one sample. mergeSEs works like dplyr joining functions. In fact, there are available dplyr-like aliases of mergeSEs, such as full_join. # Take subsets for demonstration purposes tse1 &lt;- tse[, 1] tse2 &lt;- tse[, 2] tse3 &lt;- tse[, 3] tse4 &lt;- tse[1:100, 4] # With inner join, we want to include all shared rows. When using mergeSEs function # all samples are always preserved. tse &lt;- mergeSEs(list(tse1, tse2, tse3, tse4), join = &quot;inner&quot;) tse ## class: TreeSummarizedExperiment ## dim: 100 4 ## metadata(0): ## assays(1): counts ## rownames(100): 239672 243675 ... 549322 951 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(4): CC1 CL3 M31Fcsw SV1 ## colData names(8): X.SampleID Primer ... Description NewVariable ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (100 rows) ## rowTree: 1 phylo tree(s) (19216 leaves) ## colLinks: NULL ## colTree: NULL # Left join preserves all rows of the 1st object tse &lt;- mia::left_join(tse1, tse4, missing_values = 0) tse ## class: TreeSummarizedExperiment ## dim: 19216 2 ## metadata(0): ## assays(1): counts ## rownames(19216): 239672 243675 ... 146168 594324 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(2): CL3 M31Fcsw ## colData names(8): X.SampleID Primer ... Description NewVariable ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (19216 rows) ## rowTree: 1 phylo tree(s) (19216 leaves) ## colLinks: NULL ## colTree: NULL 4.3.1 Additional functions mapTaxonomy mergeRows/mergeCols "],["quality-control.html", "Chapter 5 Exploration and quality Control 5.1 Abundance 5.2 Prevalence 5.3 Quality control Session Info", " Chapter 5 Exploration and quality Control .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } This chapter focuses on the quality control and exploration of microbiome data and establishes commonly used descriptive summaries. Familiarizing with the peculiarities of a given data set is the essential basis for any data analysis and model building. The dataset should not suffer from severe technical biases, and you should at least be aware of potential challenges, such as outliers, biases, unexpected patterns and so forth. Standard summaries and visualizations can help, and the rest comes with experience. The exploration and quality control can be iterative processes. library(mia) 5.1 Abundance Abundance visualization is an important data exploration approach. miaViz offers the function plotAbundanceDensity to plot the most abundant taxa with several options. In the following few demonstrations are shown, using the (L. Lahti et al. 2014) dataset. A Jitter plot based on relative abundance data, similar to the one presented at (Salosensaari et al. 2021) supplementary figure 1, could be visualized as follows: # Loading example data library(miaTime) library(miaViz) data(hitchip1006) tse &lt;- hitchip1006 # Add relative abundances tse &lt;- transformCounts(tse, MARGIN = &quot;samples&quot;, method = &quot;relabundance&quot;) library(miaViz) # Use argument names # assay_name / assay_name / assay_name # depending on the mia package version plotAbundanceDensity(tse, layout = &quot;jitter&quot;, assay_name = &quot;relabundance&quot;, n = 40, point_size=1, point_shape=19, point_alpha=0.1) + scale_x_log10(label=scales::percent) The relative abundance values for the top-5 taxonomic features can be visualized as a density plot over a log scaled axis, with “nationality” indicated by colors: plotAbundanceDensity(tse, layout = &quot;density&quot;, assay_name = &quot;relabundance&quot;, n = 5, colour_by=&quot;nationality&quot;, point_alpha=1/10) + scale_x_log10() 5.2 Prevalence Prevalence quantifies the frequency of samples where certain microbes were detected (above a given detection threshold). The prevalence can be given as sample size (N) or percentage (unit interval). Investigating prevalence allows you either to focus on changes which pertain to the majority of the samples, or identify rare microbes, which may be conditionally abundant in a small number of samples, however. The population prevalence (frequency) at a 1% relative abundance threshold (detection = 1/100 and as_relative = TRUE), can look like this. head(getPrevalence(tse, detection = 1/100, sort = TRUE, as_relative = TRUE)) ## Faecalibacterium prausnitzii et rel. Ruminococcus obeum et rel. ## 0.9522 0.9140 ## Oscillospira guillermondii et rel. Clostridium symbiosum et rel. ## 0.8801 0.8714 ## Subdoligranulum variable at rel. Clostridium orbiscindens et rel. ## 0.8358 0.8315 The function arguments detection and as_relative can also be used to access, how many samples do pass a threshold for raw counts. Here the population prevalence (frequency) at the absolute abundance threshold (as_relative = FALSE) at read count 1 (detection = 1) is accessed. head(getPrevalence(tse, detection = 1, sort = TRUE, assay_name = &quot;counts&quot;, as_relative = FALSE)) ## Uncultured Mollicutes Uncultured Clostridiales II ## 1 1 ## Uncultured Clostridiales I Tannerella et rel. ## 1 1 ## Sutterella wadsworthia et rel. Subdoligranulum variable at rel. ## 1 1 If the output should be used for subsetting or storing the data in the rowData, set sort = FALSE. 5.2.1 Prevalence analysis To investigate microbiome prevalence at a selected taxonomic level, two approaches are available. First the data can be agglomerated to the taxonomic level and getPrevalence applied on the resulting object. # Agglomerate taxa abundances to Phylum level, and add the new table # to the altExp slot altExp(tse,&quot;Phylum&quot;) &lt;- agglomerateByRank(tse, &quot;Phylum&quot;) # Check prevalence for the Phylum abundance table from the altExp slot head(getPrevalence(altExp(tse,&quot;Phylum&quot;), detection = 1/100, sort = TRUE, assay_name = &quot;counts&quot;, as_relative = TRUE)) ## Firmicutes Bacteroidetes Actinobacteria Proteobacteria Verrucomicrobia ## 1.0000000 0.9852302 0.4821894 0.2988705 0.1277150 ## Cyanobacteria ## 0.0008688 Alternatively, the rank argument could be set to perform the agglomeration on the fly. head(getPrevalence(tse, rank = &quot;Phylum&quot;, detection = 1/100, sort = TRUE, assay_name = &quot;counts&quot;, as_relative = TRUE)) ## Firmicutes Bacteroidetes Actinobacteria Proteobacteria Verrucomicrobia ## 1.0000000 0.9852302 0.4821894 0.2988705 0.1277150 ## Cyanobacteria ## 0.0008688 Note that, by default, na.rm = TRUE is used for agglomeration in getPrevalence, whereas the default for agglomerateByRank is FALSE to prevent accidental data loss. If you only need the names of the prevalent taxa, getPrevalentTaxa is available. This returns the taxa that exceed the given prevalence and detection thresholds. getPrevalentTaxa(tse, detection = 0, prevalence = 50/100) prev &lt;- getPrevalentTaxa(tse, detection = 0, prevalence = 50/100, rank = &quot;Phylum&quot;, sort = TRUE) prev Note that the detection and prevalence thresholds are not the same, since detection can be applied to relative counts or absolute counts depending on whether as_relative is set TRUE or FALSE The function ‘getPrevalentAbundance’ can be used to check the total relative abundance of the prevalent taxa (between 0 and 1). 5.2.2 Rare taxa Related functions are available for the analysis of rare taxa (rareMembers; rareAbundance; lowAbundance, getRareTaxa, subsetByRareTaxa). 5.2.3 Plotting prevalence To plot the prevalence, add the prevalence of each taxa to the rowData. Here, we are analysing the Phylum level abundances, which are stored in the altExp slot. rowData(altExp(tse,&quot;Phylum&quot;))$prevalence &lt;- getPrevalence(altExp(tse,&quot;Phylum&quot;), detection = 1/100, sort = FALSE, assay_name = &quot;counts&quot;, as_relative = TRUE) The prevalences can be then plotted via the plotting functions from the scater package. library(scater) plotRowData(altExp(tse,&quot;Phylum&quot;), &quot;prevalence&quot;, colour_by = &quot;Phylum&quot;) The prevalence can be also visualized on the taxonomic tree with the miaViz package. altExps(tse) &lt;- splitByRanks(tse) altExps(tse) &lt;- lapply(altExps(tse), function(y){ rowData(y)$prevalence &lt;- getPrevalence(y, detection = 1/100, sort = FALSE, assay_name = &quot;counts&quot;, as_relative = TRUE) y }) top_phyla &lt;- getTopTaxa(altExp(tse,&quot;Phylum&quot;), method=&quot;prevalence&quot;, top=5L, assay_name=&quot;counts&quot;) top_phyla_mean &lt;- getTopTaxa(altExp(tse,&quot;Phylum&quot;), method=&quot;mean&quot;, top=5L, assay_name=&quot;counts&quot;) x &lt;- unsplitByRanks(tse, ranks = taxonomyRanks(tse)[1:6]) x &lt;- addTaxonomyTree(x) After some preparation the data is assembled and can be plotted via plotRowTree. library(miaViz) plotRowTree(x[rowData(x)$Phylum %in% top_phyla,], edge_colour_by = &quot;Phylum&quot;, tip_colour_by = &quot;prevalence&quot;, node_colour_by = &quot;prevalence&quot;) Figure 5.1: Prevalence of top phyla as judged by prevalence plotRowTree(x[rowData(x)$Phylum %in% top_phyla_mean,], edge_colour_by = &quot;Phylum&quot;, tip_colour_by = &quot;prevalence&quot;, node_colour_by = &quot;prevalence&quot;) Figure 5.2: Prevalence of top phyla as judged by mean abundance 5.3 Quality control Next, let us load the GlobalPatterns data set to illustrate standard microbiome data summaries. library(mia) data(&quot;GlobalPatterns&quot;, package=&quot;mia&quot;) tse &lt;- GlobalPatterns 5.3.1 Top taxa The getTopTaxa identifies top taxa in the data. # Pick the top taxa top_features &lt;- getTopTaxa(tse, method=&quot;median&quot;, top=10) # Check the information for these rowData(tse)[top_features, taxonomyRanks(tse)] ## DataFrame with 10 rows and 7 columns ## Kingdom Phylum Class Order ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; ## 549656 Bacteria Cyanobacteria Chloroplast Stramenopiles ## 331820 Bacteria Bacteroidetes Bacteroidia Bacteroidales ## 317182 Bacteria Cyanobacteria Chloroplast Stramenopiles ## 94166 Bacteria Proteobacteria Gammaproteobacteria Pasteurellales ## 279599 Bacteria Cyanobacteria Nostocophycideae Nostocales ## 158660 Bacteria Bacteroidetes Bacteroidia Bacteroidales ## 329744 Bacteria Actinobacteria Actinobacteria Actinomycetales ## 326977 Bacteria Actinobacteria Actinobacteria Bifidobacteriales ## 248140 Bacteria Bacteroidetes Bacteroidia Bacteroidales ## 550960 Bacteria Proteobacteria Gammaproteobacteria Enterobacteriales ## Family Genus Species ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## 549656 NA NA NA ## 331820 Bacteroidaceae Bacteroides NA ## 317182 NA NA NA ## 94166 Pasteurellaceae Haemophilus Haemophilusparainflu.. ## 279599 Nostocaceae Dolichospermum NA ## 158660 Bacteroidaceae Bacteroides NA ## 329744 ACK-M1 NA NA ## 326977 Bifidobacteriaceae Bifidobacterium Bifidobacteriumadole.. ## 248140 Bacteroidaceae Bacteroides Bacteroidescaccae ## 550960 Enterobacteriaceae Providencia NA 5.3.2 Library size / read count The total counts/sample can be calculated using the perCellQCMetrics/addPerCellQC from the scater package. The former one just calculates the values, whereas the latter one directly adds them to the colData. library(scater) perCellQCMetrics(tse) ## DataFrame with 26 rows and 3 columns ## sum detected total ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## CL3 864077 6964 864077 ## CC1 1135457 7679 1135457 ## SV1 697509 5729 697509 ## M31Fcsw 1543451 2667 1543451 ## M11Fcsw 2076476 2574 2076476 ## ... ... ... ... ## TS28 937466 2679 937466 ## TS29 1211071 2629 1211071 ## Even1 1216137 4213 1216137 ## Even2 971073 3130 971073 ## Even3 1078241 2776 1078241 tse &lt;- addPerCellQC(tse) colData(tse) ## DataFrame with 26 rows and 10 columns ## X.SampleID Primer Final_Barcode Barcode_truncated_plus_T ## &lt;factor&gt; &lt;factor&gt; &lt;factor&gt; &lt;factor&gt; ## CL3 CL3 ILBC_01 AACGCA TGCGTT ## CC1 CC1 ILBC_02 AACTCG CGAGTT ## SV1 SV1 ILBC_03 AACTGT ACAGTT ## M31Fcsw M31Fcsw ILBC_04 AAGAGA TCTCTT ## M11Fcsw M11Fcsw ILBC_05 AAGCTG CAGCTT ## ... ... ... ... ... ## TS28 TS28 ILBC_25 ACCAGA TCTGGT ## TS29 TS29 ILBC_26 ACCAGC GCTGGT ## Even1 Even1 ILBC_27 ACCGCA TGCGGT ## Even2 Even2 ILBC_28 ACCTCG CGAGGT ## Even3 Even3 ILBC_29 ACCTGT ACAGGT ## Barcode_full_length SampleType ## &lt;factor&gt; &lt;factor&gt; ## CL3 CTAGCGTGCGT Soil ## CC1 CATCGACGAGT Soil ## SV1 GTACGCACAGT Soil ## M31Fcsw TCGACATCTCT Feces ## M11Fcsw CGACTGCAGCT Feces ## ... ... ... ## TS28 GCATCGTCTGG Feces ## TS29 CTAGTCGCTGG Feces ## Even1 TGACTCTGCGG Mock ## Even2 TCTGATCGAGG Mock ## Even3 AGAGAGACAGG Mock ## Description sum detected ## &lt;factor&gt; &lt;numeric&gt; &lt;numeric&gt; ## CL3 Calhoun South Carolina Pine soil, pH 4.9 864077 6964 ## CC1 Cedar Creek Minnesota, grassland, pH 6.1 1135457 7679 ## SV1 Sevilleta new Mexico, desert scrub, pH 8.3 697509 5729 ## M31Fcsw M3, Day 1, fecal swab, whole body study 1543451 2667 ## M11Fcsw M1, Day 1, fecal swab, whole body study 2076476 2574 ## ... ... ... ... ## TS28 Twin #1 937466 2679 ## TS29 Twin #2 1211071 2629 ## Even1 Even1 1216137 4213 ## Even2 Even2 971073 3130 ## Even3 Even3 1078241 2776 ## total ## &lt;numeric&gt; ## CL3 864077 ## CC1 1135457 ## SV1 697509 ## M31Fcsw 1543451 ## M11Fcsw 2076476 ## ... ... ## TS28 937466 ## TS29 1211071 ## Even1 1216137 ## Even2 971073 ## Even3 1078241 The distribution of calculated library sizes can be visualized as a histogram (left), or by sorting the samples by library size (right). library(ggplot2) p1 &lt;- ggplot(as.data.frame(colData(tse))) + geom_histogram(aes(x = sum), color = &quot;black&quot;, fill = &quot;gray&quot;, bins = 30) + labs(x = &quot;Library size&quot;, y = &quot;Frequency (n)&quot;) + # scale_x_log10(breaks = scales::trans_breaks(&quot;log10&quot;, function(x) 10^x), # labels = scales::trans_format(&quot;log10&quot;, scales::math_format(10^.x))) + theme_bw() + theme(panel.grid.major = element_blank(), # Removes the grid panel.grid.minor = element_blank(), panel.border = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) # Adds y-axis library(dplyr) df &lt;- as.data.frame(colData(tse)) %&gt;% arrange(sum) %&gt;% mutate(index = 1:n()) p2 &lt;- ggplot(df, aes(y = index, x = sum/1e6)) + geom_point() + labs(x = &quot;Library size (million reads)&quot;, y = &quot;Sample index&quot;) + theme_bw() + theme(panel.grid.major = element_blank(), # Removes the grid panel.grid.minor = element_blank(), panel.border = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) # Adds y-axis library(patchwork) p1 + p2 Figure 5.3: Library size distribution. Library sizes - and other variables from colData - can be also visualized by using specified function called plotColData. library(ggplot2) # Sort samples by read count, order the factor levels, and store back to tse as DataFrame # TODO: plotColData could include an option for sorting samples based on colData variables colData(tse) &lt;- as.data.frame(colData(tse)) %&gt;% arrange(X.SampleID) %&gt;% mutate(X.SampleID = factor(X.SampleID, levels=X.SampleID)) %&gt;% DataFrame plotColData(tse,&quot;sum&quot;,&quot;X.SampleID&quot;, colour_by = &quot;SampleType&quot;) + theme(axis.text.x = element_text(angle = 45, hjust=1)) + labs(y = &quot;Library size (N)&quot;, x = &quot;Sample ID&quot;) Figure 5.4: Library sizes per sample. plotColData(tse,&quot;sum&quot;,&quot;SampleType&quot;, colour_by = &quot;SampleType&quot;) + theme(axis.text.x = element_text(angle = 45, hjust=1)) Figure 5.5: Library sizes per sample type. In addition, data can be rarefied with subsampleCounts, which normalises the samples to an equal number of reads. However, this practice has been discouraged for the analysis of differentially abundant microorganisms (see (P. J. McMurdie and Holmes 2014)). 5.3.3 Contaminant sequences Samples might be contaminated with exogenous sequences. The impact of each contaminant can be estimated based on their frequencies and concentrations across the samples. The following decontam functions are based on the (Davis et al. 2018) and support such functionality: isContaminant, isNotContaminant addContaminantQC, addNotContaminantQC Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] patchwork_1.1.2 dplyr_1.1.1 [3] scater_1.26.1 scuttle_1.8.4 [5] miaViz_1.7.5 ggraph_2.1.0 [7] ggplot2_3.4.2 miaTime_0.1.21 [9] mia_1.7.11 MultiAssayExperiment_1.24.0 [11] TreeSummarizedExperiment_2.1.4 Biostrings_2.66.0 [13] XVector_0.38.0 SingleCellExperiment_1.20.1 [15] SummarizedExperiment_1.28.0 Biobase_2.58.0 [17] GenomicRanges_1.50.2 GenomeInfoDb_1.34.9 [19] IRanges_2.32.0 S4Vectors_0.36.2 [21] BiocGenerics_0.44.0 MatrixGenerics_1.10.0 [23] matrixStats_0.63.0-9003 BiocStyle_2.24.0 [25] rebook_1.6.0 loaded via a namespace (and not attached): [1] ggtree_3.4.4 ggnewscale_0.4.8 [3] ggbeeswarm_0.7.1 colorspace_2.1-0 [5] BiocNeighbors_1.16.0 aplot_0.1.10 [7] farver_2.1.1 graphlayouts_0.8.4 [9] ggrepel_0.9.3 bit64_4.0.5 [11] fansi_1.0.4 decontam_1.18.0 [13] codetools_0.2-19 splines_4.2.1 [15] sparseMatrixStats_1.10.0 cachem_1.0.7 [17] knitr_1.42 polyclip_1.10-4 [19] jsonlite_1.8.4 cluster_2.1.4 [21] graph_1.74.0 ggforce_0.4.1 [23] BiocManager_1.30.20 compiler_4.2.1 [25] Matrix_1.5-4 fastmap_1.1.1 [27] lazyeval_0.2.2 cli_3.6.1 [29] tweenr_2.0.2 BiocSingular_1.14.0 [31] htmltools_0.5.5 tools_4.2.1 [33] igraph_1.4.1 rsvd_1.0.5 [35] gtable_0.3.3 glue_1.6.2 [37] GenomeInfoDbData_1.2.9 reshape2_1.4.4 [39] Rcpp_1.0.10 jquerylib_0.1.4 [41] vctrs_0.6.1 ape_5.7-1 [43] nlme_3.1-162 DECIPHER_2.26.0 [45] DelayedMatrixStats_1.20.0 xfun_0.38 [47] stringr_1.5.0 beachmat_2.14.0 [49] lifecycle_1.0.3 irlba_2.3.5.1 [51] XML_3.99-0.14 zlibbioc_1.44.0 [53] MASS_7.3-58.3 scales_1.2.1 [55] tidygraph_1.2.3 parallel_4.2.1 [57] yaml_2.3.7 memoise_2.0.1 [59] gridExtra_2.3 ggfun_0.0.9 [61] yulab.utils_0.0.6 sass_0.4.5 [63] stringi_1.7.12 RSQLite_2.3.1 [65] highr_0.10 ScaledMatrix_1.6.0 [67] tidytree_0.4.2 permute_0.9-7 [69] filelock_1.0.2 BiocParallel_1.32.6 [71] rlang_1.1.0 pkgconfig_2.0.3 [73] bitops_1.0-7 evaluate_0.20 [75] lattice_0.21-8 purrr_1.0.1 [77] labeling_0.4.2 treeio_1.22.0 [79] CodeDepends_0.6.5 cowplot_1.1.1 [81] bit_4.0.5 tidyselect_1.2.0 [83] plyr_1.8.8 magrittr_2.0.3 [85] bookdown_0.33 R6_2.5.1 [87] generics_0.1.3 DelayedArray_0.24.0 [89] DBI_1.1.3 withr_2.5.0 [91] pillar_1.9.0 mgcv_1.8-42 [93] RCurl_1.98-1.12 tibble_3.2.1 [95] dir.expiry_1.4.0 crayon_1.5.2 [97] utf8_1.2.3 rmarkdown_2.21 [99] viridis_0.6.2 grid_4.2.1 [101] blob_1.2.4 vegan_2.6-4 [103] digest_0.6.31 tidyr_1.3.0 [105] gridGraphics_0.5-1 munsell_0.5.0 [107] DirichletMultinomial_1.40.0 ggplotify_0.1.0 [109] beeswarm_0.4.0 viridisLite_0.4.1 [111] vipor_0.4.5 bslib_0.4.2 Bibliography "],["taxonomic-information.html", "Chapter 6 Taxonomic Information 6.1 Assigning taxonomic information. 6.2 Functions to access taxonomic information 6.3 Data agglomeration 6.4 Data transformation 6.5 Pick specific Session Info", " Chapter 6 Taxonomic Information .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } library(mia) data(&quot;GlobalPatterns&quot;, package=&quot;mia&quot;) tse &lt;- GlobalPatterns Taxonomic information is a key part of analyzing microbiome data and without it, any type of data analysis probably will not make much sense. However, the degree of detail of taxonomic information differs depending on the dataset and annotation data used. Therefore, the mia package expects a loose assembly of taxonomic information and assumes certain key aspects: Taxonomic information is given as character vectors or factors in the rowData of a SummarizedExperiment object. The columns containing the taxonomic information must be named domain, kingdom, phylum, class, order, family, genus, species or with a capital first letter. the columns must be given in the order shown above column can be omited, but the order must remain 6.1 Assigning taxonomic information. There are a number of methods to assign taxonomic information. We like to give a short introduction about the methods available without ranking one over the other. This has to be your choice based on the result for the individual dataset. 6.1.1 dada2 The dada2 package (Benjamin J. Callahan et al. 2016) implements the assignTaxonomy function, which takes as input the ASV sequences associated with each row of data and a training dataset. For more information visit the dada2 homepage. 6.1.2 DECIPHER The DECIPHER package (Wright 2020) implements the IDTAXA algorithm to assign either taxonomic information or function information. For mia only the first option is of interest for now and more information can be found on the DECIPHER website. 6.2 Functions to access taxonomic information checkTaxonomy checks whether the taxonomic information is usable for mia checkTaxonomy(tse) ## [1] TRUE Since the rowData can contain other data, taxonomyRanks will return the columns mia assumes to contain the taxonomic information. taxonomyRanks(tse) ## [1] &quot;Kingdom&quot; &quot;Phylum&quot; &quot;Class&quot; &quot;Order&quot; &quot;Family&quot; &quot;Genus&quot; &quot;Species&quot; This can then be used to subset the rowData to columns needed. rowData(tse)[,taxonomyRanks(tse)] ## DataFrame with 19216 rows and 7 columns ## Kingdom Phylum Class Order Family ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; ## 549322 Archaea Crenarchaeota Thermoprotei NA NA ## 522457 Archaea Crenarchaeota Thermoprotei NA NA ## 951 Archaea Crenarchaeota Thermoprotei Sulfolobales Sulfolobaceae ## 244423 Archaea Crenarchaeota Sd-NA NA NA ## 586076 Archaea Crenarchaeota Sd-NA NA NA ## ... ... ... ... ... ... ## 278222 Bacteria SR1 NA NA NA ## 463590 Bacteria SR1 NA NA NA ## 535321 Bacteria SR1 NA NA NA ## 200359 Bacteria SR1 NA NA NA ## 271582 Bacteria SR1 NA NA NA ## Genus Species ## &lt;character&gt; &lt;character&gt; ## 549322 NA NA ## 522457 NA NA ## 951 Sulfolobus Sulfolobusacidocalda.. ## 244423 NA NA ## 586076 NA NA ## ... ... ... ## 278222 NA NA ## 463590 NA NA ## 535321 NA NA ## 200359 NA NA ## 271582 NA NA taxonomyRankEmpty checks for empty values in the given rank and returns a logical vector of length(x). all(!taxonomyRankEmpty(tse, rank = &quot;Kingdom&quot;)) ## [1] TRUE table(taxonomyRankEmpty(tse, rank = &quot;Genus&quot;)) ## ## FALSE TRUE ## 8008 11208 table(taxonomyRankEmpty(tse, rank = &quot;Species&quot;)) ## ## FALSE TRUE ## 1413 17803 getTaxonomyLabels is a multi-purpose function, which turns taxonomic information into a character vector of length(x) head(getTaxonomyLabels(tse)) ## [1] &quot;Class:Thermoprotei&quot; &quot;Class:Thermoprotei_1&quot; ## [3] &quot;Species:Sulfolobusacidocaldarius&quot; &quot;Class:Sd-NA&quot; ## [5] &quot;Class:Sd-NA_1&quot; &quot;Class:Sd-NA_2&quot; By default, this will use the lowest non-empty information to construct a string with the following scheme level:value. If all levels are the same, this part is omitted, but can be added by setting with_rank = TRUE. phylum &lt;- !is.na(rowData(tse)$Phylum) &amp; vapply(data.frame(apply(rowData(tse)[,taxonomyRanks(tse)[3:7]],1L,is.na)),all,logical(1)) head(getTaxonomyLabels(tse[phylum,])) ## [1] &quot;Crenarchaeota&quot; &quot;Crenarchaeota_1&quot; &quot;Crenarchaeota_2&quot; &quot;Actinobacteria&quot; ## [5] &quot;Actinobacteria_1&quot; &quot;Spirochaetes&quot; head(getTaxonomyLabels(tse[phylum,], with_rank = TRUE)) ## [1] &quot;Phylum:Crenarchaeota&quot; &quot;Phylum:Crenarchaeota_1&quot; ## [3] &quot;Phylum:Crenarchaeota_2&quot; &quot;Phylum:Actinobacteria&quot; ## [5] &quot;Phylum:Actinobacteria_1&quot; &quot;Phylum:Spirochaetes&quot; By default the return value of getTaxonomyLabels contains only unique elements by passing it through make.unique. This step can be omitted by setting make_unique = FALSE. head(getTaxonomyLabels(tse[phylum,], with_rank = TRUE, make_unique = FALSE)) ## [1] &quot;Phylum:Crenarchaeota&quot; &quot;Phylum:Crenarchaeota&quot; &quot;Phylum:Crenarchaeota&quot; ## [4] &quot;Phylum:Actinobacteria&quot; &quot;Phylum:Actinobacteria&quot; &quot;Phylum:Spirochaetes&quot; To apply the loop resolving function resolveLoop from the TreeSummarizedExperiment package (Huang 2020) within getTaxonomyLabels, set resolve_loops = TRUE. The function getUniqueTaxa gives a list of unique taxa for the specified taxonomic rank. head(getUniqueTaxa(tse, rank = &quot;Phylum&quot;)) ## [1] &quot;Crenarchaeota&quot; &quot;Euryarchaeota&quot; &quot;Actinobacteria&quot; &quot;Spirochaetes&quot; ## [5] &quot;MVP-15&quot; &quot;Proteobacteria&quot; 6.2.1 Generate a taxonomic tree on the fly To create a taxonomic tree, taxonomyTree used the information and returns a phylo object. Duplicate information from the rowData is removed. taxonomyTree(tse) ## ## Phylogenetic tree with 1645 tips and 1089 internal nodes. ## ## Tip labels: ## Species:Cenarchaeumsymbiosum, Species:pIVWA5, Species:CandidatusNitrososphaeragargensis, Species:SCA1145, Species:SCA1170, Species:Sulfolobusacidocaldarius, ... ## Node labels: ## root:ALL, Kingdom:Archaea, Phylum:Crenarchaeota, Class:C2, Class:Sd-NA, Class:Thaumarchaeota, ... ## ## Rooted; includes branch lengths. tse &lt;- addTaxonomyTree(tse) tse ## class: TreeSummarizedExperiment ## dim: 19216 26 ## metadata(0): ## assays(1): counts ## rownames(19216): Class:Thermoprotei Class:Thermoprotei ... Phylum:SR1 ## Phylum:SR1 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(26): CL3 CC1 ... Even2 Even3 ## colData names(7): X.SampleID Primer ... SampleType Description ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (19216 rows) ## rowTree: 1 phylo tree(s) (1645 leaves) ## colLinks: NULL ## colTree: NULL The implementation is based on the toTree function from the TreeSummarizedExperiment package (Huang 2020). 6.3 Data agglomeration One of the main applications of taxonomic information in regards to count data is to agglomerate count data on taxonomic levels and track the influence of changing conditions through these levels. For this mia contains the agglomerateByRank function. The ideal location to store the agglomerated data is as an alternative experiment. tse &lt;- relAbundanceCounts(tse) altExp(tse, &quot;Family&quot;) &lt;- agglomerateByRank(tse, rank = &quot;Family&quot;, agglomerateTree = TRUE) altExp(tse, &quot;Family&quot;) ## class: TreeSummarizedExperiment ## dim: 603 26 ## metadata(1): agglomerated_by_rank ## assays(2): counts relabundance ## rownames(603): Class:Thermoprotei Family:Sulfolobaceae ... ## Family:Thermodesulfobiaceae Phylum:SR1 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(26): CL3 CC1 ... Even2 Even3 ## colData names(7): X.SampleID Primer ... SampleType Description ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (603 rows) ## rowTree: 1 phylo tree(s) (496 leaves) ## colLinks: NULL ## colTree: NULL If multiple assays (counts and relabundance) exist, both will be agglomerated. assayNames(tse) ## [1] &quot;counts&quot; &quot;relabundance&quot; assayNames(altExp(tse, &quot;Family&quot;)) ## [1] &quot;counts&quot; &quot;relabundance&quot; assay(altExp(tse, &quot;Family&quot;), &quot;relabundance&quot;)[1:5,1:7] ## CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr ## Class:Thermoprotei 0.0000000 0.000e+00 0 0 0 0 0.000e+00 ## Family:Sulfolobaceae 0.0000000 0.000e+00 0 0 0 0 2.305e-06 ## Class:Sd-NA 0.0000000 0.000e+00 0 0 0 0 0.000e+00 ## Order:NRP-J 0.0001991 2.070e-04 0 0 0 0 6.914e-06 ## Family:SAGMA-X 0.0000000 6.165e-06 0 0 0 0 0.000e+00 assay(altExp(tse, &quot;Family&quot;), &quot;counts&quot;)[1:5,1:7] ## CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr ## Class:Thermoprotei 0 0 0 0 0 0 0 ## Family:Sulfolobaceae 0 0 0 0 0 0 1 ## Class:Sd-NA 0 0 0 0 0 0 0 ## Order:NRP-J 172 235 0 0 0 0 3 ## Family:SAGMA-X 0 7 0 0 0 0 0 altExpNames now consists of Family level data. This can be extended to use any taxonomic level listed in mia::taxonomyRanks(tse). 6.4 Data transformation Data transformations are common in microbiome analysis. Examples include the logarithmic transformation, calculation of relative abundances (percentages), and compositionality-aware transformations such as the centered log-ratio transformation (clr). In mia package, transformations are applied to abundance data. The transformed abundance table is stored back to ‘assays’. mia includes transformation function (‘transformCounts()’) which applies sample-wise or column-wise transformation when MARGIN = ‘samples’, feature-wise or row-wise transformation when MARGIN = ‘features’. For a complete list of available transformations and parameters, see function help. assay(tse, &quot;pseudo&quot;) &lt;- assay(tse, &quot;counts&quot;) + 1 tse &lt;- transformCounts(tse, assay_name = &quot;pseudo&quot;, method = &quot;relabundance&quot;) tse &lt;- transformCounts(x = tse, assay_name = &quot;relabundance&quot;, method = &quot;clr&quot;, pseudocount = 1, name = &quot;clr_transformation&quot;) head(assay(tse, &quot;clr_transformation&quot;)) ## CL3 CC1 SV1 M31Fcsw ## Class:Thermoprotei -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05 ## Class:Thermoprotei -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05 ## Species:Sulfolobusacidocaldarius -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05 ## Class:Sd-NA -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05 ## Class:Sd-NA -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05 ## Class:Sd-NA -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05 ## M11Fcsw M31Plmr M11Plmr F21Plmr ## Class:Thermoprotei -4.947e-05 -4.931e-05 -4.879e-05 -4.671e-05 ## Class:Thermoprotei -4.947e-05 -4.931e-05 -4.879e-05 -4.671e-05 ## Species:Sulfolobusacidocaldarius -4.947e-05 -4.931e-05 -4.658e-05 -4.671e-05 ## Class:Sd-NA -4.947e-05 -4.931e-05 -4.879e-05 -4.671e-05 ## Class:Sd-NA -4.947e-05 -4.931e-05 -4.879e-05 -4.671e-05 ## Class:Sd-NA -4.947e-05 -4.931e-05 -4.879e-05 -4.671e-05 ## M31Tong M11Tong LMEpi24M SLEpi20M ## Class:Thermoprotei -4.846e-05 -4.257e-05 -4.756e-05 -4.837e-05 ## Class:Thermoprotei -4.846e-05 -4.257e-05 -4.756e-05 -4.918e-05 ## Species:Sulfolobusacidocaldarius -4.846e-05 -4.257e-05 -4.756e-05 -4.918e-05 ## Class:Sd-NA -4.846e-05 -4.257e-05 -4.756e-05 -4.918e-05 ## Class:Sd-NA -4.846e-05 -4.257e-05 -4.756e-05 -4.918e-05 ## Class:Sd-NA -4.846e-05 -4.257e-05 -4.756e-05 -4.918e-05 ## AQC1cm AQC4cm AQC7cm NP2 ## Class:Thermoprotei -2.385e-05 -4.438e-06 2.787e-05 -4.731e-05 ## Class:Thermoprotei -4.660e-05 -4.568e-05 -4.428e-05 -4.915e-05 ## Species:Sulfolobusacidocaldarius -4.660e-05 -4.652e-05 -4.777e-05 -4.915e-05 ## Class:Sd-NA -4.660e-05 -3.726e-05 -3.090e-05 -4.915e-05 ## Class:Sd-NA -4.660e-05 -4.568e-05 -4.719e-05 -4.915e-05 ## Class:Sd-NA -4.660e-05 -4.610e-05 -4.603e-05 -4.915e-05 ## NP3 NP5 TRRsed1 TRRsed2 ## Class:Thermoprotei -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05 ## Class:Thermoprotei -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05 ## Species:Sulfolobusacidocaldarius -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05 ## Class:Sd-NA -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05 ## Class:Sd-NA -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05 ## Class:Sd-NA -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05 ## TRRsed3 TS28 TS29 Even1 ## Class:Thermoprotei -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05 ## Class:Thermoprotei -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05 ## Species:Sulfolobusacidocaldarius -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05 ## Class:Sd-NA -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05 ## Class:Sd-NA -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05 ## Class:Sd-NA -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05 ## Even2 Even3 ## Class:Thermoprotei -5.017e-05 -5.034e-05 ## Class:Thermoprotei -5.017e-05 -5.034e-05 ## Species:Sulfolobusacidocaldarius -5.017e-05 -5.034e-05 ## Class:Sd-NA -5.017e-05 -5.034e-05 ## Class:Sd-NA -5.017e-05 -5.034e-05 ## Class:Sd-NA -5.017e-05 -5.034e-05 In ‘pa’ transformation, abundance table is converted to present/absent table. tse &lt;- transformCounts(tse, method = &quot;pa&quot;) head(assay(tse, &quot;pa&quot;)) ## CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr ## Class:Thermoprotei 0 0 0 0 0 0 0 ## Class:Thermoprotei 0 0 0 0 0 0 0 ## Species:Sulfolobusacidocaldarius 0 0 0 0 0 0 1 ## Class:Sd-NA 0 0 0 0 0 0 0 ## Class:Sd-NA 0 0 0 0 0 0 0 ## Class:Sd-NA 0 0 0 0 0 0 0 ## F21Plmr M31Tong M11Tong LMEpi24M SLEpi20M ## Class:Thermoprotei 0 0 0 0 1 ## Class:Thermoprotei 0 0 0 0 0 ## Species:Sulfolobusacidocaldarius 0 0 0 0 0 ## Class:Sd-NA 0 0 0 0 0 ## Class:Sd-NA 0 0 0 0 0 ## Class:Sd-NA 0 0 0 0 0 ## AQC1cm AQC4cm AQC7cm NP2 NP3 NP5 TRRsed1 ## Class:Thermoprotei 1 1 1 1 0 0 0 ## Class:Thermoprotei 0 1 1 0 0 0 0 ## Species:Sulfolobusacidocaldarius 0 0 0 0 0 0 0 ## Class:Sd-NA 0 1 1 0 0 0 0 ## Class:Sd-NA 0 1 1 0 0 0 0 ## Class:Sd-NA 0 1 1 0 0 0 0 ## TRRsed2 TRRsed3 TS28 TS29 Even1 Even2 Even3 ## Class:Thermoprotei 0 0 0 0 0 0 0 ## Class:Thermoprotei 0 0 0 0 0 0 0 ## Species:Sulfolobusacidocaldarius 0 0 0 0 0 0 0 ## Class:Sd-NA 0 0 0 0 0 0 0 ## Class:Sd-NA 0 0 0 0 0 0 0 ## Class:Sd-NA 0 0 0 0 0 0 0 # list of abundance tables that assays slot contains assays(tse) ## List of length 5 ## names(5): counts relabundance pseudo clr_transformation pa 6.5 Pick specific Retrieving of specific elements that are required for specific analysis. For instance, extracting abundances for a specific taxa in all samples or all taxa in one sample. 6.5.1 Abundances of all taxa in specific sample taxa.abund.cc1 &lt;- getAbundanceSample(tse, sample_id = &quot;CC1&quot;, assay_name = &quot;counts&quot;) taxa.abund.cc1[1:10] ## Class:Thermoprotei Class:Thermoprotei ## 0 0 ## Species:Sulfolobusacidocaldarius Class:Sd-NA ## 0 0 ## Class:Sd-NA Class:Sd-NA ## 0 0 ## Order:NRP-J Order:NRP-J ## 1 0 ## Order:NRP-J Order:NRP-J ## 194 5 6.5.2 Abundances of specific taxa in all samples taxa.abundances &lt;- getAbundanceFeature(tse, feature_id = &quot;Phylum:Bacteroidetes&quot;, assay_name = &quot;counts&quot;) taxa.abundances[1:10] ## CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr F21Plmr M31Tong M11Tong ## 2 18 2 0 0 0 0 1 0 0 Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] mia_1.7.11 MultiAssayExperiment_1.24.0 [3] TreeSummarizedExperiment_2.1.4 Biostrings_2.66.0 [5] XVector_0.38.0 SingleCellExperiment_1.20.1 [7] SummarizedExperiment_1.28.0 Biobase_2.58.0 [9] GenomicRanges_1.50.2 GenomeInfoDb_1.34.9 [11] IRanges_2.32.0 S4Vectors_0.36.2 [13] BiocGenerics_0.44.0 MatrixGenerics_1.10.0 [15] matrixStats_0.63.0-9003 BiocStyle_2.24.0 [17] rebook_1.6.0 loaded via a namespace (and not attached): [1] ggbeeswarm_0.7.1 colorspace_2.1-0 [3] scuttle_1.8.4 BiocNeighbors_1.16.0 [5] ggrepel_0.9.3 bit64_4.0.5 [7] fansi_1.0.4 decontam_1.18.0 [9] codetools_0.2-19 splines_4.2.1 [11] sparseMatrixStats_1.10.0 cachem_1.0.7 [13] knitr_1.42 scater_1.26.1 [15] jsonlite_1.8.4 cluster_2.1.4 [17] graph_1.74.0 BiocManager_1.30.20 [19] compiler_4.2.1 Matrix_1.5-4 [21] fastmap_1.1.1 lazyeval_0.2.2 [23] cli_3.6.1 BiocSingular_1.14.0 [25] htmltools_0.5.5 tools_4.2.1 [27] rsvd_1.0.5 gtable_0.3.3 [29] glue_1.6.2 GenomeInfoDbData_1.2.9 [31] reshape2_1.4.4 dplyr_1.1.1 [33] Rcpp_1.0.10 jquerylib_0.1.4 [35] vctrs_0.6.1 ape_5.7-1 [37] nlme_3.1-162 DECIPHER_2.26.0 [39] DelayedMatrixStats_1.20.0 xfun_0.38 [41] stringr_1.5.0 beachmat_2.14.0 [43] lifecycle_1.0.3 irlba_2.3.5.1 [45] XML_3.99-0.14 zlibbioc_1.44.0 [47] MASS_7.3-58.3 scales_1.2.1 [49] parallel_4.2.1 yaml_2.3.7 [51] memoise_2.0.1 gridExtra_2.3 [53] ggplot2_3.4.2 yulab.utils_0.0.6 [55] sass_0.4.5 stringi_1.7.12 [57] RSQLite_2.3.1 ScaledMatrix_1.6.0 [59] tidytree_0.4.2 permute_0.9-7 [61] filelock_1.0.2 BiocParallel_1.32.6 [63] rlang_1.1.0 pkgconfig_2.0.3 [65] bitops_1.0-7 evaluate_0.20 [67] lattice_0.21-8 purrr_1.0.1 [69] treeio_1.22.0 CodeDepends_0.6.5 [71] bit_4.0.5 tidyselect_1.2.0 [73] plyr_1.8.8 magrittr_2.0.3 [75] bookdown_0.33 R6_2.5.1 [77] generics_0.1.3 DelayedArray_0.24.0 [79] DBI_1.1.3 withr_2.5.0 [81] pillar_1.9.0 mgcv_1.8-42 [83] RCurl_1.98-1.12 tibble_3.2.1 [85] dir.expiry_1.4.0 crayon_1.5.2 [87] utf8_1.2.3 rmarkdown_2.21 [89] viridis_0.6.2 grid_4.2.1 [91] blob_1.2.4 vegan_2.6-4 [93] digest_0.6.31 tidyr_1.3.0 [95] munsell_0.5.0 DirichletMultinomial_1.40.0 [97] beeswarm_0.4.0 viridisLite_0.4.1 [99] vipor_0.4.5 bslib_0.4.2 Bibliography "],["community-diversity.html", "Chapter 7 Community diversity 7.1 Estimation 7.2 Visualization Session Info", " Chapter 7 Community diversity .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } Diversity estimates are a central topic in microbiome data analysis. There are three commonly employed levels of diversity measurements, which are trying to put a number on different aspects of the questions associated with diversity (Whittaker 1960). Many different ways for estimating such diversity measurements have been described in the literature. Which measurement is best or applicable for your samples, is not the aim of the following sections. library(mia) data(&quot;GlobalPatterns&quot;, package=&quot;mia&quot;) tse &lt;- GlobalPatterns Alpha diversity, also sometimes interchangeably used with the term species diversity, summarizes the distribution of species abundances in a given sample into a single number that depends on species richness and evenness. Diversity indices measure the overall community heterogeneity. A number of ecological diversity measures are available. The Hill coefficient combines many standard indices into a single equation that provides observed richness, inverse Simpson, and Shannon diversity, and generalized diversity as special cases. In general, diversity increases together with increasing richness and evenness. Sometimes richness, phylogenetic diversity, evenness, dominance, and rarity are considered to be variants of alpha diversity. Richness refers to the total number of species in a community (sample). The simplest richness index is the number of observed species (observed richness). Assuming limited sampling from the community, however, this may underestimate the true species richness. Several estimators are available, including for instance ACE (A and SM 1992) and Chao1 (A 1984). Richness estimates are unaffected by species abundances. Phylogenetic diversity was first proposed by (Faith 1992). Unlike the diversity measures mentioned above, Phylogenetic diversity (PD) measure incorporates information from phylogenetic relationships stored in phylo tree between species in a community (sample). The Faith’s PD is calculated as the sum of branch length of all species in a community (sample). Evenness focuses on species abundances, and can thus complement the number of species. A typical evenness index is the Pielou’s evenness, which is Shannon diversity normalized by the observed richness. Dominance indices are in general negatively correlated with diversity, and sometimes used in ecological literature. High dominance is obtained when one or few species have a high share of the total species abundance in the community. Rarity indices characterize the concentration of taxa at low abundance. Prevalence and detection thresholds determine rare taxa whose total concentration is represented as a rarity index. 7.1 Estimation Alpha diversity can be estimated with wrapper functions that interact with other packages implementing the calculation, such as vegan (Oksanen et al. 2020). 7.1.1 Richness Richness gives the number of features present within a community and can be calculated with estimateRichness. Each of the estimate diversity/richness/evenness/dominance functions adds the calculated measure(s) to the colData of the SummarizedExperiment under the given column name. Here, we calculate observed features as a measure of richness. tse &lt;- mia::estimateRichness(tse, assay_name = &quot;counts&quot;, index = &quot;observed&quot;, name=&quot;observed&quot;) head(colData(tse)$observed) ## CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr ## 6964 7679 5729 2667 2574 3214 This allows access to the values to be analyzed directly from the colData, for example by plotting them using plotColData from the scater package (McCarthy et al. 2020). library(scater) plotColData(tse, &quot;observed&quot;, &quot;SampleType&quot;, colour_by = &quot;Final_Barcode&quot;) + theme(axis.text.x = element_text(angle=45,hjust=1)) + ylab(expression(Richness[Observed])) Figure 7.1: Shannon diversity estimates plotted grouped by sample type with colour-labeled barcode. 7.1.2 Diversity The main function, estimateDiversity, calculates the selected diversity index based on the selected assay data. tse &lt;- mia::estimateDiversity(tse, assay_name = &quot;counts&quot;, index = &quot;shannon&quot;, name = &quot;shannon&quot;) head(colData(tse)$shannon) ## CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr ## 6.577 6.777 6.498 3.828 3.288 4.289 Alpha diversities can be visualized with boxplot. Here, Shannon index is compared between different sample type groups. Individual data points are visualized by plotting them as points with geom_jitter. geom_signif is used to test whether these differences are statistically significant. It adds p-values to plot. if( !require(ggsignif) ){ install.packages(&quot;ggsignif&quot;) } library(ggplot2) library(patchwork) library(ggsignif) # Subsets the data. Takes only those samples that are from feces, skin, or tongue, # and creates data frame from the collected data df &lt;- as.data.frame(colData(tse)[colData(tse)$SampleType %in% c(&quot;Feces&quot;, &quot;Skin&quot;, &quot;Tongue&quot;), ]) # Changes old levels with new levels df$SampleType &lt;- factor(df$SampleType) # For significance testing, all different combinations are determined comb &lt;- split(t(combn(levels(df$SampleType), 2)), seq(nrow(t(combn(levels(df$SampleType), 2))))) ggplot(df, aes(x = SampleType, y = shannon)) + # Outliers are removed, because otherwise each data point would be plotted twice; # as an outlier of boxplot and as a point of dotplot. geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.2) + geom_signif(comparisons = comb, map_signif_level = FALSE) + theme(text = element_text(size = 10)) 7.1.3 Faith phylogenetic diversity The Faith index is returned by the function estimateFaith. tse &lt;- mia::estimateFaith(tse, assay_name = &quot;counts&quot;) head(colData(tse)$faith) ## [1] 250.5 262.3 208.5 117.9 119.8 135.8 Note: because tse is a TreeSummarizedExperiment object, its phylogenetic tree is used by default. However, the optional argument tree must be provided if tse does not contain one. Below a visual comparison between shannon and faith indices is shown with a violin plot. plots &lt;- lapply(c(&quot;shannon&quot;, &quot;faith&quot;), plotColData, object = tse, colour_by = &quot;SampleType&quot;) plots[[1]] + plots[[2]] + plot_layout(guides = &quot;collect&quot;) Alternatively, the phylogenetic diversity can be calculated by mia::estimateDiversity. This is a faster re-implementation of the widely used function in picante W et al. (2010). Load picante R package and get the phylo stored in rowTree. tse &lt;- mia::estimateDiversity(tse, assay_name = &quot;counts&quot;, index = &quot;faith&quot;, name = &quot;faith&quot;) 7.1.4 Evenness Evenness can be calculated with estimateEvenness. tse &lt;- estimateEvenness(tse, assay_name = &quot;counts&quot;, index=&quot;simpson&quot;) head(colData(tse)$simpson) ## [1] 0.026871 0.027197 0.047049 0.005179 0.004304 0.005011 7.1.5 Dominance Dominance can be calculated with estimateDominance. Here, the Relative index is calculated which is the relative abundance of the most dominant species in the sample. tse &lt;- estimateDominance(tse, assay_name = &quot;counts&quot;, index=&quot;relative&quot;) head(colData(tse)$relative) ## CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr ## 0.03910 0.03226 0.01690 0.22981 0.21778 0.22329 7.1.6 Rarity mia package provides one rarity index called log-modulo skewness. It can be calculated with estimateDiversity. tse &lt;- mia::estimateDiversity(tse, assay_name = &quot;counts&quot;, index = &quot;log_modulo_skewness&quot;) head(colData(tse)$log_modulo_skewness) ## [1] 2.061 2.061 2.061 2.061 2.061 2.061 7.1.7 Divergence Divergence can be evaluated with estimateDivergence. Reference and algorithm for the calculation of divergence can be specified as reference and FUN, respectively. tse &lt;- mia::estimateDivergence(tse, assay_name = &quot;counts&quot;, reference = &quot;median&quot;, FUN = vegan::vegdist) 7.2 Visualization A plot comparing all the diversity measures calculated above and stored in colData can then be constructed directly. plots &lt;- lapply(c(&quot;observed&quot;, &quot;shannon&quot;, &quot;simpson&quot;, &quot;relative&quot;, &quot;faith&quot;, &quot;log_modulo_skewness&quot;), plotColData, object = tse, x = &quot;SampleType&quot;, colour_by = &quot;SampleType&quot;) plots &lt;- lapply(plots, &quot;+&quot;, theme(axis.text.x = element_blank(), axis.title.x = element_blank(), axis.ticks.x = element_blank())) ((plots[[1]] | plots[[2]] | plots[[3]]) / (plots[[4]] | plots[[5]] | plots[[6]])) + plot_layout(guides = &quot;collect&quot;) Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] patchwork_1.1.2 ggsignif_0.6.4 [3] scater_1.26.1 ggplot2_3.4.2 [5] scuttle_1.8.4 mia_1.7.11 [7] MultiAssayExperiment_1.24.0 TreeSummarizedExperiment_2.1.4 [9] Biostrings_2.66.0 XVector_0.38.0 [11] SingleCellExperiment_1.20.1 SummarizedExperiment_1.28.0 [13] Biobase_2.58.0 GenomicRanges_1.50.2 [15] GenomeInfoDb_1.34.9 IRanges_2.32.0 [17] S4Vectors_0.36.2 BiocGenerics_0.44.0 [19] MatrixGenerics_1.10.0 matrixStats_0.63.0-9003 [21] BiocStyle_2.24.0 rebook_1.6.0 loaded via a namespace (and not attached): [1] ggbeeswarm_0.7.1 colorspace_2.1-0 [3] BiocNeighbors_1.16.0 farver_2.1.1 [5] ggrepel_0.9.3 bit64_4.0.5 [7] fansi_1.0.4 decontam_1.18.0 [9] codetools_0.2-19 splines_4.2.1 [11] sparseMatrixStats_1.10.0 cachem_1.0.7 [13] knitr_1.42 jsonlite_1.8.4 [15] cluster_2.1.4 graph_1.74.0 [17] BiocManager_1.30.20 compiler_4.2.1 [19] Matrix_1.5-4 fastmap_1.1.1 [21] lazyeval_0.2.2 cli_3.6.1 [23] BiocSingular_1.14.0 htmltools_0.5.5 [25] tools_4.2.1 rsvd_1.0.5 [27] gtable_0.3.3 glue_1.6.2 [29] GenomeInfoDbData_1.2.9 reshape2_1.4.4 [31] dplyr_1.1.1 Rcpp_1.0.10 [33] jquerylib_0.1.4 vctrs_0.6.1 [35] ape_5.7-1 nlme_3.1-162 [37] DECIPHER_2.26.0 DelayedMatrixStats_1.20.0 [39] xfun_0.38 stringr_1.5.0 [41] beachmat_2.14.0 lifecycle_1.0.3 [43] irlba_2.3.5.1 XML_3.99-0.14 [45] zlibbioc_1.44.0 MASS_7.3-58.3 [47] scales_1.2.1 parallel_4.2.1 [49] yaml_2.3.7 memoise_2.0.1 [51] gridExtra_2.3 yulab.utils_0.0.6 [53] sass_0.4.5 stringi_1.7.12 [55] RSQLite_2.3.1 highr_0.10 [57] ScaledMatrix_1.6.0 tidytree_0.4.2 [59] permute_0.9-7 filelock_1.0.2 [61] BiocParallel_1.32.6 rlang_1.1.0 [63] pkgconfig_2.0.3 bitops_1.0-7 [65] evaluate_0.20 lattice_0.21-8 [67] purrr_1.0.1 labeling_0.4.2 [69] treeio_1.22.0 CodeDepends_0.6.5 [71] cowplot_1.1.1 bit_4.0.5 [73] tidyselect_1.2.0 plyr_1.8.8 [75] magrittr_2.0.3 bookdown_0.33 [77] R6_2.5.1 generics_0.1.3 [79] DelayedArray_0.24.0 DBI_1.1.3 [81] withr_2.5.0 pillar_1.9.0 [83] mgcv_1.8-42 RCurl_1.98-1.12 [85] tibble_3.2.1 dir.expiry_1.4.0 [87] crayon_1.5.2 utf8_1.2.3 [89] rmarkdown_2.21 viridis_0.6.2 [91] grid_4.2.1 blob_1.2.4 [93] vegan_2.6-4 digest_0.6.31 [95] tidyr_1.3.0 munsell_0.5.0 [97] DirichletMultinomial_1.40.0 beeswarm_0.4.0 [99] viridisLite_0.4.1 vipor_0.4.5 [101] bslib_0.4.2 .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } Bibliography "],["community-similarity.html", "Chapter 8 Community similarity 8.1 Explained variance 8.2 Community comparisons by beta diversity analysis 8.3 Other ordination methods 8.4 Visualizing the most dominant genus on PCoA 8.5 Further reading Session Info", " Chapter 8 Community similarity Where alpha diversity focuses on community variation within a community (sample), beta diversity quantifies (dis-)similarites between communities (samples). Some of the most popular beta diversity measures in microbiome research include Bray-Curtis index (for compositional data), Jaccard index (for presence / absence data, ignoring abundance information), Aitchison distance (Euclidean distance for clr transformed abundances, aiming to avoid the compositionality bias), and the Unifrac distances (that take into account the phylogenetic tree information). Only some of the commonly used beta diversity measures are actual distances; this is a mathematically well-defined concept and many ecological beta diversity measures, such as Bray-Curtis index, are not proper distances. Therefore, the term dissimilarity or beta diversity is commonly used. Technically, beta diversities are usually represented as dist objects, which contain triangular data describing the distance between each pair of samples. These distances can be further subjected to ordination. Ordination is a common concept in ecology that aims to reduce the dimensionality of the data for further evaluation or visualization. Ordination techniques aim to capture as much of essential information in the data as possible in a lower dimensional representation. Dimension reduction is bound to loose information but the common ordination techniques aim to preserve relevant information of sample similarities in an optimal way, which is defined in different ways by different methods. [TODO add references and/or link to ordination chapter instead?] Some of the most common ordination methods in microbiome research include Principal Component Analysis (PCA), metric and non-metric multi-dimensional scaling (MDS, NMDS), The MDS methods are also known as Principal Coordinates Analysis (PCoA). Other recently popular techniques include t-SNE and UMAP. 8.1 Explained variance The percentage of explained variance is typically shown for PCA ordination plots. This quantifies the proportion of overall variance in the data that is captured by the PCA axes, or how well the ordination axes reflect the original distances. Sometimes a similar measure is shown for MDS/PCoA. The interpretation is generally different, however, and hence we do not recommend using it. PCA is a special case of PCoA with Euclidean distances. With non-Euclidean dissimilarities PCoA uses a trick where the pointwise dissimilarities are first cast into similarities in a Euclidean space (with some information loss i.e. stress) and then projected to the maximal variance axes. In this case, the maximal variance axes do not directly reflect the correspondence of the projected distances and original distances, as they do for PCA. In typical use cases, we would like to know how well the ordination reflects the original similarity structures; then the quantity of interest is the so-called “stress” function, which measures the difference in pairwise similarities between the data points in the original (high-dimensional) vs. projected (low-dimensional) space. Hence, we propose that for PCoA and other ordination methods, users would report relative stress (varies in the unit interval; the smaller the better). This can be calculated as shown below. For further examples, check the note from Huber lab. # Example data library(mia) data(GlobalPatterns, package=&quot;mia&quot;) # Data matrix (features x samples) tse &lt;- GlobalPatterns tse &lt;- transformCounts(tse, method = &quot;relabundance&quot;) # Add group information Feces yes/no colData(tse)$Group &lt;- colData(tse)$SampleType==&quot;Feces&quot; # Quantify dissimilarities in the original feature space library(vegan) x &lt;- assay(tse, &quot;relabundance&quot;) # Pick relabunance assay separately d0 &lt;- as.matrix(vegdist(t(x), &quot;bray&quot;)) # PCoA Ordination pcoa &lt;- as.data.frame(cmdscale(d0, k = 2)) names(pcoa) &lt;- c(&quot;PCoA1&quot;, &quot;PCoA2&quot;) # Quantify dissimilarities in the ordination space dp &lt;- as.matrix(dist(pcoa)) # Calculate stress i.e. relative difference in the original and # projected dissimilarities stress &lt;- sum((dp - d0)^2)/sum(d0^2) Shepard plot visualizes the original versus projected (ordination) dissimilarities between the data points: ord &lt;- order(as.vector(d0)) df &lt;- data.frame(d0 = as.vector(d0)[ord], dmds = as.vector(dp)[ord]) library(ggplot2) ggplot(aes(x = d0, y = dmds), data=df) + geom_smooth() + geom_point() + labs(title = &quot;Shepard plot&quot;, x = &quot;Original distance&quot;, y = &quot;MDS distance&quot;, subtitle = paste(&quot;Stress:&quot;, round(stress, 2))) + theme_bw() 8.2 Community comparisons by beta diversity analysis A typical comparison of community composition starts with a visual comparison of the groups on a 2D ordination. Then we estimate relative abundances and MDS ordination based on Bray-Curtis (BC) dissimilarity between the groups, and visualize the results. In the following examples dissimilarities are calculated by functions supplied to the FUN argument. This function can be defined by the user. It must return a dist function, which can then be used to calculate reduced dimensions either via ordination methods (such as MDS or NMDS), and the results can be stored in the reducedDim. This entire process is wrapped in the runMDS and runNMDS functions. library(scater) # Bray-Curtis is usually applied to relative abundances tse &lt;- transformCounts(tse, method = &quot;relabundance&quot;) # Perform PCoA tse &lt;- runMDS(tse, FUN = vegan::vegdist, method = &quot;bray&quot;, name = &quot;PCoA_BC&quot;, exprs_values = &quot;relabundance&quot;) Sample similarities can be visualized on a lower-dimensional display (typically 2D) using the plotReducedDim function in the scater package. This provides also further tools to incorporate additional information using variations in color, shape or size. Are there visible differences between the groups? # Create ggplot object p &lt;- plotReducedDim(tse, &quot;PCoA_BC&quot;, colour_by = &quot;Group&quot;) # Add explained variance for each axis e &lt;- attr(reducedDim(tse, &quot;PCoA_BC&quot;), &quot;eig&quot;); rel_eig &lt;- e/sum(e[e&gt;0]) p &lt;- p + labs(x = paste(&quot;PCoA 1 (&quot;, round(100 * rel_eig[[1]],1), &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;), y = paste(&quot;PCoA 2 (&quot;, round(100 * rel_eig[[2]],1), &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;)) print(p) Figure 8.1: MDS plot based on the Bray-Curtis distances on the GlobalPattern dataset. With additional tools from the ggplot2 universe, comparisons can be performed informing on the applicability to visualize sample similarities in a meaningful way. tse &lt;- runMDS(tse, FUN = vegan::vegdist, name = &quot;MDS_euclidean&quot;, method = &quot;euclidean&quot;, exprs_values = &quot;counts&quot;) tse &lt;- runNMDS(tse, FUN = vegan::vegdist, name = &quot;NMDS_BC&quot;) ## initial value 47.733208 ## iter 5 value 33.853364 ## iter 10 value 32.891200 ## final value 32.823570 ## converged tse &lt;- runNMDS(tse, FUN = vegan::vegdist, name = &quot;NMDS_euclidean&quot;, method = &quot;euclidean&quot;) ## initial value 31.882673 ## final value 31.882673 ## converged plots &lt;- lapply(c(&quot;PCoA_BC&quot;, &quot;MDS_euclidean&quot;, &quot;NMDS_BC&quot;, &quot;NMDS_euclidean&quot;), plotReducedDim, object = tse, colour_by = &quot;Group&quot;) library(patchwork) plots[[1]] + plots[[2]] + plots[[3]] + plots[[4]] + plot_layout(guides = &quot;collect&quot;) Figure 8.2: Comparison of MDS and NMDS plots based on the Bray-Curtis or euclidean distances on the GlobalPattern dataset. The Unifrac method is a special case, as it requires data on the relationship of features in form on a phylo tree. calculateUnifrac performs the calculation to return a dist object, which can again be used within runMDS. library(scater) tse &lt;- runMDS(tse, FUN = mia::calculateUnifrac, name = &quot;Unifrac&quot;, tree = rowTree(tse), ntop = nrow(tse), exprs_values = &quot;counts&quot;) plotReducedDim(tse, &quot;Unifrac&quot;, colour_by = &quot;Group&quot;) Figure 8.3: Unifrac distances scaled by MDS of the GlobalPattern dataset. 8.3 Other ordination methods Other dimension reduction methods, such as PCA, t-SNE and UMAP are inherited directly from the scater package. tse &lt;- runPCA(tse, name = &quot;PCA&quot;, exprs_values = &quot;counts&quot;, ncomponents = 10) plotReducedDim(tse, &quot;PCA&quot;, colour_by = &quot;Group&quot;) Figure 8.4: PCA plot on the GlobalPatterns data set containing sample from different sources. As mentioned before, applicability of the different methods depends on your sample set. FIXME: let us switch to UMAP for the examples? tse &lt;- runTSNE(tse, name = &quot;TSNE&quot;, exprs_values = &quot;counts&quot;, ncomponents = 3) plotReducedDim(tse, &quot;TSNE&quot;, colour_by = &quot;Group&quot;, ncomponents = c(1:3)) Figure 8.5: t-SNE plot on the GlobalPatterns data set containing sample from different sources. As a final note, mia provides functions for the evaluation of additional dissimilarity indices, such as: * calculateJSD, runJSD (Jensen-Shannon divergence) * calculateNMDS, plotNMDS (non-metric multi-dimensional scaling) * calculateCCA, runCCA (Canonical Correspondence Analysis) * calculateRDA, runRDA (Redundancy Analysis) * calculateOverlap, runOverlap () * calculateDPCoA, runDPCoA (Double Principal Coordinate Analysis) Redundancy analysis is similar to PCA, however, it takes into account covariates. It aims to maximize the variance in respect of covariates. The results shows how much each covariate affects. # Load required packages if(!require(&quot;vegan&quot;)){ install.packages(&quot;vegan&quot;) library(&quot;vegan&quot;) } if(!require(&quot;stringr&quot;)){ install.packages(&quot;stringr&quot;) library(&quot;stringr&quot;) } if(!require(&quot;knitr&quot;)){ install.packages(&quot;knitr&quot;) library(&quot;knitr&quot;) } # Load data data(enterotype, package=&quot;mia&quot;) # Covariates that are being analyzed variable_names &lt;- c(&quot;ClinicalStatus&quot;, &quot;Gender&quot;, &quot;Age&quot;) # Apply relative transform enterotype &lt;- transformCounts(enterotype, method = &quot;relabundance&quot;) # Create a formula formula &lt;- as.formula(paste0(&quot;assay ~ &quot;, str_c(variable_names, collapse = &quot; + &quot;)) ) # # Perform RDA rda &lt;- calculateRDA(enterotype, assay_name = &quot;relabundance&quot;, formula = formula, distance = &quot;bray&quot;, na.action = na.exclude) # Get the rda object rda &lt;- attr(rda, &quot;rda&quot;) # Calculate p-value and variance for whole model # Recommendation: use 999 permutations instead of 99 set.seed(436) permanova &lt;- anova.cca(rda, permutations = 99) # Create a data.frame for results rda_info &lt;- as.data.frame(permanova)[&quot;Model&quot;, ] # Calculate p-value and variance for each variable # by = &quot;margin&quot; --&gt; the order or variables does not matter set.seed(4585) permanova &lt;- anova.cca(rda, by = &quot;margin&quot;, permutations = 99) # Add results to data.frame rda_info &lt;- rbind(rda_info, permanova) # Add info about total variance rda_info[ , &quot;Total variance&quot;] &lt;- rda_info[&quot;Model&quot;, 2] + rda_info[&quot;Residual&quot;, 2] # Add info about explained variance rda_info[ , &quot;Explained variance&quot;] &lt;- rda_info[ , 2] / rda_info[ , &quot;Total variance&quot;] # Loop through variables, calculate homogeneity homogeneity &lt;- list() # Get colDtaa coldata &lt;- colData(enterotype) # Get assay assay &lt;- t(assay(enterotype, &quot;relabundance&quot;)) for( variable_name in rownames(rda_info) ){ # If data is continuous or discrete if( variable_name %in% c(&quot;Model&quot;, &quot;Residual&quot;) || length(unique(coldata[[variable_name]])) / length(coldata[[variable_name]]) &gt; 0.2 ){ # Do not calculate homogeneity for continuous data temp &lt;- NA } else{ # Calculate homogeneity for discrete data # Calculate homogeneity set.seed(413) temp &lt;- anova( betadisper( vegdist(assay, method = &quot;bray&quot;), group = coldata[[variable_name]] ), permutations = permutations )[&quot;Groups&quot;, &quot;Pr(&gt;F)&quot;] } # Add info to the list homogeneity[[variable_name]] &lt;- temp } # Add homogeneity to information rda_info[[&quot;Homogeneity p-value (NULL hyp: distinct/homogeneous --&gt; permanova suitable)&quot;]] &lt;- homogeneity kable(rda_info) Df SumOfSqs F Pr(&gt;F) Total variance Explained variance Homogeneity p-value (NULL hyp: distinct/homogeneous –&gt; permanova suitable) Model 6 1.1157 1.940 0.05 3.991 0.2795 NA ClinicalStatus 4 0.5837 1.522 0.15 3.991 0.1463 0.044277…. Gender 1 0.1679 1.751 0.10 3.991 0.0421 0.522999…. Age 1 0.5245 5.471 0.01 3.991 0.1314 0.000369…. Residual 30 2.8757 NA NA 3.991 0.7205 NA # Load ggord for plotting if(!require(&quot;ggord&quot;)){ if(!require(&quot;devtools&quot;)){ install.packages(&quot;devtools&quot;) library(&quot;devtools&quot;) } install_github(&quot;https://github.com/fawda123/ggord/&quot;) library(&quot;ggord&quot;) } if(!require(&quot;ggplot2&quot;)){ install.packages(&quot;ggplot2&quot;) library(&quot;ggplot2&quot;) } # Since na.exclude was used, if there were rows missing information, they were # dropped off. Subset coldata so that it matches with rda. coldata &lt;- coldata[ rownames(rda$CCA$wa), ] # Adjust names # Get labels of vectors vec_lab_old &lt;- rownames(rda$CCA$biplot) # Loop through vector labels vec_lab &lt;- sapply(vec_lab_old, FUN = function(name){ # Get the variable name variable_name &lt;- variable_names[ str_detect(name, variable_names) ] # If the vector label includes also group name if( !any(name %in% variable_names) ){ # Get the group names group_name &lt;- unique( coldata[[variable_name]] )[ which( paste0(variable_name, unique( coldata[[variable_name]] )) == name ) ] # Modify vector so that group is separated from variable name new_name &lt;- paste0(variable_name, &quot; \\U2012 &quot;, group_name) } else{ new_name &lt;- name } # Add percentage how much this variable explains, and p-value new_name &lt;- expr(paste(!!new_name, &quot; (&quot;, !!format(round( rda_info[variable_name, &quot;Explained variance&quot;]*100, 1), nsmall = 1), &quot;%, &quot;,italic(&quot;P&quot;), &quot; = &quot;, !!gsub(&quot;0\\\\.&quot;,&quot;\\\\.&quot;, format(round( rda_info[variable_name, &quot;Pr(&gt;F)&quot;], 3), nsmall = 3)), &quot;)&quot;)) return(new_name) }) # Add names names(vec_lab) &lt;- vec_lab_old # Create labels for axis xlab &lt;- paste0(&quot;RDA1 (&quot;, format(round( rda$CCA$eig[[1]]/rda$CCA$tot.chi*100, 1), nsmall = 1 ), &quot;%)&quot;) ylab &lt;- paste0(&quot;RDA2 (&quot;, format(round( rda$CCA$eig[[2]]/rda$CCA$tot.chi*100, 1), nsmall = 1 ), &quot;%)&quot;) # Create a plot plot &lt;- ggord(rda, grp_in = coldata[[&quot;ClinicalStatus&quot;]], vec_lab = vec_lab, alpha = 0.5, size = 4, addsize = -4, #ext= 0.7, txt = 3.5, repel = TRUE, #coord_fix = FALSE ) + # Adjust titles and labels guides(colour = guide_legend(&quot;ClinicalStatus&quot;), fill = guide_legend(&quot;ClinicalStatus&quot;), group = guide_legend(&quot;ClinicalStatus&quot;), shape = guide_legend(&quot;ClinicalStatus&quot;), x = guide_axis(xlab), y = guide_axis(ylab)) + theme( axis.title = element_text(size = 10) ) plot From RDA plot, we can see that only age has significant affect on microbial profile. 8.4 Visualizing the most dominant genus on PCoA In this section we visualize most dominant genus on PCoA. A similar visualization was proposed by Salosensaari et al. (2021). Let us agglomerate the data at a Genus level and getting the dominant taxa per sample. # Agglomerate to genus level tse_Genus &lt;- agglomerateByRank(tse, rank=&quot;Genus&quot;) # Convert to relative abundances tse_Genus &lt;- transformCounts(tse, method = &quot;relabundance&quot;, assay_name=&quot;counts&quot;) # Add info on dominant genus per sample tse_Genus &lt;- addPerSampleDominantTaxa(tse_Genus, assay_name=&quot;relabundance&quot;, name = &quot;dominant_taxa&quot;) Performing PCoA with Bray-Curtis dissimilarity. tse_Genus &lt;- runMDS(tse_Genus, FUN = vegan::vegdist, name = &quot;PCoA_BC&quot;, exprs_values = &quot;relabundance&quot;) Getting top taxa and visualizing the abundance on PCoA. # Getting the top taxa top_taxa &lt;- getTopTaxa(tse_Genus,top = 6, assay_name = &quot;relabundance&quot;) # Naming all the rest of non top-taxa as &quot;Other&quot; most_abundant &lt;- lapply(colData(tse_Genus)$dominant_taxa, function(x){if (x %in% top_taxa) {x} else {&quot;Other&quot;}}) # Storing the previous results as a new column within colData colData(tse_Genus)$most_abundant &lt;- as.character(most_abundant) # Calculating percentage of the most abundant most_abundant_freq &lt;- table(as.character(most_abundant)) most_abundant_percent &lt;- round(most_abundant_freq/sum(most_abundant_freq)*100, 1) # Retrieving the explained variance e &lt;- attr(reducedDim(tse_Genus, &quot;PCoA_BC&quot;), &quot;eig&quot;); var_explained &lt;- e/sum(e[e&gt;0])*100 # Visualization plot &lt;-plotReducedDim(tse_Genus,&quot;PCoA_BC&quot;, colour_by = &quot;most_abundant&quot;) + scale_colour_manual(values = c(&quot;black&quot;, &quot;blue&quot;, &quot;lightblue&quot;, &quot;darkgray&quot;, &quot;magenta&quot;, &quot;darkgreen&quot;, &quot;red&quot;), labels=paste0(names(most_abundant_percent),&quot;(&quot;,most_abundant_percent,&quot;%)&quot;))+ labs(x=paste(&quot;PC 1 (&quot;,round(var_explained[1],1),&quot;%)&quot;), y=paste(&quot;PC 2 (&quot;,round(var_explained[2],1),&quot;%)&quot;), color=&quot;&quot;) plot Note: A 3D interactive version of the earlier plot can be found from 18. Similarly let’s visualize and compare the sub-population. # Calculating the frequencies and percentages for both categories freq_TRUE &lt;- table(as.character(most_abundant[colData(tse_Genus)$Group==TRUE])) freq_FALSE &lt;- table(as.character(most_abundant[colData(tse_Genus)$Group==FALSE])) percent_TRUE &lt;- round(freq_TRUE/sum(freq_TRUE)*100, 1) percent_FALSE &lt;- round(freq_FALSE/sum(freq_FALSE)*100, 1) # Visualization plotReducedDim(tse_Genus[,colData(tse_Genus)$Group==TRUE], &quot;PCoA_BC&quot;, colour_by = &quot;most_abundant&quot;) + scale_colour_manual(values = c(&quot;black&quot;, &quot;blue&quot;, &quot;lightblue&quot;, &quot;darkgray&quot;, &quot;magenta&quot;, &quot;darkgreen&quot;, &quot;red&quot;), labels=paste0(names(percent_TRUE),&quot;(&quot;,percent_TRUE,&quot;%)&quot;))+ labs(x=paste(&quot;PC 1 (&quot;,round(var_explained[1],1),&quot;%)&quot;), y=paste(&quot;PC 2 (&quot;,round(var_explained[2],1),&quot;%)&quot;), title = &quot;Group = TRUE&quot;, color=&quot;&quot;) plotReducedDim(tse_Genus[,colData(tse_Genus)$Group==FALSE], &quot;PCoA_BC&quot;, colour_by = &quot;most_abundant&quot;) + scale_colour_manual(values = c(&quot;black&quot;, &quot;blue&quot;, &quot;lightblue&quot;, &quot;darkgray&quot;, &quot;magenta&quot;, &quot;darkgreen&quot;, &quot;red&quot;), labels=paste0(names(percent_FALSE),&quot;(&quot;,percent_FALSE,&quot;%)&quot;))+ labs(x=paste(&quot;PC 1 (&quot;,round(var_explained[1],1),&quot;%)&quot;), y=paste(&quot;PC 2 (&quot;,round(var_explained[2],1),&quot;%)&quot;), title = &quot;Group = FALSE&quot;, color=&quot;&quot;) 8.4.1 Testing differences in community composition between sample groups The permutational analysis of variance (PERMANOVA) (Anderson 2001) is a widely used non-parametric multivariate method that can be used to estimate the actual statistical significance of differences in the observed community composition between two groups of samples. PERMANOVA evaluates the hypothesis that the centroids and dispersion of the community are equivalent between the compared groups. A small p-value indicates that the compared groups have, on average, a different community composition. This method is implemented in the vegan package in the function adonis2. Note: It is recommended to by = \"margin\". It specifies that each variable’s marginal effect is analyzed individually. When by = \"terms\" (the default) the order of variables matters; each variable is analyzed sequentially, and the result is different when more than 1 variable is introduced and their order is differs. (Check comparison) We can perform PERMANOVA with adonis2 function or by first performing distance-based redundancy analysis (dbRDA), and then applying permutational test for result of redundancy analysis. Advantage of the latter approach is that by doing so we can get coefficients: how much each taxa affect to the result. if( !require(vegan) ){ BiocManager::install(&quot;vegan&quot;) library(&quot;vegan&quot;) } # Agglomerate data to Species level tse &lt;- agglomerateByRank(tse, rank = &quot;Species&quot;) # Set seed for reproducibility set.seed(1576) # We choose 99 random permutations. Consider applying more (999 or 9999) in your # analysis. permanova &lt;- adonis2(t(assay(tse,&quot;relabundance&quot;)) ~ Group, by = &quot;margin&quot;, # each term (here only &#39;Group&#39;) analyzed individually data = colData(tse), method = &quot;euclidean&quot;, permutations = 99) # Set seed for reproducibility set.seed(1576) # Perform dbRDA dbrda &lt;- dbrda(t(assay(tse,&quot;relabundance&quot;)) ~ Group, data = colData(tse)) # Perform permutational analysis permanova2 &lt;- anova.cca(dbrda, by = &quot;margin&quot;, # each term (here only &#39;Group&#39;) analyzed individually method = &quot;euclidean&quot;, permutations = 99) # Get p-values p_values &lt;- c( permanova[&quot;Group&quot;, &quot;Pr(&gt;F)&quot;], permanova2[&quot;Group&quot;, &quot;Pr(&gt;F)&quot;] ) p_values &lt;-as.data.frame(p_values) rownames(p_values) &lt;- c(&quot;adonis2&quot;, &quot;dbRDA+anova.cca&quot;) p_values ## p_values ## adonis2 0.02 ## dbRDA+anova.cca 0.02 As we can see, the community composition is significantly different between the groups (p &lt; 0.05), and these two methods give equal p-values. Let us visualize the model coefficients for species that exhibit the largest differences between the groups. This gives some insights into how the groups tend to differ from each other in terms of community composition. # Add taxa info sppscores(dbrda) &lt;- t(assay(tse,&quot;relabundance&quot;)) # Get coefficients coef &lt;- dbrda$CCA$v # Get the taxa with biggest weights top.coef &lt;- head( coef[rev(order(abs(coef))), , drop = FALSE], 20) # Sort weights in increasing order top.coef &lt;- top.coef[ order(top.coef), ] # Get top names top_names &lt;- names(top.coef)[ order(abs(top.coef), decreasing = TRUE) ] ggplot(data.frame(x = top.coef, y = factor(names(top.coef), unique(names(top.coef)))), aes(x = x, y = y)) + geom_bar(stat=&quot;identity&quot;) + labs(x=&quot;&quot;,y=&quot;&quot;,title=&quot;Top Taxa&quot;) + theme_bw() In the above example, the largest differences between the two groups can be attributed to Genus:Bacteroides (elevated in the first group) and Family:Ruminococcaceae (elevated in the second group), and many other co-varying species. 8.4.2 Checking the homogeneity condition It is important to note that the application of PERMANOVA assumes homogeneous group dispersions (variances). This can be tested with the PERMDISP2 method (Anderson 2006) by using the same assay and distance method than in PERMANOVA. anova( betadisper(vegdist(t(assay(tse, &quot;counts&quot;))), colData(tse)$Group) ) ## Analysis of Variance Table ## ## Response: Distances ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Groups 1 0.2385 0.2385 103 3.6e-10 *** ## Residuals 24 0.0554 0.0023 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 If the groups have similar dispersion, PERMANOVA can be seen as an appropriate choice for comparing community compositions. 8.5 Further reading How to extract information from clusters Chapter 10 on community typing Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] ggord_1.1.7 knitr_1.42 [3] stringr_1.5.0 patchwork_1.1.2 [5] scater_1.26.1 scuttle_1.8.4 [7] ggplot2_3.4.2 vegan_2.6-4 [9] lattice_0.21-8 permute_0.9-7 [11] mia_1.7.11 MultiAssayExperiment_1.24.0 [13] TreeSummarizedExperiment_2.1.4 Biostrings_2.66.0 [15] XVector_0.38.0 SingleCellExperiment_1.20.1 [17] SummarizedExperiment_1.28.0 Biobase_2.58.0 [19] GenomicRanges_1.50.2 GenomeInfoDb_1.34.9 [21] IRanges_2.32.0 S4Vectors_0.36.2 [23] BiocGenerics_0.44.0 MatrixGenerics_1.10.0 [25] matrixStats_0.63.0-9003 BiocStyle_2.24.0 [27] rebook_1.6.0 loaded via a namespace (and not attached): [1] Rtsne_0.16 ggbeeswarm_0.7.1 [3] colorspace_2.1-0 BiocNeighbors_1.16.0 [5] farver_2.1.1 ggrepel_0.9.3 [7] bit64_4.0.5 fansi_1.0.4 [9] decontam_1.18.0 codetools_0.2-19 [11] splines_4.2.1 sparseMatrixStats_1.10.0 [13] cachem_1.0.7 jsonlite_1.8.4 [15] cluster_2.1.4 graph_1.74.0 [17] BiocManager_1.30.20 compiler_4.2.1 [19] Matrix_1.5-4 fastmap_1.1.1 [21] lazyeval_0.2.2 cli_3.6.1 [23] BiocSingular_1.14.0 htmltools_0.5.5 [25] tools_4.2.1 rsvd_1.0.5 [27] gtable_0.3.3 glue_1.6.2 [29] GenomeInfoDbData_1.2.9 reshape2_1.4.4 [31] dplyr_1.1.1 Rcpp_1.0.10 [33] jquerylib_0.1.4 vctrs_0.6.1 [35] ape_5.7-1 nlme_3.1-162 [37] DECIPHER_2.26.0 DelayedMatrixStats_1.20.0 [39] xfun_0.38 beachmat_2.14.0 [41] lifecycle_1.0.3 irlba_2.3.5.1 [43] XML_3.99-0.14 zlibbioc_1.44.0 [45] MASS_7.3-58.3 scales_1.2.1 [47] parallel_4.2.1 yaml_2.3.7 [49] memoise_2.0.1 gridExtra_2.3 [51] yulab.utils_0.0.6 sass_0.4.5 [53] stringi_1.7.12 RSQLite_2.3.1 [55] highr_0.10 ScaledMatrix_1.6.0 [57] tidytree_0.4.2 filelock_1.0.2 [59] BiocParallel_1.32.6 rlang_1.1.0 [61] pkgconfig_2.0.3 bitops_1.0-7 [63] evaluate_0.20 purrr_1.0.1 [65] labeling_0.4.2 treeio_1.22.0 [67] CodeDepends_0.6.5 cowplot_1.1.1 [69] bit_4.0.5 tidyselect_1.2.0 [71] plyr_1.8.8 magrittr_2.0.3 [73] bookdown_0.33 R6_2.5.1 [75] generics_0.1.3 DelayedArray_0.24.0 [77] DBI_1.1.3 withr_2.5.0 [79] pillar_1.9.0 mgcv_1.8-42 [81] RCurl_1.98-1.12 tibble_3.2.1 [83] dir.expiry_1.4.0 crayon_1.5.2 [85] utf8_1.2.3 rmarkdown_2.21 [87] viridis_0.6.2 grid_4.2.1 [89] blob_1.2.4 digest_0.6.31 [91] tidyr_1.3.0 munsell_0.5.0 [93] DirichletMultinomial_1.40.0 beeswarm_0.4.0 [95] viridisLite_0.4.1 vipor_0.4.5 [97] bslib_0.4.2 Bibliography "],["microbiome-community.html", "Chapter 9 Community composition 9.1 Visualizing taxonomic composition Session Info", " Chapter 9 Community composition .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } library(mia) data(&quot;GlobalPatterns&quot;, package=&quot;mia&quot;) tse &lt;- GlobalPatterns 9.1 Visualizing taxonomic composition 9.1.1 Composition barplot A typical way to visualize microbiome composition is by using composition barplot. In the following, relative abundance is calculated and top taxa are retrieved for the Phylum rank. Thereafter, the barplot is visualized ordering rank by abundance values and samples by “Bacteroidetes”: library(miaViz) # Computing relative abundance tse &lt;- relAbundanceCounts(tse) # Getting top taxa on a Phylum level tse_phylum &lt;- agglomerateByRank(tse, rank =&quot;Phylum&quot;, onRankOnly=TRUE) top_taxa &lt;- getTopTaxa(tse_phylum,top = 5, assay_name = &quot;relabundance&quot;) # Renaming the &quot;Phylum&quot; rank to keep only top taxa and the rest to &quot;Other&quot; phylum_renamed &lt;- lapply(rowData(tse)$Phylum, function(x){if (x %in% top_taxa) {x} else {&quot;Other&quot;}}) rowData(tse)$Phylum &lt;- as.character(phylum_renamed) # Visualizing the composition barplot, with samples order by &quot;Bacteroidetes&quot; plotAbundance(tse, assay_name=&quot;relabundance&quot;, rank = &quot;Phylum&quot;, order_rank_by=&quot;abund&quot;, order_sample_by = &quot;Bacteroidetes&quot;) 9.1.2 Composition heatmap Community composition can be visualized with heatmap, where the horizontal axis represents samples and the vertical axis the taxa. Color of each intersection point represents abundance of a taxon in a specific sample. Here, abundances are first CLR (centered log-ratio) transformed to remove compositionality bias. Then Z transformation is applied to CLR-transformed data. This shifts all taxa to zero mean and unit variance, allowing visual comparison between taxa that have different absolute abundance levels. After these rough visual exploration techniques, we can visualize the abundances at Phylum level. library(ggplot2) # Add clr-transformation on samples assay(tse_phylum, &quot;pseudo&quot;) &lt;- assay(tse_phylum, &quot;counts&quot;) + 1 tse_phylum &lt;- transformCounts(tse_phylum, assay_name = &quot;pseudo&quot;, method = &quot;relabundance&quot;) tse_phylum &lt;- transformCounts(tse_phylum, assay_name = &quot;relabundance&quot;, method = &quot;clr&quot;) # Add z-transformation on features (taxa) tse_phylum &lt;- transformCounts(tse_phylum, assay_name = &quot;clr&quot;, MARGIN = &quot;features&quot;, method = &quot;z&quot;, name = &quot;clr_z&quot;) Visualize as heatmap. # Melt the assay for plotting purposes df &lt;- meltAssay(tse_phylum, assay_name = &quot;clr_z&quot;) # Determines the scaling of colours maxval &lt;- round(max(abs(df$clr_z))) limits &lt;- c(-maxval, maxval) breaks &lt;- seq(from = min(limits), to = max(limits), by = 0.5) colours &lt;- c(&quot;darkblue&quot;, &quot;blue&quot;, &quot;white&quot;, &quot;red&quot;, &quot;darkred&quot;) # Creates a ggplot object ggplot(df, aes(x = SampleID, y = FeatureID, fill = clr_z)) + geom_tile() + scale_fill_gradientn(name = &quot;CLR + Z transform&quot;, breaks = breaks, limits = limits, colours = colours) + theme(text = element_text(size=10), axis.text.x = element_text(angle=45, hjust=1), legend.key.size = unit(1, &quot;cm&quot;)) + labs(x = &quot;Samples&quot;, y = &quot;Taxa&quot;) pheatmap is a package that provides methods to plot clustered heatmaps. if(!require(pheatmap)){install.packages(&quot;pheatmap&quot;); library(pheatmap)} # Takes subset: only samples from feces, skin, or tongue tse_phylum_subset &lt;- tse_phylum[ , colData(tse_phylum)$SampleType %in% c(&quot;Feces&quot;, &quot;Skin&quot;, &quot;Tongue&quot;) ] # Add clr-transformation tse_phylum_subset &lt;- transformCounts(tse_phylum_subset, method = &quot;clr&quot;, pseudocount = 1) tse_phylum_subset &lt;- transformCounts(tse_phylum_subset, assay_name = &quot;clr&quot;, MARGIN = &quot;features&quot;, method = &quot;z&quot;, name = &quot;clr_z&quot;) # Get n most abundant taxa, and subsets the data by them top_taxa &lt;- getTopTaxa(tse_phylum_subset, top = 20) tse_phylum_subset &lt;- tse_phylum_subset[top_taxa, ] # Gets the assay table mat &lt;- assay(tse_phylum_subset, &quot;clr_z&quot;) # Creates the heatmap pheatmap(mat) We can create clusters by hierarchical clustering and add them to the plot. if(!require(ape)){ install.packages(&quot;ape&quot;) library(ape) } # Hierarchical clustering taxa_hclust &lt;- hclust(dist(mat), method = &quot;complete&quot;) # Creates a phylogenetic tree taxa_tree &lt;- as.phylo(taxa_hclust) if(!require(ggtree)){ install.packages(&quot;ggtree&quot;) library(ggtree) } # Plot taxa tree taxa_tree &lt;- ggtree(taxa_tree) + theme(plot.margin=margin(0,0,0,0)) # removes margins # Get order of taxa in plot taxa_ordered &lt;- get_taxa_name(taxa_tree) taxa_tree Based on phylo tree, we decide to create three clusters. # Creates clusters taxa_clusters &lt;- cutree(tree = taxa_hclust, k = 3) # Converts into data frame taxa_clusters &lt;- data.frame(clusters = taxa_clusters) taxa_clusters$clusters &lt;- factor(taxa_clusters$clusters) # Order data so that it&#39;s same as in phylo tree taxa_clusters &lt;- taxa_clusters[taxa_ordered, , drop = FALSE] # Prints taxa and their clusters taxa_clusters ## clusters ## Chloroflexi 3 ## Actinobacteria 3 ## Crenarchaeota 3 ## Planctomycetes 3 ## Gemmatimonadetes 3 ## Thermi 3 ## Acidobacteria 3 ## Spirochaetes 2 ## Fusobacteria 2 ## SR1 2 ## Cyanobacteria 2 ## Proteobacteria 2 ## Synergistetes 2 ## Lentisphaerae 1 ## Bacteroidetes 1 ## Verrucomicrobia 1 ## Tenericutes 1 ## Firmicutes 1 ## Euryarchaeota 1 ## SAR406 1 # Adds information to rowData rowData(tse_phylum_subset)$clusters &lt;- taxa_clusters[order(match(rownames(taxa_clusters), rownames(tse_phylum_subset))), ] # Prints taxa and their clusters rowData(tse_phylum_subset)$clusters ## [1] 1 1 2 3 2 2 1 1 1 1 3 2 3 3 3 2 2 3 3 1 ## Levels: 1 2 3 # Hierarchical clustering sample_hclust &lt;- hclust(dist(t(mat)), method = &quot;complete&quot;) # Creates a phylogenetic tree sample_tree &lt;- as.phylo(sample_hclust) # Plot sample tree sample_tree &lt;- ggtree(sample_tree) + layout_dendrogram() + theme(plot.margin=margin(0,0,0,0)) # removes margins # Get order of samples in plot samples_ordered &lt;- rev(get_taxa_name(sample_tree)) sample_tree # Creates clusters sample_clusters &lt;- factor(cutree(tree = sample_hclust, k = 3)) # Converts into data frame sample_data &lt;- data.frame(clusters = sample_clusters) # Order data so that it&#39;s same as in phylo tree sample_data &lt;- sample_data[samples_ordered, , drop = FALSE] # Order data based on tse_phylum_subset &lt;- tse_phylum_subset[ , rownames(sample_data)] # Add sample type data sample_data$sample_types &lt;- unfactor(colData(tse_phylum_subset)$SampleType) sample_data ## clusters sample_types ## M11Plmr 2 Skin ## M31Plmr 2 Skin ## F21Plmr 2 Skin ## M31Fcsw 1 Feces ## M11Fcsw 1 Feces ## TS28 3 Feces ## TS29 3 Feces ## M31Tong 3 Tongue ## M11Tong 3 Tongue Now we can create heatmap with additional annotations. # Determines the scaling of colorss # Scale colors breaks &lt;- seq(-ceiling(max(abs(mat))), ceiling(max(abs(mat))), length.out = ifelse( max(abs(mat))&gt;5, 2*ceiling(max(abs(mat))), 10 ) ) colors &lt;- colorRampPalette(c(&quot;darkblue&quot;, &quot;blue&quot;, &quot;white&quot;, &quot;red&quot;, &quot;darkred&quot;))(length(breaks)-1) pheatmap(mat, annotation_row = taxa_clusters, annotation_col = sample_data, breaks = breaks, color = colors) In addition, there are also other packages that provide functions for more complex heatmaps, such as iheatmapr and ComplexHeatmap (Gu 2022). sechm package provides wrapper for ComplexHeatmap and its usage is explained in chapter 14 along with the pheatmap package for clustered heatmaps. Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] ggtree_3.4.4 ape_5.7-1 [3] pheatmap_1.0.12 miaViz_1.7.5 [5] ggraph_2.1.0 ggplot2_3.4.2 [7] mia_1.7.11 MultiAssayExperiment_1.24.0 [9] TreeSummarizedExperiment_2.1.4 Biostrings_2.66.0 [11] XVector_0.38.0 SingleCellExperiment_1.20.1 [13] SummarizedExperiment_1.28.0 Biobase_2.58.0 [15] GenomicRanges_1.50.2 GenomeInfoDb_1.34.9 [17] IRanges_2.32.0 S4Vectors_0.36.2 [19] BiocGenerics_0.44.0 MatrixGenerics_1.10.0 [21] matrixStats_0.63.0-9003 BiocStyle_2.24.0 [23] rebook_1.6.0 loaded via a namespace (and not attached): [1] ggnewscale_0.4.8 ggbeeswarm_0.7.1 [3] colorspace_2.1-0 scuttle_1.8.4 [5] BiocNeighbors_1.16.0 aplot_0.1.10 [7] farver_2.1.1 graphlayouts_0.8.4 [9] ggrepel_0.9.3 bit64_4.0.5 [11] fansi_1.0.4 decontam_1.18.0 [13] codetools_0.2-19 splines_4.2.1 [15] sparseMatrixStats_1.10.0 cachem_1.0.7 [17] knitr_1.42 scater_1.26.1 [19] polyclip_1.10-4 jsonlite_1.8.4 [21] cluster_2.1.4 graph_1.74.0 [23] ggforce_0.4.1 BiocManager_1.30.20 [25] compiler_4.2.1 Matrix_1.5-4 [27] fastmap_1.1.1 lazyeval_0.2.2 [29] cli_3.6.1 tweenr_2.0.2 [31] BiocSingular_1.14.0 htmltools_0.5.5 [33] tools_4.2.1 igraph_1.4.1 [35] rsvd_1.0.5 gtable_0.3.3 [37] glue_1.6.2 GenomeInfoDbData_1.2.9 [39] reshape2_1.4.4 dplyr_1.1.1 [41] Rcpp_1.0.10 jquerylib_0.1.4 [43] vctrs_0.6.1 nlme_3.1-162 [45] DECIPHER_2.26.0 DelayedMatrixStats_1.20.0 [47] xfun_0.38 stringr_1.5.0 [49] beachmat_2.14.0 lifecycle_1.0.3 [51] irlba_2.3.5.1 XML_3.99-0.14 [53] zlibbioc_1.44.0 MASS_7.3-58.3 [55] scales_1.2.1 tidygraph_1.2.3 [57] parallel_4.2.1 RColorBrewer_1.1-3 [59] yaml_2.3.7 memoise_2.0.1 [61] gridExtra_2.3 ggfun_0.0.9 [63] yulab.utils_0.0.6 sass_0.4.5 [65] stringi_1.7.12 RSQLite_2.3.1 [67] highr_0.10 ScaledMatrix_1.6.0 [69] tidytree_0.4.2 permute_0.9-7 [71] filelock_1.0.2 BiocParallel_1.32.6 [73] rlang_1.1.0 pkgconfig_2.0.3 [75] bitops_1.0-7 evaluate_0.20 [77] lattice_0.21-8 purrr_1.0.1 [79] labeling_0.4.2 patchwork_1.1.2 [81] treeio_1.22.0 CodeDepends_0.6.5 [83] bit_4.0.5 tidyselect_1.2.0 [85] plyr_1.8.8 magrittr_2.0.3 [87] bookdown_0.33 R6_2.5.1 [89] generics_0.1.3 DelayedArray_0.24.0 [91] DBI_1.1.3 withr_2.5.0 [93] pillar_1.9.0 mgcv_1.8-42 [95] RCurl_1.98-1.12 tibble_3.2.1 [97] dir.expiry_1.4.0 crayon_1.5.2 [99] utf8_1.2.3 rmarkdown_2.21 [101] viridis_0.6.2 grid_4.2.1 [103] blob_1.2.4 vegan_2.6-4 [105] digest_0.6.31 tidyr_1.3.0 [107] gridGraphics_0.5-1 munsell_0.5.0 [109] DirichletMultinomial_1.40.0 ggplotify_0.1.0 [111] beeswarm_0.4.0 viridisLite_0.4.1 [113] vipor_0.4.5 bslib_0.4.2 Bibliography "],["clustering.html", "Chapter 10 Community typing (clustering) 10.1 Hiearchical clustering 10.2 K-means clustering 10.3 Dirichlet Multinomial Mixtures (DMM) 10.4 Community Detection 10.5 Biclustering 10.6 Additional Community Typing", " Chapter 10 Community typing (clustering) .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } library(mia) data(&quot;GlobalPatterns&quot;, package=&quot;mia&quot;) tse &lt;- GlobalPatterns Clustering is an unsupervised machine learning technique. The idea of it is to find clusters from the data. A cluster is a group of features/samples that share pattern. For example, with clustering, we can find group of samples that share similar community composition. There are multiple clustering algorithms available. 10.1 Hiearchical clustering Hiearchical clustering is a clustering method that aims to find hiearchy between samples/features. There are to approaches: agglomerative (“bottom-up”) and divisive (“top-down”). In agglomerative approach, each observation is first unique cluster. Algorithm continues by agglomerating similar clusters. Divisive approach starts with one cluster that contains all the observations. Clusters are splitted recursively to clusters that differ the most. Clustering ends when each cluster contains only one observation. Hiearchical clustering can be visualized with dendrogram tree. In each splitting point, the three is divided into two clusters leading to hierarchy. Let’s load data from mia package. library(mia) library(vegan) # Load experimental data data(peerj13075) (tse &lt;- peerj13075) ## class: TreeSummarizedExperiment ## dim: 674 58 ## metadata(0): ## assays(1): counts ## rownames(674): OTU1 OTU2 ... OTU2567 OTU2569 ## rowData names(6): kingdom phylum ... family genus ## colnames(58): ID1 ID2 ... ID57 ID58 ## colData names(5): Sample Geographical_location Gender Age Diet ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: NULL ## rowTree: NULL ## colLinks: NULL ## colTree: NULL Hierarchical clustering requires 2 steps. In the fist step, dissimilarities are calculated. In prior to that, data transformation is applied if needed. Since sequencing data is compositional, relative transformation is applied. In the second step, clustering is performed based on dissimilarities. if( !require(NbClust) ){install.packages(&quot;NbClust&quot;); library(NbClust)} if( !require(cobiclust) ){install.packages(&quot;cobiclust&quot;); library(cobiclust)} # Apply transformation tse &lt;- transformCounts(tse, method = &quot;relabundance&quot;) # Get the assay assay &lt;- assay(tse, &quot;relabundance&quot;) # Transpose assay --&gt; samples are now in rows --&gt; we are clustering samples assay &lt;- t(assay) # Calculate distances diss &lt;- vegdist(assay, method = &quot;bray&quot;) # Perform hierarchical clustering hc &lt;- hclust(diss, method = &quot;complete&quot;) # To visualize, convert hclust object into dendrogram object dendro &lt;- as.dendrogram(hc) # Plot dendrogram plot(dendro) We can use dendrogram to determine the number of clusters. Usually the tree is splitted where the branch length is the largest. However, as we can see from the dendrogram, clusters are not clear. Algorithms are available to identify the optimal number of clusters. # Determine the optimal number of clusters res &lt;- NbClust(diss = diss, distance = NULL, method = &quot;ward.D2&quot;, index = &quot;silhouette&quot;) ## ## Only frey, mcclain, cindex, sihouette and dunn can be computed. To compute the other indices, data matrix is needed res$Best.nc ## Number_clusters Value_Index ## 15.0000 0.4543 Based on the result, let’s divide observations into 15 clusters. if( !require(dendextend) ){ install.packages(&quot;dendextend&quot;) library(dendextend) } # Find clusters cutree(hc, k = 15) ## ID1 ID2 ID3 ID4 ID5 ID6 ID7 ID8 ID9 ID10 ID11 ID12 ID13 ID14 ID15 ID16 ## 1 2 3 4 5 5 2 2 2 6 5 5 2 5 2 5 ## ID17 ID18 ID19 ID20 ID21 ID22 ID23 ID24 ID25 ID26 ID27 ID28 ID29 ID30 ID31 ID32 ## 5 4 5 5 7 8 9 5 3 1 8 8 8 3 1 2 ## ID33 ID34 ID35 ID36 ID37 ID38 ID39 ID40 ID41 ID42 ID43 ID44 ID45 ID46 ID47 ID48 ## 2 2 2 2 2 9 10 11 6 5 4 2 9 1 12 2 ## ID49 ID50 ID51 ID52 ID53 ID54 ID55 ID56 ID57 ID58 ## 4 4 2 8 7 13 14 3 8 15 # Making colors for 6 clusters col_val_map &lt;- randomcoloR::distinctColorPalette(15) %&gt;% as.list() %&gt;% setNames(paste0(&quot;clust_&quot;,seq(15))) dend &lt;- color_branches(dendro, k=15, col=unlist(col_val_map)) labels(dend) &lt;- NULL plot(dend) 10.2 K-means clustering Hierarchical clustering did not yield clusters. Let’s try k-means clustering instead. Here observations are divided into clusters so that the distances between observations and cluster centers are minimized; an observation belongs to cluster whose center is the nearest. The algorithm starts by dividing observation to random clusters whose number is defined by user. The centroids of clusters are then calculated. After that, observations’ allocation to clusters are updated so that the means are minimized. Again, centroid are calculated, and algorithm continues iteratively until the assignments do not change. The number of clusters can be determined based on algorithm. Here we utilize silhouette analysis. if( !require(factoextra) ){ install.packages(&quot;factoextra&quot;) library(factoextra) } # Convert dist object into matrix diss &lt;- as.matrix(diss) # Perform silhouette analysis and plot the result fviz_nbclust(diss, kmeans, method = &quot;silhouette&quot;) Based on the result of silhouette analysis, we choose 3 to be the number of clusters in k-means clustering. library(scater) # The first step is random, add seed for reproducibility set.seed(15463) # Perform k-means clustering with 3 clusters km &lt;- kmeans(diss, 3, nstart = 25) # Add the result to colData colData(tse)$clusters &lt;- as.factor(km$cluster) # Perform PCoA so that we can visualize clusters tse &lt;- runMDS(tse, exprs_values = &quot;relabundance&quot;, FUN = vegan::vegdist, method = &quot;bray&quot;) # Plot PCoA and color clusters plotReducedDim(tse, &quot;MDS&quot;, colour_by = &quot;clusters&quot;) 10.3 Dirichlet Multinomial Mixtures (DMM) This section focus on DMM analysis. One technique that allows to search for groups of samples that are similar to each other is the Dirichlet-Multinomial Mixture Model. In DMM, we first determine the number of clusters (k) that best fit the data (model evidence) using Laplace approximation. After fitting the model with k clusters, we obtain for each sample k probabilities that reflect the probability that a sample belongs to the given cluster. Let’s cluster the data with DMM clustering. # Runs model and calculates the most likely number of clusters from 1 to 7. # Since this is a large dataset it takes long computational time. # For this reason we use only a subset of the data; agglomerated by Phylum as a rank. tse &lt;- GlobalPatterns tse &lt;- agglomerateByRank(tse, rank = &quot;Phylum&quot;, agglomerateTree=TRUE) tse_dmn &lt;- mia::runDMN(tse, name = &quot;DMN&quot;, k = 1:7) # It is stored in metadata tse_dmn ## class: TreeSummarizedExperiment ## dim: 67 26 ## metadata(2): agglomerated_by_rank DMN ## assays(1): counts ## rownames(67): Phylum:Crenarchaeota Phylum:Euryarchaeota ... ## Phylum:Synergistetes Phylum:SR1 ## rowData names(7): Kingdom Phylum ... Genus Species ## colnames(26): CL3 CC1 ... Even2 Even3 ## colData names(7): X.SampleID Primer ... SampleType Description ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: a LinkDataFrame (67 rows) ## rowTree: 1 phylo tree(s) (66 leaves) ## colLinks: NULL ## colTree: NULL Return information on metadata that the object contains. names(metadata(tse_dmn)) ## [1] &quot;agglomerated_by_rank&quot; &quot;DMN&quot; This returns a list of DMN objects for a closer investigation. getDMN(tse_dmn) ## [[1]] ## class: DMN ## k: 1 ## samples x taxa: 26 x 67 ## Laplace: 7715 BIC: 7802 AIC: 7760 ## ## [[2]] ## class: DMN ## k: 2 ## samples x taxa: 26 x 67 ## Laplace: 7673 BIC: 7927 AIC: 7842 ## ## [[3]] ## class: DMN ## k: 3 ## samples x taxa: 26 x 67 ## Laplace: 7690 BIC: 8076 AIC: 7948 ## ## [[4]] ## class: DMN ## k: 4 ## samples x taxa: 26 x 67 ## Laplace: 7751 BIC: 8274 AIC: 8103 ## ## [[5]] ## class: DMN ## k: 5 ## samples x taxa: 26 x 67 ## Laplace: 7854 BIC: 8553 AIC: 8340 ## ## [[6]] ## class: DMN ## k: 6 ## samples x taxa: 26 x 67 ## Laplace: 7926 BIC: 8796 AIC: 8540 ## ## [[7]] ## class: DMN ## k: 7 ## samples x taxa: 26 x 67 ## Laplace: 8003 BIC: 9051 AIC: 8752 Show Laplace approximation (model evidence) for each model of the k models. library(miaViz) plotDMNFit(tse_dmn, type = &quot;laplace&quot;) Return the model that has the best fit. getBestDMNFit(tse_dmn, type = &quot;laplace&quot;) ## class: DMN ## k: 2 ## samples x taxa: 26 x 67 ## Laplace: 7673 BIC: 7927 AIC: 7842 10.3.1 PCoA for ASV-level data with Bray-Curtis; with DMM clusters shown with colors Group samples and return DMNGroup object that contains a summary. Patient status is used for grouping. dmn_group &lt;- calculateDMNgroup(tse_dmn, variable = &quot;SampleType&quot;, exprs_values = &quot;counts&quot;, k = 2, seed=.Machine$integer.max) dmn_group ## class: DMNGroup ## summary: ## k samples taxa NLE LogDet Laplace BIC AIC ## Feces 2 4 67 1078.3 -106.19 901.1 1171.9 1213 ## Freshwater 2 2 67 889.6 -97.28 716.9 936.4 1025 ## Freshwater (creek) 2 3 67 1600.3 787.33 1869.9 1674.5 1735 ## Mock 2 3 67 1008.4 -55.37 856.6 1082.5 1143 ## Ocean 2 3 67 1096.7 -56.21 944.6 1170.9 1232 ## Sediment (estuary) 2 3 67 1195.5 18.63 1080.8 1269.7 1331 ## Skin 2 3 67 992.6 -84.93 826.1 1066.8 1128 ## Soil 2 3 67 1380.3 11.21 1261.8 1454.5 1515 ## Tongue 2 2 67 783.0 -107.74 605.1 829.8 918 Mixture weights (rough measure of the cluster size). DirichletMultinomial::mixturewt(getBestDMNFit(tse_dmn)) ## pi theta ## 1 0.5385 20.60 ## 2 0.4615 15.28 Samples-cluster assignment probabilities / how probable it is that sample belongs to each cluster head(DirichletMultinomial::mixture(getBestDMNFit(tse_dmn))) ## [,1] [,2] ## CL3 1.000e+00 5.004e-17 ## CC1 1.000e+00 3.799e-22 ## SV1 1.000e+00 2.021e-12 ## M31Fcsw 7.309e-26 1.000e+00 ## M11Fcsw 1.061e-16 1.000e+00 ## M31Plmr 9.991e-14 1.000e+00 Contribution of each taxa to each component head(DirichletMultinomial::fitted(getBestDMNFit(tse_dmn))) ## [,1] [,2] ## Phylum:Crenarchaeota 0.3043 0.1354653 ## Phylum:Euryarchaeota 0.2314 0.1468632 ## Phylum:Actinobacteria 1.2105 1.0600542 ## Phylum:Spirochaetes 0.2141 0.1318414 ## Phylum:MVP-15 0.0299 0.0007646 ## Phylum:Proteobacteria 6.8425 1.8151526 Get the assignment probabilities prob &lt;- DirichletMultinomial::mixture(getBestDMNFit(tse_dmn)) # Add column names colnames(prob) &lt;- c(&quot;comp1&quot;, &quot;comp2&quot;) # For each row, finds column that has the highest value. Then extract the column # names of highest values. vec &lt;- colnames(prob)[max.col(prob,ties.method = &quot;first&quot;)] Computing the euclidean PCoA and storing it as a data frame # Does clr transformation. Pseudocount is added, because data contains zeros. assay(tse, &quot;pseudo&quot;) &lt;- assay(tse, &quot;counts&quot;) + 1 tse &lt;- transformCounts(tse, assay_name = &quot;pseudo&quot;, method = &quot;relabundance&quot;) tse &lt;- transformCounts(tse, &quot;relabundance&quot;, method = &quot;clr&quot;) library(scater) # Does principal coordinate analysis df &lt;- calculateMDS(tse, exprs_values = &quot;clr&quot;, method = &quot;euclidean&quot;) # Creates a data frame from principal coordinates euclidean_pcoa_df &lt;- data.frame(pcoa1 = df[,1], pcoa2 = df[,2]) # Creates a data frame that contains principal coordinates and DMM information euclidean_dmm_pcoa_df &lt;- cbind(euclidean_pcoa_df, dmm_component = vec) # Creates a plot euclidean_dmm_plot &lt;- ggplot(data = euclidean_dmm_pcoa_df, aes(x=pcoa1, y=pcoa2, color = dmm_component)) + geom_point() + labs(x = &quot;Coordinate 1&quot;, y = &quot;Coordinate 2&quot;, title = &quot;PCoA with Aitchison distances&quot;) + theme(title = element_text(size = 12)) # makes titles smaller euclidean_dmm_plot 10.4 Community Detection Another approach for discovering communities within the samples of the data, is to run community detection algorithms after building a graph. The following demonstration builds a graph based on the k nearest-neighbors and performs the community detection on the fly. bluster (Lun 2021) package offers several clustering methods, among which graph-based are present, enabling the community detection task. Installing package: if(!require(bluster)){ BiocManager::install(&quot;bluster&quot;) } The algorithm used is “short random walks” (Pons and Latapy 2006). Graph is constructed using different k values (the number of nearest neighbors to consider during graph construction) using the robust centered log ratio (rclr) assay data. Then plotting the communities using UMAP (McInnes, Healy, and Melville 2018) ordination as a visual exploration aid. In the following demonstration we use the enterotype dataset from the (Ernst, Shetty, and Lahti 2020) package. library(bluster) library(patchwork) # For arranging several plots as a grid library(scater) data(&quot;enterotype&quot;, package=&quot;mia&quot;) tse &lt;- enterotype tse &lt;- transformCounts(tse, method = &quot;rclr&quot;) # Performing and storing UMAP tse &lt;- runUMAP(tse, name=&quot;UMAP&quot;, exprs_values=&quot;rclr&quot;) k &lt;- c(2,3,5,10) ClustAndPlot &lt;- function(x) { # Creating the graph and running the short random walks algorithm graph_clusters &lt;- clusterRows(t(assays(tse)$rclr), NNGraphParam(k=x)) # Results of the clustering as a color for each sample plotUMAP(tse, colour_by = I(graph_clusters)) + labs(title = paste0(&quot;k = &quot;, x)) } # Applying the function for different k values plots &lt;- lapply(k,ClustAndPlot) # Displaying plots in a grid (plots[[1]] + plots[[2]]) / (plots[[3]] + plots[[4]]) Similarly, the bluster (Lun 2021) package offers clustering diagnostics that can be used for judging the clustering quality (see Assorted clustering diagnostics). In the following, Silhouette width as a diagnostic tool is computed and results are visualized for each case presented earlier. For more about Silhouettes read (Rousseeuw 1987). ClustDiagPlot &lt;- function(x) { # Getting the clustering results graph_clusters &lt;- clusterRows(t(assays(tse)$rclr), NNGraphParam(k=x)) # Computing the diagnostic info sil &lt;- approxSilhouette(t(assays(tse)$rclr), graph_clusters) # Plotting as a boxlpot to observe cluster separation boxplot(split(sil$width, graph_clusters), main=paste0(&quot;k = &quot;, x)) } # Applying the function for different k values res &lt;- lapply(k,ClustDiagPlot) 10.5 Biclustering Biclustering methods cluster rows and columns simultaneously in order to find subsets of correlated features/samples. Here, we use following packages: biclust cobiclust cobiclust is especially developed for microbiome data whereas biclust is more general method. In this section, we show three different cases and example solutions to apply biclustering to them. Taxa vs samples Taxa vs biomolecule/biomarker Taxa vs taxa Biclusters can be visualized using heatmap or boxplot, for instance. For checking purposes, also scatter plot might be valid choice. Check more ideas for heatmaps from chapters 14 and @ref(microbiome-community. 10.5.1 Taxa vs samples When you have microbial abundance matrices, we suggest to use cobiclust which is designed for microbial data. Load example data library(mia) data(&quot;HintikkaXOData&quot;) mae &lt;- HintikkaXOData Only the most prevalent taxa are included in analysis. # Subset data in the first experiment mae[[1]] &lt;- subsetByPrevalentTaxa(mae[[1]], rank = &quot;Genus&quot;, prevalence = 0.2, detection = 0.001) # clr-transform in the first experiment mae[[1]] &lt;- transformCounts(mae[[1]], method = &quot;relabundance&quot;) mae[[1]] &lt;- transformCounts(mae[[1]], &quot;relabundance&quot;, method = &quot;rclr&quot;) cobiclust takes counts table as an input and gives cobiclust object as an output. It includes clusters for taxa and samples. # Do clustering; use counts table´ clusters &lt;- cobiclust(assay(mae[[1]], &quot;counts&quot;)) # Get clusters row_clusters &lt;- clusters$classification$rowclass col_clusters &lt;- clusters$classification$colclass # Add clusters to rowdata and coldata rowData(mae[[1]])$clusters &lt;- factor(row_clusters) colData(mae[[1]])$clusters &lt;- factor(col_clusters) # Order data based on clusters mae[[1]] &lt;- mae[[1]][order(rowData(mae[[1]])$clusters), order(colData(mae[[1]])$clusters)] # Print clusters clusters$classification ## $rowclass ## [1] 1 1 1 1 2 2 1 1 1 1 1 1 2 2 2 2 1 2 1 1 2 1 2 2 1 1 2 1 1 1 1 1 2 1 1 2 1 1 ## [39] 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 1 1 ## ## $colclass ## C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C11 C12 C13 C14 C15 C16 C17 C18 C19 C20 ## 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## C21 C22 C23 C24 C25 C26 C27 C28 C29 C30 C31 C32 C33 C34 C35 C36 C37 C38 C39 C40 ## 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 Next we can plot clusters. Annotated heatmap is a common choice. if(!require(pheatmap)){ install.packages(&quot;pheatmap&quot;) library(pheatmap) } # z-transform for heatmap mae[[1]] &lt;- transformCounts(mae[[1]], assay_name = &quot;rclr&quot;, MARGIN = &quot;features&quot;, method = &quot;z&quot;, name = &quot;clr_z&quot;) # Create annotations. When column names are equal, they should share levels. # Here samples include 3 clusters, and taxa 2. That is why we have to make # column names unique. annotation_col &lt;- data.frame(colData(mae[[1]])[, &quot;clusters&quot;, drop = F]) colnames(annotation_col) &lt;- &quot;col_clusters&quot; annotation_row &lt;- data.frame(rowData(mae[[1]])[, &quot;clusters&quot;, drop = F]) colnames(annotation_row) &lt;- &quot;row_clusters&quot; Plot the heatmap. pheatmap(assay(mae[[1]], &quot;clr_z&quot;), cluster_rows = F, cluster_cols = F, annotation_col = annotation_col, annotation_row = annotation_row) Boxplot is commonly used to summarize the results: if(!require(ggplot2)){ install.packages(&quot;ggplot2&quot;) library(ggplot2) } if(!require(patchwork)){ install.packages(&quot;patchwork&quot;) library(patchwork) } # ggplot requires data in melted format melt_assay &lt;- meltAssay(mae[[1]], assay_name = &quot;rclr&quot;, add_col_data = T, add_row_data = T) # patchwork two plots side-by-side p1 &lt;- ggplot(melt_assay) + geom_boxplot(aes(x = clusters.x, y = rclr)) + labs(x = &quot;Taxa clusters&quot;) p2 &lt;- ggplot(melt_assay) + geom_boxplot(aes(x = clusters.y, y = rclr)) + labs(x = &quot;Sample clusters&quot;) p1 + p2 10.5.2 Taxa vs biomolecules Here, we analyze cross-correlation between taxa and metabolites. This is a case, where we use biclust method which is suitable for numeric matrices in general. # Samples must be in equal order # (Only 1st experiment was ordered in cobiclust step leading to unequal order) mae[[1]] &lt;- mae[[1]][ , colnames(mae[[2]]) ] # Make rownames unique since it is require by other steps rownames(mae[[1]]) &lt;- make.unique(rownames(mae[[1]])) # Calculate correlations corr &lt;- getExperimentCrossCorrelation(mae, 1, 2, assay_name1 = &quot;rclr&quot;, assay_name2 = &quot;nmr&quot;, mode = &quot;matrix&quot;, cor_threshold = 0.2) biclust takes matrix as an input and returns biclust object. # Load package if(!require(biclust)){ install.packages(&quot;biclust&quot;) library(biclust) } # Set seed for reproducibility set.seed(3973) # Find biclusters bc &lt;- biclust(corr, method=BCPlaid(), fit.model = y ~ m, background = TRUE, shuffle = 100, back.fit = 0, max.layers = 10, iter.startup = 10, iter.layer = 100, verbose = FALSE) bc ## ## An object of class Biclust ## ## call: ## biclust(x = corr, method = BCPlaid(), fit.model = y ~ m, background = TRUE, ## shuffle = 100, back.fit = 0, max.layers = 10, iter.startup = 10, ## iter.layer = 100, verbose = FALSE) ## ## There was no cluster found The object includes cluster information. However compared to cobiclust, biclust object includes only information about clusters that were found, not general cluster. Meaning that if one cluster size of 5 features was found out of 20 features, those 15 features do not belong to any cluster. That is why we have to create an additional cluster for features/samples that are not assigned into any cluster. # Functions for obtaining biclust information # Get clusters for rows and columns .get_biclusters_from_biclust &lt;- function(bc, assay){ # Get cluster information for columns and rows bc_columns &lt;- t(bc@NumberxCol) bc_columns &lt;- data.frame(bc_columns) bc_rows &lt;- bc@RowxNumber bc_rows &lt;- data.frame(bc_rows) # Get data into right format bc_columns &lt;- .manipulate_bc_data(bc_columns, assay, &quot;col&quot;) bc_rows &lt;- .manipulate_bc_data(bc_rows, assay, &quot;row&quot;) return(list(bc_columns = bc_columns, bc_rows = bc_rows)) } # Input clusters, and how many observations there should be, i.e., # the number of samples or features .manipulate_bc_data &lt;- function(bc_clusters, assay, row_col){ # Get right dimension dim &lt;- ifelse(row_col == &quot;col&quot;, ncol(assay), nrow(assay)) # Get column/row names if( row_col == &quot;col&quot; ){ names &lt;- colnames(assay) } else{ names &lt;- rownames(assay) } # If no clusters were found, create one. Otherwise create additional # cluster which # contain those samples that are not included in clusters that were found. if( nrow(bc_clusters) != dim ){ bc_clusters &lt;- data.frame(cluster = rep(TRUE, dim)) } else { # Create additional cluster that includes those samples/features that # are not included in other clusters. vec &lt;- ifelse(rowSums(bc_clusters) &gt; 0, FALSE, TRUE) # If additional cluster contains samples, then add it if ( any(vec) ){ bc_clusters &lt;- cbind(bc_clusters, vec) } } # Adjust row and column names rownames(bc_clusters) &lt;- names colnames(bc_clusters) &lt;- paste0(&quot;cluster_&quot;, 1:ncol(bc_clusters)) return(bc_clusters) } # Get biclusters bcs &lt;- .get_biclusters_from_biclust(bc, corr) bicluster_rows &lt;- bcs$bc_rows bicluster_columns &lt;- bcs$bc_columns # Print biclusters for rows head(bicluster_rows) ## cluster_1 ## D_5__Ruminiclostridium 5 TRUE ## D_5__Lachnoclostridium TRUE ## D_5__Holdemania TRUE ## D_5__Anaerostipes TRUE ## D_5__uncultured_3 TRUE ## D_5__Ruminococcaceae NK4A214 group TRUE Let’s collect information for the scatter plot. # Function for obtaining sample-wise sum, mean, median, and mean variance # for each cluster .sum_mean_median_var &lt;- function(tse1, tse2, assay_name1, assay_name2, clusters1, clusters2){ list &lt;- list() # Create a data frame that includes all the information for(i in 1:ncol(clusters1) ){ # Subset data based on cluster tse_subset1 &lt;- tse1[clusters1[,i], ] tse_subset2 &lt;- tse2[clusters2[,i], ] # Get assay assay1 &lt;- assay(tse_subset1, assay_name1) assay2 &lt;- assay(tse_subset2, assay_name2) # Calculate sum, mean, median, and mean variance sum1 &lt;- colSums2(assay1, na.rm = T) mean1 &lt;- colMeans2(assay1, na.rm = T) median1 &lt;- colMedians(assay1, na.rm = T) var1 &lt;- colVars(assay1, na.rm = T) sum2 &lt;- colSums2(assay2, na.rm = T) mean2 &lt;- colMeans2(assay2, na.rm = T) median2 &lt;- colMedians(assay2, na.rm = T) var2 &lt;- colVars(assay2, na.rm = T) list[[i]] &lt;- data.frame(sample = colnames(tse1), sum1, sum2, mean1, mean2, median1, median2, var1, var2) } return(list) } # Calculate info df &lt;- .sum_mean_median_var(mae[[1]], mae[[2]], &quot;rclr&quot;, &quot;nmr&quot;, bicluster_rows, bicluster_columns) Now we can create a scatter plot. X-axis includes median clr abundance of microbiome and y-axis median absolute concentration of each metabolite. Each data point represents a single sample. From the plots, we can see that there is low negative correlation in both cluster 1 and 3. This means that when abundance of bacteria belonging to cluster 1 or 3 is higher, the concentration of metabolites of cluster 1 or 3 is lower, and vice versa. pics &lt;- list() for(i in seq_along(df)){ pics[[i]] &lt;- ggplot(df[[i]]) + geom_point(aes(x = median1, y = median2)) + labs(title = paste0(&quot;Cluster &quot;, i), x = &quot;Taxa (rclr median)&quot;, y = &quot;Metabolites (abs. median)&quot;) print(pics[[i]]) } # pics[[1]] + pics[[2]] + pics[[3]] pheatmap does not allow boolean values, so they must be converted into factors. bicluster_columns &lt;- data.frame(apply(bicluster_columns, 2, as.factor)) bicluster_rows &lt;- data.frame(apply(bicluster_rows, 2, as.factor)) Again, we can plot clusters with heatmap. # Adjust colors for all clusters if( ncol(bicluster_rows) &gt; ncol(bicluster_columns) ){ cluster_names &lt;- colnames(bicluster_rows) } else { cluster_names &lt;- colnames(bicluster_columns) } annotation_colors &lt;- list() for(name in cluster_names){ annotation_colors[[name]] &lt;- c(&quot;TRUE&quot; = &quot;red&quot;, &quot;FALSE&quot; = &quot;white&quot;) } # Create a heatmap pheatmap(corr, cluster_cols = F, cluster_rows = F, annotation_col = bicluster_columns, annotation_row = bicluster_rows, annotation_colors = annotation_colors) 10.5.3 Taxa vs taxa Third and final example deals with situation where we want to analyze correlation between taxa. biclust is suitable for this. # Calculate cross-correlation corr &lt;- getExperimentCrossCorrelation(mae, 1, 1, assay_name1 = &quot;rclr&quot;, assay_name2 = &quot;rclr&quot;, mode = &quot;matrix&quot;, cor_threshold = 0.2, verbose = F, show_warning = F) # Find biclusters bc &lt;- biclust(corr, method=BCPlaid(), fit.model = y ~ m, background = TRUE, shuffle = 100, back.fit = 0, max.layers = 10, iter.startup = 10, iter.layer = 100, verbose = FALSE) # Get biclusters bcs &lt;- .get_biclusters_from_biclust(bc, corr) bicluster_rows &lt;- bcs$bc_rows bicluster_columns &lt;- bcs$bc_columns # Create a column that combines information # If row/column includes in multiple clusters, cluster numbers are separated with &quot;_&amp;_&quot; bicluster_columns$clusters &lt;- apply(bicluster_columns, 1, function(x){paste(paste(which(x)), collapse = &quot;_&amp;_&quot;) }) bicluster_columns &lt;- bicluster_columns[, &quot;clusters&quot;, drop = FALSE] bicluster_rows$clusters &lt;- apply(bicluster_rows, 1, function(x){paste(paste(which(x)), collapse = &quot;_&amp;_&quot;) }) bicluster_rows &lt;- bicluster_rows[, &quot;clusters&quot;, drop = FALSE] # Convert boolean values into factor bicluster_columns &lt;- data.frame(apply(bicluster_columns, 2, as.factor)) bicluster_rows &lt;- data.frame(apply(bicluster_rows, 2, as.factor)) pheatmap(corr, cluster_cols = F, cluster_rows = F, annotation_col = bicluster_columns, annotation_row = bicluster_rows) 10.6 Additional Community Typing For more community typing techniques applied to the ‘SprockettTHData’ data set, see the attached .Rmd file. Link: Rmd Bibliography "],["differential-abundance.html", "Chapter 11 Differential abundance 11.1 Differential abundance analysis 11.2 Tree-based methods Session Info", " Chapter 11 Differential abundance .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 11.1 Differential abundance analysis This section provides an overview and examples of differential abundance analysis (DAA) based on one of the openly available datasets in mia to illustrate how to perform differential abundance analysis (DAA). DAA identifies differences in the abundances of individual taxonomic groups between two or more groups (e.g. treatment vs control). This can be performed at any phylogenetic level. We perform DAA to identify biomarkers and/or gain understanding of a complex system by looking at its isolated components. For example, identifying that a bacterial taxon is different between a patient group with disease X vs a healthy control group might lead to important insights into the pathophysiology. Changes in the microbiota might be cause or a consequence of a disease. Either way, it can help to understand the system as a whole. Be aware that this approach has also been criticized recently (Quinn, Gordon-Rodriguez, and Erb 2021). 11.1.1 Examples and tools There are many tools to perform DAA. The most popular tools, without going into evaluating whether or not they perform well for this task, are: ALDEx2 (Gloor, Macklaim, and Fernandes 2016) ANCOMBC (Lin and Peddada 2020a) corncob (Martin, Witten, and Willis 2021) DESeq2 (Love, Huber, and Anders 2014) edgeR (Chen, Lun, and Smyth 2016) lefser (Khleborodova 2021) Maaslin2 (Mallick, Rahnavard, and McIver 2020) metagenomeSeq (Paulson, Talukder, and Bravo 2017) limma (Ritchie et al. 2015) LinDA (Zhou et al. 2022) t-test Wilcoxon test We recommend to have a look at Nearing et al. (2022) who compared all these listed methods across 38 different datasets. Because different methods use different approaches (parametric vs non-parametric, different normalization techiniques, assumptions etc.), results can differ between methods. Unfortunately, as Nearing et al. (2022) point out, they can differ substantially. Therefore, it is highly recommended to pick several methods to get an idea about how robust and potentially reproducible your findings are depending on the method. In this section we demonstrate 4 methods that can be recommended based on recent literature (ANCOM-BC, ALDEx2, Maaslin2 and LinDA) and we will compare the results between them. Note that the purpose of this section is to show how to perform DAA in R, not how to correctly do causal inference. Depending on your experimental setup and your theory, you must determine how to specify any model exactly. E.g., there might be confounding factors that might drive (the absence of) differences between the shown groups that we ignore here for simplicity. However, we will show how you could include covariates in those models. Furthermore, we picked a dataset that merely has microbial abundances in a TSE object as well as a grouping variable in the sample data. We simplify the analysis by only including 2 of the 3 groups. library(mia) library(patchwork) library(tidySummarizedExperiment) library(ALDEx2) library(Maaslin2) library(MicrobiomeStat) library(knitr) library(tidyverse) library(ANCOMBC) # set random seed because some tools can randomly vary and then produce # different results: set.seed(13253) # we use a demo dataset and restrict it to two geo locations # for easy illustration data(peerj13075) tse &lt;- peerj13075 tse &lt;- tse[ ,tse$Geographical_location %in% c(&quot;Pune&quot;, &quot;Nashik&quot;)] # Let us make this a factor tse$Geographical_location &lt;- factor(tse$Geographical_location) # how many observations do we have per group? count(as.data.frame(colData(tse)), Geographical_location) %&gt;% kable() Geographical_location n Nashik 11 Pune 36 11.1.2 Prevalence Filtering Before we jump to our analyses, we may want to perform prevalence filtering. Nearing et al. (2022) found that applying a 10% threshold for the prevalence of the taxa generally resulted in more robust results. Some tools have builtin arguments for that. By applying the threshold to our input data, we can make sure it is applied for all tools. Below we show how to do this in mia: tse &lt;- subsetByPrevalentTaxa(tse, detection = 0, prevalence = 0.1) 11.1.3 ALDEx2 In this section, we will show how to perform a simple ALDEx2 analysis. If you wanted to pick a single method, this method could be recommended to use. According to the developers experience, it tends to identify the common features identified by other methods. This statement is in line with a recent independent evaluation by Nearing et al. (2022). Please also have a look at the more extensive vignette that covers this flexible tool in more depth. ALDEx2 estimates technical variation within each sample per taxon by utilizing the Dirichlet distribution. It furthermore applies the centered-log-ratio transformation (or closely related log-ratio transforms). Depending on the experimental setup, it will perform a two sample Welch’s T-test and Wilcoxon-test or a one-way ANOVA and Kruskal-Wallis-test. For more complex study designs, there is a possibility to utilize the glm functionality within ALDEx2. The Benjamini-Hochberg procedure is applied in any case to correct for multiple testing. Below we show a simple example that illustrates the workflow. # Generate Monte Carlo samples of the Dirichlet distribution for each sample. # Convert each instance using the centered log-ratio transform. # This is the input for all further analyses. set.seed(254) x &lt;- aldex.clr(assay(tse), tse$Geographical_location) The t-test: # calculates expected values of the Welch&#39;s t-test and Wilcoxon rank # test on the data returned by aldex.clr x_tt &lt;- aldex.ttest(x, paired.test = FALSE, verbose = FALSE) Effect sizes: # determines the median clr abundance of the feature in all samples and in # groups, the median difference between the two groups, the median variation # within each group and the effect size, which is the median of the ratio # of the between group difference and the larger of the variance within groups x_effect &lt;- aldex.effect(x, CI = TRUE, verbose = FALSE) # combine all outputs aldex_out &lt;- data.frame(x_tt, x_effect) Now, we can create a so called Bland-Altman or MA plot (left). It shows the association between the relative abundance and the magnitude of the difference per sample. Next to that, we can also create a plot that shows the dispersion on the x-axis instead of log-ratio abundance. Red dots represent genera that are differentially abundant (\\(q \\leq 0.1\\)) between the 2 groups. Black points are rare taxa and grey ones are abundant taxa. The dashed line represent an effect size of 1. See Gloor, Macklaim, and Fernandes (2016) to learn more about these plots. par(mfrow = c(1, 2)) aldex.plot( aldex_out, type = &quot;MA&quot;, test = &quot;welch&quot;, xlab = &quot;Log-ratio abundance&quot;, ylab = &quot;Difference&quot;, cutoff = 0.05 ) aldex.plot( aldex_out, type = &quot;MW&quot;, test = &quot;welch&quot;, xlab = &quot;Dispersion&quot;, ylab = &quot;Difference&quot;, cutoff = 0.05 ) The evaluation as differential abundant in above plots is based on the corrected p-value. According to the ALDEx2 developers, the safest approach is to identify those features where the 95% CI of the effect size does not cross 0. As we can see in below table, this is not the case for any of the identified genera (see overlap column, which indicates the proportion of overlap). Also, the authors recommend to focus on effect sizes and CIs rather than interpreting the p-value. To keep the comparison simple, we will here use the p-value as decision criterion. But please be aware that the effect size together with the CI is a better answer to the question we are typically interested in (see also this article). rownames_to_column(aldex_out, &quot;genus&quot;) %&gt;% filter(wi.eBH &lt;= 0.05) %&gt;% # here we chose the wilcoxon output rather than tt select(genus, we.eBH, wi.eBH, effect, overlap) %&gt;% kable() genus we.eBH wi.eBH effect overlap OTU194 0.0553 0.0151 0.9552 0.1563 OTU562 0.0714 0.0266 -0.7147 0.1648 OTU611 0.1204 0.0468 -0.7630 0.1745 OTU773 0.0281 0.0036 1.1930 0.1037 OTU860 0.0866 0.0380 -0.8501 0.1733 OTU1075 0.0374 0.0083 -1.1059 0.1278 OTU1235 0.0280 0.0253 -0.9094 0.1702 OTU1680 0.0834 0.0341 -0.9270 0.1915 OTU2529 0.1113 0.0449 -0.8634 0.1929 11.1.4 ANCOM-BC The analysis of composition of microbiomes with bias correction (ANCOM-BC) (Lin and Peddada 2020b) is a recently developed method for differential abundance testing. It is based on an earlier published approach (Mandal et al. 2015). The previous version of ANCOM was among the methods that produced the most consistent results and is probably a conservative approach (Nearing et al. 2022). However, the new ANCOM-BC method operates quite differently compared to the former ANCOM method. As the only method, ANCOM-BC incorporates the so called sampling fraction into the model. The latter term could be empirically estimated by the ratio of the library size to the microbial load. According to the authors, variations in this sampling fraction would bias differential abundance analyses if ignored. Furthermore, this method provides p-values and confidence intervals for each taxon. It also controls the FDR and it is computationally simple to implement. Note that the original method was implemented in the ancombc() function (see extended tutorial). The method has since then been updated and new features have been added to enable multi-group comparisons and repeated measurements among other improvements. We do not cover the more advanced features of ANCOMBC in this tutorial as these features are documented in detail in this tutorial. We now proceed with a simple example. First, we specify a formula. In this formula, other covariates could potentially be included to adjust for confounding. We show this further below. Again, please make sure to check the function documentation as well as the linked tutorials to learn about the additional arguments that we specify. # perform the analysis out &lt;- ancombc2( data = tse, tax_level=&quot;genus&quot;, fix_formula = &quot;Geographical_location&quot;, p_adj_method = &quot;fdr&quot;, prv_cut = 0, # prev filtering has been done above already lib_cut = 0, group = &quot;Geographical_location&quot;, struc_zero = TRUE, neg_lb = TRUE, iter_control = list(tol = 1e-5, max_iter = 20, verbose = FALSE), em_control = list(tol = 1e-5, max_iter = 20), # use max_iter &gt;= 100 on real data alpha = 0.05, global = TRUE # multi group comparison will be deactivated automatically ) # store the results in res res &lt;- out$res The object out contains all model output. Again, see the documentation of the function under Value for an explanation of all the output objects. Our question whether taxa are differentially abundant can be answered by looking at the res object, which now contains dataframes with the coefficients, standard errors, p-values and q-values. Conveniently, there is a dataframe diff_abn. Here, for each taxon it is indicated whether it is differentially abundant between the groups (again, keep in mind that the answer is not black-white). Below we show the first 6 entries of this dataframe: kable(head(res)) taxon lfc_(Intercept) lfc_Geographical_locationPune se_(Intercept) se_Geographical_locationPune W_(Intercept) W_Geographical_locationPune p_(Intercept) p_Geographical_locationPune q_(Intercept) q_Geographical_locationPune diff_(Intercept) diff_Geographical_locationPune Abyssicoccus 0.0399 -0.0570 0.1675 0.1915 0.2383 -0.2975 0.8117 0.7661 0.8718 0.8463 FALSE FALSE Acidaminococcus 0.6874 -0.9024 0.1947 0.2225 3.5304 -4.0547 0.0004 0.0001 0.0032 0.0004 TRUE TRUE Acinetobacter 0.1243 -0.1672 0.7823 0.8940 0.1589 -0.1870 0.8737 0.8516 0.8969 0.8701 FALSE FALSE Actinomyces 0.1347 -0.1807 0.1938 0.2215 0.6952 -0.8161 0.4869 0.4145 0.6596 0.5616 FALSE FALSE Actinoplanes 0.2716 -0.3594 0.1635 0.1869 1.6608 -1.9231 0.0967 0.0545 0.2793 0.1504 FALSE FALSE Aerococcus 0.0237 -0.0358 0.1677 0.1917 0.1413 -0.1868 0.8876 0.8519 0.8994 0.8701 FALSE FALSE 11.1.5 MaAsLin2 Next, we will illustrate how to use MaAsLin2, which is the next generation of MaAsLin. As it is based on generalized linear models, it is flexible for different study designs and covariate structures. The official package tutorial can be found here. # maaslin expects features as columns and samples as rows # for both the asv/otu table as well as meta data asv &lt;- t(assay(tse)) meta_data &lt;- data.frame(colData(tse)) # you can specifiy different GLMs/normalizations/transforms. We used similar # settings as in Nearing et al. (2021) here: fit_data &lt;- Maaslin2( asv, meta_data, output = &quot;DAA example&quot;, transform = &quot;AST&quot;, fixed_effects = &quot;Geographical_location&quot;, # random_effects = c(...), # you can also fit MLM by specifying random effects # specifying a ref is especially important if you have more than 2 levels reference = &quot;Geographical_location,Pune&quot;, normalization = &quot;TSS&quot;, standardize = FALSE, min_prevalence = 0 # prev filterin already done ) Which genera are identified as differentially abundant? (leave out “head” to see all). kable(head(filter(fit_data$results, qval &lt;= 0.05))) feature metadata value coef stderr pval name qval N N.not.zero OTU1053 Geographical_location Pune -0.0080 0.0011 0 Geographical_locationPune 0 47 9 OTU860 Geographical_location Pune -0.0373 0.0059 0 Geographical_locationPune 0 47 13 OTU1075 Geographical_location Pune -0.1295 0.0207 0 Geographical_locationPune 0 47 27 OTU1980 Geographical_location Pune -0.0395 0.0062 0 Geographical_locationPune 0 47 9 OTU611 Geographical_location Pune -0.0274 0.0045 0 Geographical_locationPune 0 47 10 OTU2335 Geographical_location Pune -0.0089 0.0015 0 Geographical_locationPune 0 47 10 A folder will be created that is called like the above specified output. It contains also figures to visualize the difference between genera for the significant ones. 11.1.6 LinDA Lastly, we cover linear models for differential abundance analysis of microbiome compositional data (Zhou et al. (2022)). This tool is very similar to ANCOMBC with few differences: 1) LinDA correct for the compositional bias differently using the mode of all regression coefficients. 2) The authors claim that it runs 100-1000x faster than ANCOMBC and 3) it support hierarchical models. The latter could be ignored as ANCOMBC will be supporting hierarchical models with the next release. Nevertheless, LinDA seems a promising tool that achieves the best power/fdr trade-off together with ANCOMBC according to the authors. The speed might make it the choice for bigger datasets or datasets with a very high number of features. otu.tab &lt;- as.data.frame(assay(tse)) meta &lt;- as.data.frame(colData(tse)) %&gt;% select(Geographical_location) res &lt;- linda( otu.tab, meta, formula = &#39;~Geographical_location&#39;, alpha = 0.05, prev.filter = 0, mean.abund.filter = 0) ## 0 features are filtered! ## The filtered data has 47 samples and 262 features will be tested! ## Pseudo-count approach is used. ## Fit linear models ... ## Completed. # to scan the table for genera where H0 could be rejected: kable(head(filter(as.data.frame(res$output$Geographical_locationPune), reject))) baseMean log2FoldChange lfcSE stat pvalue padj reject df OTU15 1194.9 -1.9113 0.3579 -5.340 0.0000 0.0000 TRUE 45 OTU22 393.5 -0.6683 0.2184 -3.060 0.0037 0.0160 TRUE 45 OTU76 837.0 -1.8013 0.3598 -5.006 0.0000 0.0001 TRUE 45 OTU127 938.2 -1.7558 0.3912 -4.488 0.0000 0.0004 TRUE 45 OTU170 416.9 -0.7518 0.2351 -3.197 0.0025 0.0123 TRUE 45 OTU194 869.3 4.3671 1.2254 3.564 0.0009 0.0054 TRUE 45 11.1.7 Comparison of the methods When we compare the methods in the context of a research question, we could look at e.g. at whether they agree based on the applied decision criterion (e.g. adjusted p value &lt; 0.05). That is what we illustrate here. First we will look at how many taxa were identified by each method to begin with. In the next step we will look at the intersection of identified taxa. To achieve that, we first create a dataframe that summarises the decision criterion for each method and shows a score from 0 to 3 indicating how many methods agreed on a particular taxon. # change genus names to otu ids for ancombc results to make it joinable with others id_switch &lt;- as.data.frame(rowData(tse)) %&gt;% rownames_to_column(&quot;taxid&quot;) %&gt;% select(taxid, genus) abc_res &lt;- select(out$res, genus = taxon, ancombc = diff_Geographical_locationPune) %&gt;% left_join(id_switch, by = &quot;genus&quot;) %&gt;% select(-genus) # join all results together summ &lt;- full_join( rownames_to_column(aldex_out, &quot;taxid&quot;) %&gt;% select(taxid, aldex2 = wi.eBH), abc_res, by = &quot;taxid&quot;) %&gt;% full_join( select(fit_data$results, taxid = feature, maaslin2 = qval), by = &quot;taxid&quot;) %&gt;% full_join( rownames_to_column(as.data.frame(res$output$Geographical_locationPune), &quot;taxid&quot;) %&gt;% select(taxid, LinDA = reject), by = &quot;taxid&quot;) %&gt;% mutate( across(c(aldex2, maaslin2), ~ .x &lt;= 0.05), # the following line would be necessary without prevalence filtering # as some methods output NA #across(-genus, function(x) ifelse(is.na(x), FALSE, x)), ancombc = ifelse(is.na(ancombc), FALSE, ancombc), score = rowSums(across(c(aldex2, ancombc, maaslin2, LinDA))), ) # This is how it looks like: kable(head(summ)) taxid aldex2 ancombc maaslin2 LinDA score OTU2 FALSE FALSE FALSE FALSE 0 OTU15 FALSE TRUE TRUE TRUE 3 OTU22 FALSE FALSE TRUE TRUE 2 OTU53 FALSE FALSE FALSE FALSE 0 OTU69 FALSE FALSE FALSE FALSE 0 OTU76 FALSE FALSE TRUE TRUE 2 Now we can answer our questions: # how many genera were identified by each method? summarise(summ, across(where(is.logical), sum)) %&gt;% kable() aldex2 ancombc maaslin2 LinDA 9 31 67 75 # which genera are identified by all methods? filter(summ, score == 4) %&gt;% kable() taxid aldex2 ancombc maaslin2 LinDA score OTU773 TRUE TRUE TRUE TRUE 4 OTU860 TRUE TRUE TRUE TRUE 4 OTU1075 TRUE TRUE TRUE TRUE 4 OTU1235 TRUE TRUE TRUE TRUE 4 OTU1680 TRUE TRUE TRUE TRUE 4 OTU2529 TRUE TRUE TRUE TRUE 4 We see that each method identified at least some genera as differentially abundant. Many of those that were identified by ALDEx2, were also identified by the other methods. Let us plot the data for any method or for those taxa that were identified by all methods: # Data data(peerj13075) tse &lt;- peerj13075 # Add relative abundances and clr abundances tse &lt;- transformCounts(tse, method=&quot;relabundance&quot;) tse &lt;- transformCounts(tse, method=&quot;clr&quot;, pseudocount=1) # Subset to prevalent taxa (exclude rare taxa at 10 percent prevalence using 0 detection threshold): # do the subsetting based on the relative abundance assay tse &lt;- subsetByPrevalentTaxa(tse, detection = 0, prevalence = 10/100, assay.type=&quot;relabundance&quot;) # Subset to certain geolocations tse &lt;- tse[ ,tse$Geographical_location %in% c(&quot;Pune&quot;, &quot;Nashik&quot;)] # Let us make the geo location a factor tse$Geographical_location &lt;- factor(tse$Geographical_location) # Create a jittered boxplot for each genus assay.type &lt;- &quot;relabundance&quot; plot_data &lt;- data.frame(t(assay(tse, assay.type))) plot_data$Geographical_location &lt;- tse$Geographical_location plots &lt;- pmap(select(summ, taxid, score), function(taxid, score) { ggplot(plot_data, aes_string(x=&quot;Geographical_location&quot;, y=taxid)) + geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.2) + scale_y_log10() + labs(title=glue::glue(&quot;{taxid}&quot;), x=&quot;&quot;, y=glue::glue(&quot;Abundance ({assay.type})&quot;)) + theme_bw() + theme(legend.position = &quot;none&quot;) }) # now we can show only those genera that have at least score 3 (or 2 or 1) robust_plots &lt;- plots[summ$score == 4 &amp; !is.na(summ$score)] # to display this nicely in the book we use patchwork here: # (we show first ones) robust_plots[[1]] + robust_plots[[2]] + robust_plots[[3]] + robust_plots[[4]] + robust_plots[[5]] + robust_plots[[6]] + plot_layout(nrow = 1) # or if we have most trust in any specific method we can show genera that # are differentially abundant according to that method and then look in the # title how many methods also identified it (we only show first 6 here): ancombc_plots &lt;- plots[summ$ancombc &amp; !is.na(summ$score)] ancombc_plots[[1]] + ancombc_plots[[2]] + ancombc_plots[[3]] + ancombc_plots[[4]] + ancombc_plots[[5]] + ancombc_plots[[6]] 11.1.8 Confounding variables To perform causal inference, it is crucial that the method is able to include covariates in the model. This is not possible with e.g. the Wilcoxon test. Other methods such as both ANCOM methods, ALDEx2, LinDA, MaAsLin2 and others allow this. Below we show how to include a covariate in ANCOM-BC. It is very similar for all the methods that allow this. Since in this dataset there are no covariates, I first simulate a new variable and add it to the TSE object. # FIXME: switch to a faster example / method out_cov = ancombc2( data = tse, fix_formula = &quot;Geographical_location + Age&quot;, # here we add Age to the model p_adj_method = &quot;fdr&quot;, prv_cut = 0, # we did that already lib_cut = 0, group = &quot;Geographical_location&quot;, struc_zero = TRUE, neg_lb = TRUE, iter_control = list(tol = 1e-5, max_iter = 20, verbose = FALSE), em_control = list(tol = 1e-5, max_iter = 20), alpha = 0.05, global = TRUE # multi group comparison will be deactivated automatically ) # now the model answers the question: holding Age constant, are # bacterial taxa differentially abundant? Or, if that is of interest, # holding phenotype constant, is Age associated with bacterial abundance? # Again we only show the first 6 entries. kable(head(out_cov$res)) taxon lfc_(Intercept) lfc_Geographical_locationPune lfc_AgeElderly lfc_AgeMiddle_age se_(Intercept) se_Geographical_locationPune se_AgeElderly se_AgeMiddle_age W_(Intercept) W_Geographical_locationPune W_AgeElderly W_AgeMiddle_age p_(Intercept) p_Geographical_locationPune p_AgeElderly p_AgeMiddle_age q_(Intercept) q_Geographical_locationPune q_AgeElderly q_AgeMiddle_age diff_(Intercept) diff_Geographical_locationPune diff_AgeElderly diff_AgeMiddle_age OTU2 0.0441 -0.1005 0.0892 0.0118 0.1727 0.2390 0.2301 0.2346 0.2553 -0.4203 0.3876 0.0504 0.7985 0.6742 0.6983 0.9598 0.8739 0.9143 0.9128 0.9925 FALSE FALSE FALSE FALSE OTU15 0.7071 -0.7615 -0.2435 -0.1584 0.1988 0.2752 0.2649 0.2702 3.5567 -2.7669 -0.9190 -0.5865 0.0004 0.0057 0.3581 0.5576 0.0029 0.0365 0.8827 0.9891 TRUE TRUE FALSE FALSE OTU53 0.0248 -1.0822 1.4991 1.1526 0.7869 1.0893 1.0491 1.0698 0.0315 -0.9935 1.4289 1.0774 0.9749 0.3205 0.1530 0.2813 0.9749 0.6300 0.7718 0.7889 FALSE FALSE FALSE FALSE OTU87 0.1808 0.1182 -0.4585 -0.4494 0.1907 0.2640 0.2541 0.2592 0.9481 0.4476 -1.8039 -1.7342 0.3431 0.6544 0.0712 0.0829 0.5236 0.9143 0.5707 0.6097 FALSE FALSE FALSE FALSE OTU99 0.3073 -0.1658 -0.2769 -0.3349 0.1637 0.2266 0.2182 0.2225 1.8767 -0.7315 -1.2693 -1.5053 0.0606 0.4645 0.2043 0.1323 0.2096 0.7479 0.8240 0.6097 FALSE FALSE FALSE FALSE OTU111 0.0066 -0.1499 0.1351 0.2453 0.1712 0.2369 0.2281 0.2326 0.0388 -0.6325 0.5925 1.0548 0.9691 0.5271 0.5535 0.2915 0.9749 0.8026 0.8901 0.7889 FALSE FALSE FALSE FALSE In the next section of this book chapter we cover methods that can also take into account the phylogenetic information of bacterial taxa to perform group-wise associations. 11.2 Tree-based methods 11.2.1 Group-wise associations testing based on balances For testing associations based on balances, check the philr R/Bioconductor package. Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] doRNG_1.8.6 rngtools_1.5.2 [3] foreach_1.5.2 ANCOMBC_2.1.3 [5] lubridate_1.9.2 forcats_1.0.0 [7] stringr_1.5.0 dplyr_1.1.1 [9] purrr_1.0.1 readr_2.1.4 [11] tidyr_1.3.0 tibble_3.2.1 [13] ggplot2_3.4.2 tidyverse_2.0.0 [15] knitr_1.42 MicrobiomeStat_1.1 [17] Maaslin2_1.10.0 ALDEx2_1.28.1 [19] zCompositions_1.4.0-1 truncnorm_1.0-9 [21] NADA_1.6-1.1 survival_3.5-5 [23] MASS_7.3-58.3 tidySummarizedExperiment_1.6.1 [25] patchwork_1.1.2 mia_1.7.11 [27] MultiAssayExperiment_1.24.0 TreeSummarizedExperiment_2.1.4 [29] Biostrings_2.66.0 XVector_0.38.0 [31] SingleCellExperiment_1.20.1 SummarizedExperiment_1.28.0 [33] Biobase_2.58.0 GenomicRanges_1.50.2 [35] GenomeInfoDb_1.34.9 IRanges_2.32.0 [37] S4Vectors_0.36.2 BiocGenerics_0.44.0 [39] MatrixGenerics_1.10.0 matrixStats_0.63.0-9003 [41] BiocStyle_2.24.0 rebook_1.6.0 loaded via a namespace (and not attached): [1] estimability_1.4.1 coda_0.19-4 [3] bit64_4.0.5 multcomp_1.4-23 [5] irlba_2.3.5.1 DelayedArray_0.24.0 [7] data.table_1.14.8 rpart_4.1.19 [9] doParallel_1.0.17 RCurl_1.98-1.12 [11] generics_0.1.3 ScaledMatrix_1.6.0 [13] TH.data_1.1-1 timeSeries_4021.105 [15] RSQLite_2.3.1 proxy_0.4-27 [17] bit_4.0.5 tzdb_0.3.0 [19] DirichletMultinomial_1.40.0 viridis_0.6.2 [21] xfun_0.38 fBasics_4022.94 [23] hms_1.1.3 jquerylib_0.1.4 [25] evaluate_0.20 DEoptimR_1.0-11 [27] fansi_1.0.4 readxl_1.4.2 [29] igraph_1.4.1 DBI_1.1.3 [31] htmlwidgets_1.6.2 hash_2.2.6.2 [33] Rmpfr_0.9-1 CVXR_1.0-11 [35] ellipsis_0.3.2 energy_1.7-11 [37] backports_1.4.1 bookdown_0.33 [39] permute_0.9-7 sparseMatrixStats_1.10.0 [41] vctrs_0.6.1 cachem_1.0.7 [43] withr_2.5.0 robustbase_0.95-1 [45] emmeans_1.8.5 checkmate_2.1.0 [47] vegan_2.6-4 treeio_1.22.0 [49] getopt_1.20.3 cluster_2.1.4 [51] gsl_2.1-8 ape_5.7-1 [53] dir.expiry_1.4.0 lazyeval_0.2.2 [55] crayon_1.5.2 labeling_0.4.2 [57] pkgconfig_2.0.3 nlme_3.1-162 [59] vipor_0.4.5 nnet_7.3-18 [61] rlang_1.1.0 spatial_7.3-16 [63] lifecycle_1.0.3 sandwich_3.0-2 [65] filelock_1.0.2 phyloseq_1.40.0 [67] rsvd_1.0.5 cellranger_1.1.0 [69] graph_1.74.0 Matrix_1.5-4 [71] lpsymphony_1.24.0 zoo_1.8-11 [73] Rhdf5lib_1.18.2 boot_1.3-28.1 [75] base64enc_0.1-3 beeswarm_0.4.0 [77] viridisLite_0.4.1 stabledist_0.7-1 [79] rootSolve_1.8.2.3 bitops_1.0-7 [81] rhdf5filters_1.8.0 blob_1.2.4 [83] DelayedMatrixStats_1.20.0 decontam_1.18.0 [85] DECIPHER_2.26.0 beachmat_2.14.0 [87] scales_1.2.1 memoise_2.0.1 [89] magrittr_2.0.3 plyr_1.8.8 [91] zlibbioc_1.44.0 compiler_4.2.1 [93] RColorBrewer_1.1-3 clue_0.3-64 [95] lme4_1.1-32 cli_3.6.1 [97] ade4_1.7-22 lmerTest_3.1-3 [99] pbapply_1.7-0 htmlTable_2.4.1 [101] Formula_1.2-5 mgcv_1.8-42 [103] tidyselect_1.2.0 stringi_1.7.12 [105] highr_0.10 yaml_2.3.7 [107] BiocSingular_1.14.0 ggrepel_0.9.3 [109] grid_4.2.1 sass_0.4.5 [111] tools_4.2.1 lmom_2.9 [113] timechange_0.2.0 parallel_4.2.1 [115] rstudioapi_0.14 logging_0.10-108 [117] foreign_0.8-84 statip_0.2.3 [119] optparse_1.7.3 gridExtra_2.3 [121] gld_2.6.6 farver_2.1.1 [123] stable_1.1.6 RcppZiggurat_0.1.6 [125] digest_0.6.31 BiocManager_1.30.20 [127] Rcpp_1.0.10 scuttle_1.8.4 [129] httr_1.4.5 Rdpack_2.4 [131] colorspace_2.1-0 XML_3.99-0.14 [133] modeest_2.4.0 splines_4.2.1 [135] yulab.utils_0.0.6 rmutil_1.1.10 [137] statmod_1.5.0 tidytree_0.4.2 [139] expm_0.999-7 scater_1.26.1 [141] multtest_2.52.0 Exact_3.2 [143] plotly_4.10.1 xtable_1.8-4 [145] gmp_0.7-1 jsonlite_1.8.4 [147] nloptr_2.0.3 CodeDepends_0.6.5 [149] timeDate_4022.108 Rfast_2.0.7 [151] R6_2.5.1 Hmisc_5.0-1 [153] pillar_1.9.0 htmltools_0.5.5 [155] glue_1.6.2 fastmap_1.1.1 [157] minqa_1.2.5 BiocParallel_1.32.6 [159] BiocNeighbors_1.16.0 class_7.3-21 [161] codetools_0.2-19 pcaPP_2.0-3 [163] mvtnorm_1.1-3 utf8_1.2.3 [165] lattice_0.21-8 bslib_0.4.2 [167] numDeriv_2016.8-1.1 ggbeeswarm_0.7.1 [169] DescTools_0.99.48 biglm_0.9-2.1 [171] rmarkdown_2.21 biomformat_1.24.0 [173] munsell_0.5.0 e1071_1.7-13 [175] rhdf5_2.40.0 GenomeInfoDbData_1.2.9 [177] iterators_1.0.14 reshape2_1.4.4 [179] gtable_0.3.3 rbibutils_2.2.13 Bibliography "],["machine_learning.html", "Chapter 12 Machine learning 12.1 Supervised machine learning 12.2 Unsupervised machine learning Session Info", " Chapter 12 Machine learning .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } Machine learning (ML) is a part of artificial intelligence. There are multiple definitions, but “machine” refers to computation and “learning” to improving performance based on the data by finding patterns from it. Machine learning includes wide variety of methods from simple statistical methods to more complex methods such as neural-networks. Machine learning can be divided into supervised and unsupervised machine learning. Supervised ML is used to predict outcome based on the data. Unsupervised ML is used, for example, to reduce dimensionality (e.g. PCA) and to find clusters from the data (e.g., k-means clustering). 12.1 Supervised machine learning “Supervised” means that the training data is introduced before. The training data contains labels (e.g., patient status), and the model is fitted based on the training data. After fitting, the model is utilized to predict labels of data whose labels are not known. library(mia) # Load experimental data data(peerj13075, package=&quot;mia&quot;) tse &lt;- peerj13075 Let’s first preprocess the data. # Agglomerate data tse &lt;- agglomerateByRank(tse, rank = &quot;order&quot;) # Apply CLR transform tse &lt;- transformCounts(tse, assay_name = &quot;counts&quot;, method = &quot;clr&quot;, MARGIN=&quot;samples&quot;, pseudocount=1) # Get assay assay &lt;- assay(tse, &quot;clr&quot;) # Transpose assay assay &lt;- t(assay) # Convert into data.frame df &lt;- as.data.frame(assay) # Add labels to assay labels &lt;- colData(tse)$Diet labels &lt;- as.factor(labels) df$diet &lt;- labels df[5, 5] ## [1] -0.4612 In the example below, we use mikropml package. We try to predict the diet type based on the data. if( !require(&quot;mikropml&quot;) ){ install.packages(&quot;mikropml&quot;) library(mikropml) } # Run random forest results &lt;- run_ml(df, &quot;rf&quot;, outcome_colname = &#39;diet&#39;, kfold = 2, cv_times = 5, training_frac = 0.8) # Print result confusionMatrix(data = results$trained_model$finalModel$predicted, reference = results$trained_model$finalModel$y) ## Confusion Matrix and Statistics ## ## Reference ## Prediction Mixed Veg ## Mixed 15 10 ## Veg 8 14 ## ## Accuracy : 0.617 ## 95% CI : (0.464, 0.755) ## No Information Rate : 0.511 ## P-Value [Acc &gt; NIR] : 0.0942 ## ## Kappa : 0.235 ## ## Mcnemar&#39;s Test P-Value : 0.8137 ## ## Sensitivity : 0.652 ## Specificity : 0.583 ## Pos Pred Value : 0.600 ## Neg Pred Value : 0.636 ## Prevalence : 0.489 ## Detection Rate : 0.319 ## Detection Prevalence : 0.532 ## Balanced Accuracy : 0.618 ## ## &#39;Positive&#39; Class : Mixed ## mikropml offers easier interface to caret package. However, we can also use it directly. Let’s use xgboost model which is another commonly used algorithm in bioinformatics. # Set seed for reproducibility set.seed(6358) # Specify train control train_control &lt;- trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, savePredictions = &quot;final&quot;, allowParallel = TRUE) # Specify hyperparameter tuning grid tune_grid &lt;- expand.grid(nrounds = c(50, 100, 200), max_depth = c(6, 8, 10), colsample_bytree = c(0.6, 0.8, 1), eta = c(0.1, 0.3), gamma = 0, min_child_weight = c(3, 4, 5), subsample = c(0.6, 0.8) ) # Train the model, use LOOCV to evaluate performance model &lt;- train(x = assay, y = labels, method = &quot;xgbTree&quot;, objective = &quot;binary:logistic&quot;, trControl = train_control, tuneGrid = tune_grid, metric = &quot;AUC&quot;, verbosity = 0 ) Let’s create ROC curve which is a commonly used method in binary classification. For unbalanced data, you might want to plot precision-recall curve. if( !require(MLeval) ){ install.packages(&quot;MLeval&quot;) library(MLeval) } # Calculate different evaluation metrics res &lt;- evalm(model, showplots = FALSE) # Use patchwork to plot ROC and precision-recall curve side-by-side library(patchwork) res$roc + res$proc + plot_layout(guides = &quot;collect&quot;) &amp; theme(legend.position = &#39;bottom&#39;) 12.2 Unsupervised machine learning “Unsupervised” means that the labels (e.g., patient status is not known), and patterns are learned based only the abundance table, for instance. Unsupervised ML is also known as a data mining where patterns are extracted from big datasets. For unsupervised machine learning, please refer to chapters that are listed below: Chapter 10 Chapter 8 Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] patchwork_1.1.2 MLeval_0.3 [3] caret_6.0-94 lattice_0.21-8 [5] ggplot2_3.4.2 mikropml_1.5.0 [7] mia_1.7.11 MultiAssayExperiment_1.24.0 [9] TreeSummarizedExperiment_2.1.4 Biostrings_2.66.0 [11] XVector_0.38.0 SingleCellExperiment_1.20.1 [13] SummarizedExperiment_1.28.0 Biobase_2.58.0 [15] GenomicRanges_1.50.2 GenomeInfoDb_1.34.9 [17] IRanges_2.32.0 S4Vectors_0.36.2 [19] BiocGenerics_0.44.0 MatrixGenerics_1.10.0 [21] matrixStats_0.63.0-9003 BiocStyle_2.24.0 [23] rebook_1.6.0 loaded via a namespace (and not attached): [1] plyr_1.8.8 lazyeval_0.2.2 [3] splines_4.2.1 BiocParallel_1.32.6 [5] listenv_0.9.0 scater_1.26.1 [7] digest_0.6.31 foreach_1.5.2 [9] yulab.utils_0.0.6 htmltools_0.5.5 [11] viridis_0.6.2 fansi_1.0.4 [13] magrittr_2.0.3 memoise_2.0.1 [15] MLmetrics_1.1.1 ScaledMatrix_1.6.0 [17] cluster_2.1.4 ROCR_1.0-11 [19] DECIPHER_2.26.0 recipes_1.0.5 [21] globals_0.16.2 gower_1.0.1 [23] hardhat_1.2.0 timechange_0.2.0 [25] colorspace_2.1-0 blob_1.2.4 [27] ggrepel_0.9.3 xfun_0.38 [29] dplyr_1.1.1 crayon_1.5.2 [31] RCurl_1.98-1.12 jsonlite_1.8.4 [33] graph_1.74.0 survival_3.5-5 [35] iterators_1.0.14 ape_5.7-1 [37] glue_1.6.2 gtable_0.3.3 [39] ipred_0.9-14 zlibbioc_1.44.0 [41] DelayedArray_0.24.0 kernlab_0.9-32 [43] BiocSingular_1.14.0 shape_1.4.6 [45] future.apply_1.10.0 scales_1.2.1 [47] DBI_1.1.3 Rcpp_1.0.10 [49] viridisLite_0.4.1 decontam_1.18.0 [51] tidytree_0.4.2 proxy_0.4-27 [53] bit_4.0.5 rsvd_1.0.5 [55] lava_1.7.2.1 prodlim_2019.11.13 [57] glmnet_4.1-7 dir.expiry_1.4.0 [59] farver_2.1.1 pkgconfig_2.0.3 [61] XML_3.99-0.14 scuttle_1.8.4 [63] nnet_7.3-18 CodeDepends_0.6.5 [65] sass_0.4.5 utf8_1.2.3 [67] labeling_0.4.2 tidyselect_1.2.0 [69] rlang_1.1.0 reshape2_1.4.4 [71] munsell_0.5.0 tools_4.2.1 [73] cachem_1.0.7 xgboost_1.7.3.1 [75] cli_3.6.1 DirichletMultinomial_1.40.0 [77] generics_0.1.3 RSQLite_2.3.1 [79] evaluate_0.20 stringr_1.5.0 [81] fastmap_1.1.1 yaml_2.3.7 [83] ModelMetrics_1.2.2.2 knitr_1.42 [85] bit64_4.0.5 randomForest_4.7-1.1 [87] purrr_1.0.1 future_1.32.0 [89] nlme_3.1-162 sparseMatrixStats_1.10.0 [91] compiler_4.2.1 beeswarm_0.4.0 [93] filelock_1.0.2 e1071_1.7-13 [95] treeio_1.22.0 tibble_3.2.1 [97] bslib_0.4.2 stringi_1.7.12 [99] highr_0.10 Matrix_1.5-4 [101] vegan_2.6-4 permute_0.9-7 [103] vctrs_0.6.1 pillar_1.9.0 [105] lifecycle_1.0.3 BiocManager_1.30.20 [107] jquerylib_0.1.4 BiocNeighbors_1.16.0 [109] data.table_1.14.8 bitops_1.0-7 [111] irlba_2.3.5.1 R6_2.5.1 [113] bookdown_0.33 gridExtra_2.3 [115] vipor_0.4.5 parallelly_1.35.0 [117] codetools_0.2-19 MASS_7.3-58.3 [119] withr_2.5.0 GenomeInfoDbData_1.2.9 [121] mgcv_1.8-42 parallel_4.2.1 [123] grid_4.2.1 rpart_4.1.19 [125] beachmat_2.14.0 timeDate_4022.108 [127] tidyr_1.3.0 class_7.3-21 [129] rmarkdown_2.21 DelayedMatrixStats_1.20.0 [131] pROC_1.18.0 lubridate_1.9.2 [133] ggbeeswarm_0.7.1 "],["multi-assay-analyses.html", "Chapter 13 Multi-assay analyses 13.1 Cross-correlation Analysis 13.2 Multi-Omics Factor Analysis Session Info", " Chapter 13 Multi-assay analyses .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } library(mia) Multi-omics means that we integrate data from multiple sources. For example, we can integrate microbial abundances in the gut with biomolecular profiling data from blood samples. This kind of integrative multi-omic approaches can support the analysis of microbiome dysbiosis and facilitate the discovery of novel biomarkers for health and disease. With cross-correlation analysis, we can analyze how strongly and how differently variables are associated between each other. For instance, we can analyze if higher presence of a specific taxon equals to higher levels of a biomolecule. The data containers that the miaverse utilizes are scalable and they can contain different types of data in a same container. Because of that, the miaverse is well-suitable for multi-assay microbiome data which incorporates different types of complementary data sources in a single reproducible workflow. Another experiment can be stored in altExp slot of SE data container or both experiments can be stored side-by-side in MAE data container (see the sections 2.2.5 and 2.2.6 to learn more about altExp and MAE objects, respectively). Different experiments are first imported into SE or TreeSE data container similarly to the case when only one experiment is present. After that different experiments are combined into the same data container. Result is one TreeSE object with alternative experiment in altExp slot, or MAE object with multiple experiment in its experiment slot. As an example data, we use data from following publication: Hintikka L et al. (2021) Xylo-oligosaccharides in prevention of hepatic steatosis and adipose tissue inflammation: associating taxonomic and metabolomic patterns in fecal microbiotas with biclustering (Hintikka et al. 2021). In this article, mice were fed with high-fat and low-fat diets with or without prebiotics. The purpose of this was to study if prebiotics would reduce the negative impacts of high-fat diet. This example data can be loaded from microbiomeDataSets. The data is already in MAE format. It includes three different experiments: microbial abundance data, metabolite concentrations, and data about different biomarkers. Help for importing data into SE object you can find from here. # Load the data data(HintikkaXOData, package = &quot;mia&quot;) mae &lt;- HintikkaXOData mae ## A MultiAssayExperiment object of 3 listed ## experiments with user-defined names and respective classes. ## Containing an ExperimentList class object of length 3: ## [1] microbiota: TreeSummarizedExperiment with 12706 rows and 40 columns ## [2] metabolites: TreeSummarizedExperiment with 38 rows and 40 columns ## [3] biomarkers: TreeSummarizedExperiment with 39 rows and 40 columns ## Functionality: ## experiments() - obtain the ExperimentList instance ## colData() - the primary/phenotype DataFrame ## sampleMap() - the sample coordination DataFrame ## `$`, `[`, `[[` - extract colData columns, subset, or experiment ## *Format() - convert into a long or wide DataFrame ## assays() - convert ExperimentList to a SimpleList of matrices ## exportClass() - save data to flat files if(!require(stringr)){ install.packages(&quot;stringr&quot;) library(stringr) } # Drop off those bacteria that do not include information in Phylum or lower levels mae[[1]] &lt;- mae[[1]][!is.na(rowData(mae[[1]])$Phylum), ] # Clean taxonomy data, so that names do not include additional characters rowData(mae[[1]]) &lt;- DataFrame(apply(rowData(mae[[1]]), 2, str_remove, pattern = &quot;._[0-9]__&quot;)) # Microbiome data mae[[1]] ## class: TreeSummarizedExperiment ## dim: 12613 40 ## metadata(0): ## assays(1): counts ## rownames(12613): GAYR01026362.62.2014 CVJT01000011.50.2173 ... ## JRJTB:03787:02429 JRJTB:03787:02478 ## rowData names(7): Phylum Class ... Species OTU ## colnames(40): C1 C2 ... C39 C40 ## colData names(0): ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: NULL ## rowTree: NULL ## colLinks: NULL ## colTree: NULL # Metabolite data mae[[2]] ## class: TreeSummarizedExperiment ## dim: 38 40 ## metadata(0): ## assays(1): nmr ## rownames(38): Butyrate Acetate ... Malonate 1,3-dihydroxyacetone ## rowData names(0): ## colnames(40): C1 C2 ... C39 C40 ## colData names(0): ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: NULL ## rowTree: NULL ## colLinks: NULL ## colTree: NULL # Biomarker data mae[[3]] ## class: TreeSummarizedExperiment ## dim: 39 40 ## metadata(0): ## assays(1): signals ## rownames(39): Triglycerides_liver CLSs_epi ... NPY_serum Glycogen_liver ## rowData names(0): ## colnames(40): C1 C2 ... C39 C40 ## colData names(0): ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## rowLinks: NULL ## rowTree: NULL ## colLinks: NULL ## colTree: NULL 13.1 Cross-correlation Analysis Next we can do the cross-correlation analysis. Here we analyse if individual bacteria genera correlates with concentrations of individual metabolites. This helps as to answer the question: “If this bacteria is present, is this metabolite’s concentration then low or high”? # Agglomerate microbiome data at family level mae[[1]] &lt;- agglomerateByPrevalence(mae[[1]], rank = &quot;Family&quot;) # Does log10 transform for microbiome data mae[[1]] &lt;- transformCounts(mae[[1]], method = &quot;log10&quot;, pseudocount = 1) # Give unique names so that we do not have problems when we are creating a plot rownames(mae[[1]]) &lt;- getTaxonomyLabels(mae[[1]]) # Cross correlates data sets correlations &lt;- testExperimentCrossCorrelation(mae, experiment1 = 1, experiment2 = 2, assay_name1 = &quot;log10&quot;, assay_name2 = &quot;nmr&quot;, method = &quot;spearman&quot;, p_adj_threshold = NULL, cor_threshold = NULL, # Remove when mia is fixed mode = &quot;matrix&quot;, sort = TRUE, show_warnings = FALSE) Creates the heatmap if( !require(&quot;ComplexHeatmap&quot;) ){ BiocManager::install(&quot;ComplexHeatmap&quot;) library(&quot;ComplexHeatmap&quot;) } # Create a heatmap and store it plot &lt;- Heatmap(correlations$cor, # Print values to cells cell_fun = function(j, i, x, y, width, height, fill) { # If the p-value is under threshold if( !is.na(correlations$p_adj[i, j]) &amp; correlations$p_adj[i, j] &lt; 0.05 ){ # Print &quot;X&quot; grid.text(sprintf(&quot;%s&quot;, &quot;X&quot;), x, y, gp = gpar(fontsize = 8, col = &quot;black&quot;)) } }, heatmap_legend_param = list(title = &quot;&quot;, legend_height = unit(5, &quot;cm&quot;)) ) plot 13.2 Multi-Omics Factor Analysis Multi-Omics Factor Analysis (Argelaguet 2018) (MOFA) is an unsupervised method for integrating multi-omic data sets in a downstream analysis. It could be seen as a generalization of principal component analysis. Yet, with the ability to infer a latent (low-dimensional) representation, shared among the mutliple (-omics) data sets in hand. We use the R MOFA2 package for the analysis, and install the corresponding dependencies. if(!require(MOFA2)){ BiocManager::install(&quot;MOFA2&quot;) } # For inter-operability between Python and R, and setting Python dependencies, # reticulate package is needed if(!require(reticulate)){ install.packages(&quot;reticulate&quot;) } # Let us assume that these have been installed already. #reticulate::install_miniconda(force = TRUE) #reticulate::use_miniconda(condaenv = &quot;env1&quot;, required = FALSE) #reticulate::py_install(packages = c(&quot;mofapy2&quot;), pip = TRUE, python_version=3.6) The mae object could be used straight to create the MOFA model. Yet, we transform our assays since the model assumes normality per default. Other distributions that can be used, include Poisson or Bernoulli. library(MOFA2) # For simplicity, classify all high-fat diets as high-fat, and all the low-fat # diets as low-fat diets colData(mae)$Diet &lt;- ifelse(colData(mae)$Diet == &quot;High-fat&quot; | colData(mae)$Diet == &quot;High-fat + XOS&quot;, &quot;High-fat&quot;, &quot;Low-fat&quot;) # Removing duplicates at the microbiome data # which are also in form e.g. &quot;Ambiguous&quot; and &quot;uncultured&quot; taxa mae[[1]] &lt;- mae[[1]][!duplicated(rownames(assay(mae[[1]]))), ] # Transforming microbiome data with rclr mae[[1]] &lt;- transformCounts(mae[[1]], method = &quot;relabundance&quot;) mae[[1]] &lt;- transformCounts(mae[[1]], assay_name = &quot;relabundance&quot;, method = &quot;rclr&quot;) # Transforming metabolomic data with log10 mae[[2]] &lt;- transformCounts(mae[[2]], assay_name = &quot;nmr&quot;, MARGIN = &quot;samples&quot;, method = &quot;log10&quot;) # Transforming biomarker data with z-transform mae[[3]] &lt;- transformCounts(mae[[3]], assay_name = &quot;signals&quot;, MARGIN = &quot;features&quot;, method = &quot;z&quot;, pseudocount = 1) # Removing assays no longer needed assay(mae[[1]], &quot;counts&quot;) &lt;- NULL assay(mae[[1]], &quot;log10&quot;) &lt;- NULL assay(mae[[2]], &quot;nmr&quot;) &lt;- NULL assay(mae[[3]], &quot;signals&quot;) &lt;- NULL # Building our mofa model model &lt;- create_mofa_from_MultiAssayExperiment(mae, groups = &quot;Diet&quot;, extract_metadata = TRUE) model ## Untrained MOFA model with the following characteristics: ## Number of views: 3 ## Views names: microbiota metabolites biomarkers ## Number of features (per view): 38 38 39 ## Number of groups: 2 ## Groups names: High-fat Low-fat ## Number of samples (per group): 20 20 ## Model options could be defined as follows: model_opts &lt;- get_default_model_options(model) model_opts$num_factors &lt;- 5 head(model_opts) ## $likelihoods ## microbiota metabolites biomarkers ## &quot;gaussian&quot; &quot;gaussian&quot; &quot;gaussian&quot; ## ## $num_factors ## [1] 5 ## ## $spikeslab_factors ## [1] FALSE ## ## $spikeslab_weights ## [1] TRUE ## ## $ard_factors ## [1] TRUE ## ## $ard_weights ## [1] TRUE Model’s training options are defined with the following: train_opts &lt;- get_default_training_options(model) head(train_opts) ## $maxiter ## [1] 1000 ## ## $convergence_mode ## [1] &quot;fast&quot; ## ## $drop_factor_threshold ## [1] -1 ## ## $verbose ## [1] FALSE ## ## $startELBO ## [1] 1 ## ## $freqELBO ## [1] 5 Preparing and training the model: model.prepared &lt;- prepare_mofa( object = model, model_options = model_opts ) # Some systems may require the specification `use_basilisk = TRUE` # so it has been added to the following code model.trained &lt;- run_mofa(model.prepared, use_basilisk = TRUE) Visualizing the variance explained: library(patchwork) library(ggplot2) wrap_plots( plot_variance_explained(model.trained, x=&quot;view&quot;, y=&quot;factor&quot;, plot_total = T), nrow = 2 ) + plot_annotation(title = &quot;Variance Explained per factor and assay&quot;, theme = theme(plot.title = element_text(hjust = 0.5))) The top weights for each assay using all 5 factors: plots &lt;- lapply(c(&quot;microbiota&quot;, &quot;metabolites&quot;,&quot;biomarkers&quot;), function(name) { plot_top_weights(model.trained, view = name, factors = &quot;all&quot;, nfeatures = 10) + labs(title = paste0(&quot;Top weights of the &quot;, name,&quot; assay&quot;)) }) wrap_plots(plots, nrow = 3) &amp; theme(text = element_text(size = 8)) More tutorials and examples of using the package are found at: link Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] grid stats4 stats graphics grDevices utils datasets [8] methods base other attached packages: [1] ggplot2_3.4.2 patchwork_1.1.2 [3] reticulate_1.28 MOFA2_1.6.0 [5] ComplexHeatmap_2.12.1 stringr_1.5.0 [7] mia_1.7.11 MultiAssayExperiment_1.24.0 [9] TreeSummarizedExperiment_2.1.4 Biostrings_2.66.0 [11] XVector_0.38.0 SingleCellExperiment_1.20.1 [13] SummarizedExperiment_1.28.0 Biobase_2.58.0 [15] GenomicRanges_1.50.2 GenomeInfoDb_1.34.9 [17] IRanges_2.32.0 S4Vectors_0.36.2 [19] BiocGenerics_0.44.0 MatrixGenerics_1.10.0 [21] matrixStats_0.63.0-9003 BiocStyle_2.24.0 [23] rebook_1.6.0 loaded via a namespace (and not attached): [1] circlize_0.4.15 corrplot_0.92 [3] BiocBaseUtils_1.0.0 plyr_1.8.8 [5] lazyeval_0.2.2 splines_4.2.1 [7] BiocParallel_1.32.6 scater_1.26.1 [9] digest_0.6.31 foreach_1.5.2 [11] yulab.utils_0.0.6 htmltools_0.5.5 [13] viridis_0.6.2 fansi_1.0.4 [15] magrittr_2.0.3 memoise_2.0.1 [17] ScaledMatrix_1.6.0 cluster_2.1.4 [19] doParallel_1.0.17 DECIPHER_2.26.0 [21] colorspace_2.1-0 blob_1.2.4 [23] ggrepel_0.9.3 xfun_0.38 [25] dplyr_1.1.1 crayon_1.5.2 [27] RCurl_1.98-1.12 jsonlite_1.8.4 [29] graph_1.74.0 iterators_1.0.14 [31] ape_5.7-1 glue_1.6.2 [33] gtable_0.3.3 zlibbioc_1.44.0 [35] GetoptLong_1.0.5 DelayedArray_0.24.0 [37] BiocSingular_1.14.0 Rhdf5lib_1.18.2 [39] shape_1.4.6 HDF5Array_1.24.2 [41] scales_1.2.1 pheatmap_1.0.12 [43] DBI_1.1.3 Rcpp_1.0.10 [45] viridisLite_0.4.1 decontam_1.18.0 [47] clue_0.3-64 tidytree_0.4.2 [49] bit_4.0.5 rsvd_1.0.5 [51] dir.expiry_1.4.0 RColorBrewer_1.1-3 [53] farver_2.1.1 pkgconfig_2.0.3 [55] XML_3.99-0.14 scuttle_1.8.4 [57] uwot_0.1.14 CodeDepends_0.6.5 [59] sass_0.4.5 here_1.0.1 [61] utf8_1.2.3 labeling_0.4.2 [63] tidyselect_1.2.0 rlang_1.1.0 [65] reshape2_1.4.4 munsell_0.5.0 [67] tools_4.2.1 cachem_1.0.7 [69] cli_3.6.1 DirichletMultinomial_1.40.0 [71] generics_0.1.3 RSQLite_2.3.1 [73] evaluate_0.20 fastmap_1.1.1 [75] yaml_2.3.7 knitr_1.42 [77] bit64_4.0.5 purrr_1.0.1 [79] nlme_3.1-162 sparseMatrixStats_1.10.0 [81] compiler_4.2.1 beeswarm_0.4.0 [83] filelock_1.0.2 png_0.1-8 [85] treeio_1.22.0 tibble_3.2.1 [87] bslib_0.4.2 stringi_1.7.12 [89] highr_0.10 basilisk.utils_1.8.0 [91] forcats_1.0.0 lattice_0.21-8 [93] Matrix_1.5-4 vegan_2.6-4 [95] permute_0.9-7 vctrs_0.6.1 [97] rhdf5filters_1.8.0 pillar_1.9.0 [99] lifecycle_1.0.3 BiocManager_1.30.20 [101] jquerylib_0.1.4 GlobalOptions_0.1.2 [103] BiocNeighbors_1.16.0 cowplot_1.1.1 [105] bitops_1.0-7 irlba_2.3.5.1 [107] R6_2.5.1 bookdown_0.33 [109] gridExtra_2.3 vipor_0.4.5 [111] codetools_0.2-19 MASS_7.3-58.3 [113] rhdf5_2.40.0 rprojroot_2.0.3 [115] rjson_0.2.21 withr_2.5.0 [117] GenomeInfoDbData_1.2.9 mgcv_1.8-42 [119] parallel_4.2.1 beachmat_2.14.0 [121] tidyr_1.3.0 basilisk_1.8.1 [123] rmarkdown_2.21 DelayedMatrixStats_1.20.0 [125] Rtsne_0.16 Cairo_1.6-0 [127] ggbeeswarm_0.7.1 Bibliography "],["viz-chapter.html", "Chapter 14 Visualization 14.1 Pre-analysis exploration 14.2 Diversity estimation 14.3 Statistical analysis Session Info", " Chapter 14 Visualization .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } Data visualization will inevitably shape interpretation and motivate the next steps of the analysis. A variety of visualization methods are available for microbiome analysis but the application requires careful attention to details. Knowledge on the available tools and their limitations plays an important role in selecting the most suitable methods to address a given question. This chapter introduces the reader to a number of visualization techniques found in this book, such as: barplots boxplots heatmaps ordination charts regression charts trees The toolkit which provides the essential plotting functionality includes the following packages: patchwork, cowplot, ggpubr and gridExtra: plot layout and multi-panel plotting miaViz: specific visualization tools for TreeSummaizedExperiment objects scater: specific visualization tools for SingleCellExperiment objects ggplot2, pheatmap, ggtree, sechm: composition heatmaps ANCOMBC, ALDEx2 and Maaslin2: visual differential abundance fido: tree-based methods for differential abundance plotly: animated and 3D plotting For systematic and extensive tutorials on the visual tools available in mia, readers can refer to the following material: microbiome tutorials 14.1 Pre-analysis exploration 14.1.1 Accessing row and column data SCE and TreeSE objects contain multiple layers of information in the form of rows, columns and meta data. The scater package supports in accessing, modifying and graphing the meta data related to features as well as samples. # list row meta data names(rowData(tse)) ## [1] &quot;Kingdom&quot; &quot;Phylum&quot; &quot;Class&quot; &quot;Order&quot; &quot;Family&quot; &quot;Genus&quot; &quot;Species&quot; # list column meta data names(colData(tse)) ## [1] &quot;X.SampleID&quot; &quot;Primer&quot; ## [3] &quot;Final_Barcode&quot; &quot;Barcode_truncated_plus_T&quot; ## [5] &quot;Barcode_full_length&quot; &quot;SampleType&quot; ## [7] &quot;Description&quot; Such meta data can be directly plotted with the functions plotRowData and plotColData. # obtain QC data tse &lt;- addPerCellQC(tse) tse &lt;- addPerFeatureQC(tse) # plot QC Mean against Species plotRowData(tse, &quot;mean&quot;, &quot;Species&quot;) + theme(axis.text.x = element_blank()) + labs(x = &quot;Species&quot;, y = &quot;QC Mean&quot;) # plot QC Sum against Sample ID, colour-labeled by Sample Type plotColData(tse, &quot;sum&quot;, &quot;X.SampleID&quot;, colour_by = &quot;SampleType&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + labs(x = &quot;Sample ID&quot;, y = &quot;QC Sum&quot;) Alternatively, they can be converted to a data.frame object and passed to ggplot. # store colData into a data frame coldata &lt;- as.data.frame(colData(tse)) # plot Number of Samples against Sampling Site ggplot(coldata, aes(x = SampleType)) + geom_bar(width = 0.5) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + labs(x = &quot;Sampling Site&quot;, y = &quot;Number of Samples&quot;) Further methods of application can be found in the chapters 5.3 and 7.1.1 and in a few external tutorials with open data. Additionally, rowData and colData allow manipulation and subsetting of large data sets into smaller units, as explained in chapter 4. 14.1.2 Viewing abundance and prevalence patterns Prior-to-analysis exploration may involve questions such as how microorganisms are distributed across samples (abundance) and what microorganisms are present in most of the samples (prevalence). The information on abundance and prevalence can be summarized into a jitter or density plot and a tree, respectively, with the miaViz package. Specifically, the functions plotAbundance, plotAbundanceDensity and plotRowTree are used, and examples on their usage are discussed throughout chapter 5. 14.2 Diversity estimation Alpha diversity is commonly measured as one of the diversity indices explained in chapter 7. Because the focus lies on each sample separately, one-dimensional plots, such as scatter, violin and box plots, are suitable. Beta diversity is generally evaluated as one of the dissimilarity indices reported in chapter 8. Unlike alpha diversity, samples are compared collectively to estimate the heterogeneity across them, therefore multidimensional plots, such as Shepard and ordination plots are suitable. alpha diversity beta diversity used metrics diversity indices dissimilarity indices metric dimensionality one-dimensional multidimensional suitable visualization scatter, violin, box plots Shepard, ordination plots In conclusion, visualization techniques for alpha and beta diversity significantly differ from one another. 14.2.1 Alpha diversity with scatter, violin and box plots The basic method to visualize the diversity values assigned to the different samples in a TSE object includes the following, where each data point represents one sample: # estimate shannon diversity index tse &lt;- mia::estimateDiversity(tse, assay_name = &quot;counts&quot;, index = &quot;shannon&quot;, name = &quot;shannon&quot;) # plot shannon diversity index, colour-labeled by Sample Type plotColData(tse, &quot;shannon&quot;, colour_by = &quot;SampleType&quot;) The several indices available for the evaluation of alpha diversity often return slightly divergent results, which can be visually compared with a multiple violin or box plot. For this purpose, plotColData (for violin plots) or ggplot (for box plots) are recursively applied to a number of diversity indices with the function lapply and the multi-panel plotting functionality of the patchwork package is then exploited. # estimate faith diversity index tse &lt;- mia::estimateFaith(tse, assay_name = &quot;counts&quot;) # store colData into a data frame coldata &lt;- as.data.frame(colData(tse)) # generate plots for shannon and faith indices # and store them into a list plots &lt;- lapply(c(&quot;shannon&quot;, &quot;faith&quot;), function(i) ggplot(coldata, aes_string(y = i)) + geom_boxplot() + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())) # combine plots with patchwork plots[[1]] + plots[[2]] The analogous output in the form of a violin plot is obtained in chapter 7.1.3. In addition, box plots that group samples according to certain information, such as origin, sex, age and health condition, can be labeled with p-values for significant differences with the package ggsignif package, as shown in chapter 7.1.2. 14.2.2 Beta diversity with Shepard and coordination plots The scater package offers the general function plotReducedDim. In its basic form, it takes a TSE object and the results on sample similarity stored in the same object, which can be evaluated with the following coordination methods: runMDS runNMDS runPCA runTSNE runUMAP Since these clustering techniques allow for multiple coordinates or components, coordination plots can also span multiple dimensions, which is explained in chapter 18. # perform NMDS coordination method tse &lt;- runNMDS(tse, FUN = vegan::vegdist, name = &quot;NMDS&quot;) ## initial value 47.733208 ## iter 5 value 33.853364 ## iter 10 value 32.891200 ## final value 32.823570 ## converged # plot results of a 2-component NMDS on tse, # coloured-scaled by shannon diversity index plotReducedDim(tse, &quot;NMDS&quot;, colour_by = &quot;shannon&quot;) Multiple combinations of coordinates or dimensions can also be integrated into a multi-panel arrangement. # perform MDS coordination method tse &lt;- runMDS(tse, FUN = vegan::vegdist, method = &quot;bray&quot;, name = &quot;MDS&quot;, exprs_values = &quot;counts&quot;, ncomponents = 3) # plot results of a 3-component MDS on tse, # coloured-scaled by faith diversity index plotReducedDim(tse, &quot;MDS&quot;, ncomponents = c(1:3), colour_by = &quot;faith&quot;) Similarly to iterating plotColData over indices of alpha diversity, lapply can be used in combination with patchwork to recursively apply plotReducedDim and visually compare results among various coordination methods. # generate plots for MDS and NMDS methods # and store them into a list plots &lt;- lapply(c(&quot;MDS&quot;, &quot;NMDS&quot;), plotReducedDim, object = tse, colour_by = &quot;shannon&quot;) # combine plots with patchwork plots[[1]] + plots[[2]] + plot_layout(guides = &quot;collect&quot;) For similar examples, readers are referred to chapter 8. Further material on the graphic capabilities of patchwork is available in its official package tutorial. 14.3 Statistical analysis 14.3.1 Heatmaps As described in chapter 9.1, bar plots and heatmaps can offer a useful insight into the composition of a community. Simple methods involve the functions plotAbundance and geom_tile in combination with scale_fill_gradientn from the packages miaViz and ggplot2, respectively. For instance, below the composition of multiple samples (x axis) is reported in terms of relative abundances (y axis) for the top 10 taxa at the Order rank. Bar plots and heatmaps with analogous information at the Phylum level are available in the aforementioned chapter. # agglomerate tse by Order tse_order &lt;- agglomerateByRank(tse, rank = &quot;Order&quot;, onRankOnly = TRUE) # transform counts into relative abundance tse_order &lt;- transformCounts(tse_order, assay_name = &quot;counts&quot;, method = &quot;relabundance&quot;) # get top orders top_taxa &lt;- getTopTaxa(tse_order, top = 10, assay_name = &quot;relabundance&quot;) # leave only names for top 10 orders and label the rest with &quot;Other&quot; order_renamed &lt;- lapply(rowData(tse_order)$Order, function(x){if (x %in% top_taxa) {x} else {&quot;Other&quot;}}) rowData(tse_order)$Order &lt;- as.character(order_renamed) # plot composition as a bar plot plotAbundance(tse_order, assay_name = &quot;relabundance&quot;, rank = &quot;Order&quot;, order_rank_by = &quot;abund&quot;, order_sample_by = &quot;Clostridiales&quot;) To add a sample annotation, you can combine plots that you get from the output of plotAbundance. # Create plots plots &lt;- plotAbundance(tse_order, assay_name = &quot;relabundance&quot;, rank = &quot;Order&quot;, order_rank_by = &quot;abund&quot;, order_sample_by = &quot;Clostridiales&quot;, features = &quot;SampleType&quot;) # Modify the legend of the first plot to be smaller plots[[1]] &lt;- plots[[1]] + theme(legend.key.size = unit(0.3, &#39;cm&#39;), legend.text = element_text(size = 6), legend.title = element_text(size = 8)) # Modify the legend of the second plot to be smaller plots[[2]] &lt;- plots[[2]] + theme(legend.key.height = unit(0.3, &#39;cm&#39;), legend.key.width = unit(0.3, &#39;cm&#39;), legend.text = element_text(size = 6), legend.title = element_text(size = 8), legend.direction = &quot;vertical&quot;) # Load required packages if( !require(&quot;ggpubr&quot;) ){ install.packages(&quot;ggpubr&quot;) library(&quot;ggpubr&quot;) } # Load required packages if( !require(&quot;patchwork&quot;) ){ install.packages(&quot;patchwork&quot;) library(&quot;patchwork&quot;) } # Combine legends legend &lt;- wrap_plots(as_ggplot(get_legend(plots[[1]])), as_ggplot(get_legend(plots[[2]])), ncol = 1) # Remove legends from the plots plots[[1]] &lt;- plots[[1]] + theme(legend.position = &quot;none&quot;) plots[[2]] &lt;- plots[[2]] + theme(legend.position = &quot;none&quot;, axis.title.x=element_blank()) # Combine plots plot &lt;- wrap_plots(plots[[2]], plots[[1]], ncol = 1, heights = c(2, 10)) # Combine the plot with the legend wrap_plots(plot, legend, nrow = 1, widths = c(2, 1)) For more sophisticated visualizations than those produced with plotAbundance and ggplot2, the packages pheatmap and sechm provide methods to include feature and sample clusters in a heatmap, along with further functionality. # Agglomerate tse by phylum tse_phylum &lt;- agglomerateByRank(tse, rank = &quot;Phylum&quot;, onRankOnly = TRUE) # Add clr-transformation on samples tse_phylum &lt;- transformCounts(tse_phylum, MARGIN = &quot;samples&quot;, method = &quot;clr&quot;, assay_name = &quot;counts&quot;, pseudocount=1) # Add z-transformation on features (taxa) tse_phylum &lt;- transformCounts(tse_phylum, assay_name = &quot;clr&quot;, MARGIN = &quot;features&quot;, method = &quot;z&quot;, name = &quot;clr_z&quot;) # Take subset: only samples from feces, skin, or tongue tse_phylum_subset &lt;- tse_phylum[ , tse_phylum$SampleType %in% c(&quot;Feces&quot;, &quot;Skin&quot;, &quot;Tongue&quot;) ] # Add clr-transformation tse_phylum_subset &lt;- transformCounts(tse_phylum_subset, method = &quot;clr&quot;, MARGIN=&quot;samples&quot;, assay_name = &quot;counts&quot;, pseudocount=1) # Does z-transformation tse_phylum_subset &lt;- transformCounts(tse_phylum_subset, assay_name = &quot;clr&quot;, MARGIN = &quot;features&quot;, method = &quot;z&quot;, name = &quot;clr_z&quot;) # Get n most abundant taxa, and subsets the data by them top_taxa &lt;- getTopTaxa(tse_phylum_subset, top = 20) tse_phylum_subset &lt;- tse_phylum_subset[top_taxa, ] # Gets the assay table mat &lt;- assay(tse_phylum_subset, &quot;clr_z&quot;) # Creates the heatmap pheatmap(mat) We can cluster both samples and features hierarchically and add them to the x and y axes of the heatmap, respectively. # Hierarchical clustering taxa_hclust &lt;- hclust(dist(mat), method = &quot;complete&quot;) # Creates a phylogenetic tree taxa_tree &lt;- as.phylo(taxa_hclust) # Plot taxa tree taxa_tree &lt;- ggtree(taxa_tree) + theme(plot.margin=margin(0,0,0,0)) # removes margins # Get order of taxa in plot taxa_ordered &lt;- get_taxa_name(taxa_tree) # to view the tree, run # taxa_tree Based on phylo tree, we decide to create three clusters. # Creates clusters taxa_clusters &lt;- cutree(tree = taxa_hclust, k = 3) # Converts into data frame taxa_clusters &lt;- data.frame(clusters = taxa_clusters) taxa_clusters$clusters &lt;- factor(taxa_clusters$clusters) # Order data so that it&#39;s same as in phylo tree taxa_clusters &lt;- taxa_clusters[taxa_ordered, , drop = FALSE] # Prints taxa and their clusters taxa_clusters ## clusters ## Chloroflexi 3 ## Actinobacteria 3 ## Crenarchaeota 3 ## Planctomycetes 3 ## Gemmatimonadetes 3 ## Thermi 3 ## Acidobacteria 3 ## Spirochaetes 2 ## Fusobacteria 2 ## SR1 2 ## Cyanobacteria 2 ## Proteobacteria 2 ## Synergistetes 2 ## Lentisphaerae 1 ## Bacteroidetes 1 ## Verrucomicrobia 1 ## Tenericutes 1 ## Firmicutes 1 ## Euryarchaeota 1 ## SAR406 1 The information on the clusters is then added to the feature meta data. # Adds information to rowData rowData(tse_phylum_subset)$clusters &lt;- taxa_clusters[order(match(rownames(taxa_clusters), rownames(tse_phylum_subset))), ] # Prints taxa and their clusters rowData(tse_phylum_subset)$clusters ## [1] 1 1 2 3 2 2 1 1 1 1 3 2 3 3 3 2 2 3 3 1 ## Levels: 1 2 3 Similarly, samples are hierarchically grouped into clusters, the most suitable number of clusters for the plot is selected and the new information is stored into the sample meta data. # Hierarchical clustering sample_hclust &lt;- hclust(dist(t(mat)), method = &quot;complete&quot;) # Creates a phylogenetic tree sample_tree &lt;- as.phylo(sample_hclust) # Plot sample tree sample_tree &lt;- ggtree(sample_tree) + layout_dendrogram() + theme(plot.margin=margin(0,0,0,0)) # removes margins # Get order of samples in plot samples_ordered &lt;- rev(get_taxa_name(sample_tree)) # to view the tree, run # sample_tree # Creates clusters sample_clusters &lt;- factor(cutree(tree = sample_hclust, k = 3)) # Converts into data frame sample_data &lt;- data.frame(clusters = sample_clusters) # Order data so that it&#39;s same as in phylo tree sample_data &lt;- sample_data[samples_ordered, , drop = FALSE] # Order data based on tse_phylum_subset &lt;- tse_phylum_subset[ , rownames(sample_data)] # Add sample type data sample_data$sample_types &lt;- unfactor(colData(tse_phylum_subset)$SampleType) sample_data ## clusters sample_types ## M11Plmr 2 Skin ## M31Plmr 2 Skin ## F21Plmr 2 Skin ## M31Fcsw 1 Feces ## M11Fcsw 1 Feces ## TS28 3 Feces ## TS29 3 Feces ## M31Tong 3 Tongue ## M11Tong 3 Tongue Now we can create heatmap with additional annotations. # Determines the scaling of colorss # Scale colors breaks &lt;- seq(-ceiling(max(abs(mat))), ceiling(max(abs(mat))), length.out = ifelse( max(abs(mat))&gt;5, 2*ceiling(max(abs(mat))), 10 ) ) colors &lt;- colorRampPalette(c(&quot;darkblue&quot;, &quot;blue&quot;, &quot;white&quot;, &quot;red&quot;, &quot;darkred&quot;))(length(breaks)-1) pheatmap(mat, annotation_row = taxa_clusters, annotation_col = sample_data, breaks = breaks, color = colors) The package sechm allows for further visual capabilities and flexibility. In this case, the clustering step is automatically performed by the plotting function and does not need to be executed in advance. # Stores annotation colros to metadata metadata(tse_phylum_subset)$anno_colors$SampleType &lt;- c(Feces = &quot;blue&quot;, Skin = &quot;red&quot;, Tongue = &quot;gray&quot;) # Create a plot sechm(tse_phylum_subset, features = rownames(tse_phylum_subset), assayName = &quot;clr&quot;, do.scale = TRUE, top_annotation = c(&quot;SampleType&quot;), gaps_at = &quot;SampleType&quot;, cluster_cols = TRUE, cluster_rows = TRUE) It is also possible to create an analogous heatmap by just using the ggplot2 package. However, a relatively long code is required to generate an identical output. # Add feature names to column as a factor taxa_clusters$Feature &lt;- rownames(taxa_clusters) taxa_clusters$Feature &lt;- factor(taxa_clusters$Feature, levels = taxa_clusters$Feature) # Create annotation plot row_annotation &lt;- ggplot(taxa_clusters) + geom_tile(aes(x = NA, y = Feature, fill = clusters)) + coord_equal(ratio = 1) + theme( axis.text.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), axis.title.y=element_blank(), axis.title.x = element_text(angle = 90, vjust = 0.5, hjust=1), plot.margin=margin(0,0,0,0), ) + labs(fill = &quot;Clusters&quot;, x = &quot;Clusters&quot;) # to view the notation, run # row_annotation # Add sample names to one of the columns sample_data$sample &lt;- factor(rownames(sample_data), levels = rownames(sample_data)) # Create annotation plot sample_types_annotation &lt;- ggplot(sample_data) + scale_y_discrete(position = &quot;right&quot;, expand = c(0,0)) + geom_tile(aes(y = NA, x = sample, fill = sample_types)) + coord_equal(ratio = 1) + theme( axis.text.x=element_blank(), axis.text.y=element_blank(), axis.title.x=element_blank(), axis.ticks.x=element_blank(), plot.margin=margin(0,0,0,0), axis.title.y.right = element_text(angle=0, vjust = 0.5) ) + labs(fill = &quot;Sample types&quot;, y = &quot;Sample types&quot;) # to view the notation, run # sample_types_annotation # Create annotation plot sample_clusters_annotation &lt;- ggplot(sample_data) + scale_y_discrete(position = &quot;right&quot;, expand = c(0,0)) + geom_tile(aes(y = NA, x = sample, fill = clusters)) + coord_equal(ratio = 1) + theme( axis.text.x=element_blank(), axis.text.y=element_blank(), axis.title.x=element_blank(), axis.ticks.x=element_blank(), plot.margin=margin(0,0,0,0), axis.title.y.right = element_text(angle=0, vjust = 0.5) ) + labs(fill = &quot;Clusters&quot;, y = &quot;Clusters&quot;) # to view the notation, run # sample_clusters_annotation # Order data based on clusters and sample types mat &lt;- mat[unfactor(taxa_clusters$Feature), unfactor(sample_data$sample)] # ggplot requires data in melted format melted_mat &lt;- melt(mat) colnames(melted_mat) &lt;- c(&quot;Taxa&quot;, &quot;Sample&quot;, &quot;clr_z&quot;) # Determines the scaling of colorss maxval &lt;- round(max(abs(melted_mat$clr_z))) limits &lt;- c(-maxval, maxval) breaks &lt;- seq(from = min(limits), to = max(limits), by = 0.5) colours &lt;- c(&quot;darkblue&quot;, &quot;blue&quot;, &quot;white&quot;, &quot;red&quot;, &quot;darkred&quot;) heatmap &lt;- ggplot(melted_mat) + geom_tile(aes(x = Sample, y = Taxa, fill = clr_z)) + theme( axis.title.y=element_blank(), axis.title.x=element_blank(), axis.ticks.y=element_blank(), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), plot.margin=margin(0,0,0,0), # removes margins legend.key.height= unit(1, &#39;cm&#39;) ) + scale_fill_gradientn(name = &quot;CLR + Z transform&quot;, breaks = breaks, limits = limits, colours = colours) + scale_y_discrete(position = &quot;right&quot;) heatmap library(patchwork) # Create layout design &lt;- c( patchwork::area(3, 1, 4, 1), patchwork::area(1, 2, 1, 3), patchwork::area(2, 2, 2, 3), patchwork::area(3, 2, 4, 3) ) # to view the design, run # plot(design) # Combine plots plot &lt;- row_annotation + sample_clusters_annotation + sample_types_annotation + heatmap + plot_layout(design = design, guides = &quot;collect&quot;, # Specify layout, collect legends # Adjust widths and heights to align plots. # When annotation plot is larger, it might not fit into # its column/row. # Then you need to make column/row larger. # Relative widths and heights of each column and row: # Currently, the width of the first column is 15 % and the height of # first two rows are 30 % the size of others # To get this work most of the times, you can adjust all sizes to be 1, i.e. equal, # but then the gaps between plots are larger. widths = c(0.15, 1, 1), heights = c(0.3, 0.3, 1, 1)) # plot # Create layout design &lt;- c( patchwork::area(4, 1, 5, 1), patchwork::area(4, 2, 5, 2), patchwork::area(1, 3, 1, 4), patchwork::area(2, 3, 2, 4), patchwork::area(3, 3, 3, 4), patchwork::area(4, 3, 5, 4) ) # to view the design, run # plot(design) # Combine plots plot &lt;- taxa_tree + row_annotation + sample_tree + sample_clusters_annotation + sample_types_annotation + heatmap + plot_layout(design = design, guides = &quot;collect&quot;, # Specify layout, collect legends widths = c(0.2, 0.15, 1, 1, 1), heights = c(0.1, 0.15, 0.15, 0.25, 1, 1)) plot Heatmaps find several other applications in biclustering and multi-assay analyses. These are discussed further in chapters 10 and 13. Session Info View session info R version 4.2.1 (2022-06-23) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] ggpubr_0.6.0 ggtree_3.4.4 [3] ape_5.7-1 pheatmap_1.0.12 [5] reshape2_1.4.4 sechm_1.4.1 [7] miaViz_1.7.5 ggraph_2.1.0 [9] patchwork_1.1.2 scater_1.26.1 [11] scuttle_1.8.4 mia_1.7.11 [13] MultiAssayExperiment_1.24.0 TreeSummarizedExperiment_2.1.4 [15] Biostrings_2.66.0 XVector_0.38.0 [17] SingleCellExperiment_1.20.1 SummarizedExperiment_1.28.0 [19] Biobase_2.58.0 GenomicRanges_1.50.2 [21] GenomeInfoDb_1.34.9 IRanges_2.32.0 [23] S4Vectors_0.36.2 BiocGenerics_0.44.0 [25] MatrixGenerics_1.10.0 matrixStats_0.63.0-9003 [27] ggplot2_3.4.2 BiocStyle_2.24.0 [29] rebook_1.6.0 loaded via a namespace (and not attached): [1] backports_1.4.1 circlize_0.4.15 [3] plyr_1.8.8 igraph_1.4.1 [5] lazyeval_0.2.2 splines_4.2.1 [7] BiocParallel_1.32.6 digest_0.6.31 [9] ca_0.71.1 foreach_1.5.2 [11] yulab.utils_0.0.6 htmltools_0.5.5 [13] viridis_0.6.2 fansi_1.0.4 [15] magrittr_2.0.3 memoise_2.0.1 [17] ScaledMatrix_1.6.0 cluster_2.1.4 [19] doParallel_1.0.17 DECIPHER_2.26.0 [21] ComplexHeatmap_2.12.1 graphlayouts_0.8.4 [23] colorspace_2.1-0 blob_1.2.4 [25] ggrepel_0.9.3 xfun_0.38 [27] dplyr_1.1.1 crayon_1.5.2 [29] RCurl_1.98-1.12 jsonlite_1.8.4 [31] graph_1.74.0 iterators_1.0.14 [33] glue_1.6.2 polyclip_1.10-4 [35] registry_0.5-1 gtable_0.3.3 [37] zlibbioc_1.44.0 V8_4.2.2 [39] GetoptLong_1.0.5 DelayedArray_0.24.0 [41] car_3.1-2 BiocSingular_1.14.0 [43] shape_1.4.6 abind_1.4-5 [45] scales_1.2.1 DBI_1.1.3 [47] rstatix_0.7.2 randomcoloR_1.1.0.1 [49] Rcpp_1.0.10 viridisLite_0.4.1 [51] clue_0.3-64 decontam_1.18.0 [53] gridGraphics_0.5-1 tidytree_0.4.2 [55] bit_4.0.5 rsvd_1.0.5 [57] RColorBrewer_1.1-3 dir.expiry_1.4.0 [59] pkgconfig_2.0.3 XML_3.99-0.14 [61] farver_2.1.1 CodeDepends_0.6.5 [63] sass_0.4.5 utf8_1.2.3 [65] labeling_0.4.2 ggplotify_0.1.0 [67] tidyselect_1.2.0 rlang_1.1.0 [69] munsell_0.5.0 tools_4.2.1 [71] cachem_1.0.7 cli_3.6.1 [73] DirichletMultinomial_1.40.0 generics_0.1.3 [75] RSQLite_2.3.1 broom_1.0.4 [77] evaluate_0.20 stringr_1.5.0 [79] fastmap_1.1.1 yaml_2.3.7 [81] knitr_1.42 bit64_4.0.5 [83] tidygraph_1.2.3 purrr_1.0.1 [85] nlme_3.1-162 sparseMatrixStats_1.10.0 [87] aplot_0.1.10 compiler_4.2.1 [89] curl_5.0.0 beeswarm_0.4.0 [91] filelock_1.0.2 png_0.1-8 [93] ggsignif_0.6.4 treeio_1.22.0 [95] tibble_3.2.1 tweenr_2.0.2 [97] bslib_0.4.2 stringi_1.7.12 [99] highr_0.10 lattice_0.21-8 [101] Matrix_1.5-4 vegan_2.6-4 [103] permute_0.9-7 vctrs_0.6.1 [105] pillar_1.9.0 lifecycle_1.0.3 [107] BiocManager_1.30.20 GlobalOptions_0.1.2 [109] jquerylib_0.1.4 BiocNeighbors_1.16.0 [111] cowplot_1.1.1 bitops_1.0-7 [113] irlba_2.3.5.1 seriation_1.4.2 [115] R6_2.5.1 TSP_1.2-3 [117] bookdown_0.33 gridExtra_2.3 [119] vipor_0.4.5 codetools_0.2-19 [121] MASS_7.3-58.3 rjson_0.2.21 [123] withr_2.5.0 GenomeInfoDbData_1.2.9 [125] mgcv_1.8-42 parallel_4.2.1 [127] grid_4.2.1 ggfun_0.0.9 [129] beachmat_2.14.0 tidyr_1.3.0 [131] rmarkdown_2.21 DelayedMatrixStats_1.20.0 [133] carData_3.0-5 Cairo_1.6-0 [135] Rtsne_0.16 ggnewscale_0.4.8 [137] ggforce_0.4.1 ggbeeswarm_0.7.1 "],["training.html", "Chapter 15 Training 15.1 Checklist 15.2 Recommended software 15.3 Study material 15.4 Support and resources 15.5 Code of Conduct", " Chapter 15 Training .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } The page provides practical information to support training and self-study. 15.1 Checklist Brief checklist to prepare for training (see below for links). Install the recommended software Watch the short online videos and familiarize with the other available material Join Gitter online chat for support 15.2 Recommended software We recommend to install and set up the relevant software packages on your own computer as this will support later use. The essential components to install include: R (the latest official release) RStudio; choose “Rstudio Desktop” to download the latest version. Check the Rstudio home page for more information. RStudio is optional. Install key R packages (Section 3 provides an installation script) After a successful installation you can consider trying out examples from Section 17 already before training. You can run the workflows by simply copy-pasting examples. You can then test further examples from this tutorial, modifying and applying these techniques to your own data. Plain source code for the individual chapters of this book are available via Github 15.3 Study material We encourage to familiarize with the material and test examples in advance. Short online videos on microbiome data science with R/Bioconductor Lecture slides Orchestrating Microbiome Analysis with R/Bioconductor (OMA) (this book) Exercises for self-study Resources and links to complementary external material 15.4 Support and resources For online support on installation and other matters, join us at Gitter. You are also welcome to connect through various channels with our broader developer and user community. 15.5 Code of Conduct We support the Bioconductor Code of Conduct. The community values an open approach to science that promotes sharing of ideas, code, software and expertise a kind and welcoming environment, diversity and inclusivity community contributions and collaboration "],["resources.html", "Chapter 16 Resources 16.1 Data containers 16.2 R programming resources 16.3 Reproducible reporting with Quarto", " Chapter 16 Resources 16.1 Data containers 16.1.1 Resources for TreeSummarizedExperiment SingleCellExperiment (Lun and Risso 2020) Online tutorial Project page SummarizedExperiment (Morgan et al. 2020) Online tutorial Project page TreeSummarizedExperiment (Huang 2020) Online tutorial Project page Publication: (Huang et al. 2021) 16.1.2 Other relevant containers DataFrame which behaves similarly to data.frame, yet efficient and fast when used with large datasets. DNAString along with DNAStringSet,RNAString and RNAStringSet efficient storage and handling of long biological sequences are offered within the Biostrings package (Pagès et al. 2020). GenomicRanges ((Lawrence et al. 2013)) offers an efficient representation and manipulation of genomic annotations and alignments, see e.g. GRanges and GRangesList at An Introduction to the GenomicRangesPackage. NGS Analysis Basics provides a walk-through of the above-mentioned features with detailed examples. 16.1.3 Alternative containers for microbiome data The phyloseq package and class became the first widely used data container for microbiome data science in R. Many methods for taxonomic profiling data are readily available for this class. We provide here a short description how phyloseq and *Experiment classes relate to each other. assays : This slot is similar to otu_table in phyloseq. In a SummarizedExperiment object multiple assays, raw counts, transformed counts can be stored. See also (Ramos et al. 2017) for storing data from multiple experiments such as RNASeq, Proteomics, etc. rowData : This slot is similar to tax_table in phyloseq to store taxonomic information. colData : This slot is similar to sample_data in phyloseq to store information related to samples. rowTree : This slot is similar to phy_tree in phyloseq to store phylogenetic tree. In this book, you will come across terms like FeatureIDs and SampleIDs. FeatureIDs : These are basically OTU/ASV ids which are row names in assays and rowData. SampleIDs : As the name suggests, these are sample ids which are column names in assays and row names in colData. FeatureIDs and SampleIDs are used but the technical terms rownames and colnames are encouraged to be used, since they relate to actual objects we work with. 16.1.4 Resources for phyloseq The (Tree)SummarizedExperiment objects can be converted into the alternative phyloseq format, for which further methods are available. List of R tools for microbiome analysis phyloseq (P. McMurdie and Holmes 2013) microbiome tutorial microbiomeutilities Bioconductor Workflow for Microbiome Data Analysis: from raw reads to community analyses (Ben J. Callahan et al. 2016). 16.2 R programming resources If you are new to R, you could try swirl for a kickstart to R programming. Further support resources are available through the Bioconductor project (Huber et al. 2015). R programming basics: Base R Basics of R programming: Base R R cheat sheets R visualization with ggplot2 R graphics cookbook Rmarkdown Rmarkdown tips (Xie, Dervieux, and Riederer 2020) RStudio RStudio cheat sheet 16.2.1 Bioconductor Classes S4 system S4 class system has brought several useful features to the object-oriented programming paradigm within R, and it is constantly deployed in R/Bioconductor packages (Huber et al. 2015).   Online Document: Hervé Pagès, A quick overview of the S4 class system. Laurent Gatto, A practical tutorial on S4 programming How S4 Methods Work (J. Chambers 2006)   Books: John M. Chambers. Software for Data Analysis: Programming with R. Springer, New York, 2008. ISBN-13 978-0387759357 (J. M. Chambers 2008) I Robert Gentleman. R Programming for Bioinformatics. Chapman &amp; Hall/CRC, New York, 2008. ISBN-13 978-1420063677 (R. Gentleman 2008) 16.3 Reproducible reporting with Quarto Reproducible reporting is the starting point for robust interactive data science. Perform the following tasks: If you are entirely new to literate programming and reproducible reporting, take this 10 minute tutorial to get introduced to the most important functions within Markdown. Create a Quarto template in RStudio, and render it into a document (markdown, PDF, docx or other format). In case you are new to Quarto, see this page. Examples are tips for closely related Rmarkdown are available in the online tutorial to reproducible reporting by Dr. C Titus Brown; see also Rmarkdown cheatsheet Figure sources: Original article - Huang R et al. (2021) TreeSummarizedExperiment: a S4 class for data with hierarchical structure. F1000Research 9:1246. (Huang et al. 2021) Reference Sequence slot extension - Lahti L et al. (2020) Upgrading the R/Bioconductor ecosystem for microbiome research F1000Research 9:1464 (slides). Bibliography "],["exercises.html", "Chapter 17 Exercises 17.1 Workflows 17.2 Data containers: TreeSE 17.3 Data manipulation 17.4 Abundance tables 17.5 Community diversity (alpha diversity) 17.6 Community composition (beta diversity) 17.7 Differential abundance 17.8 Visualization 17.9 Multiomics", " Chapter 17 Exercises Here you can find assignments on different topics. Tips for exercises: Add comments that explain what each line or lines of code do. This helps you and others to understand your code and find bugs. Furthermore, it is easier for you to reuse the code, and it promotes transparency. Interpret results by comparing them to literature. List main findings, so that results can easily be understood by others without advanced data analytics knowledge. Avoid hard-coding. Use variables which get values in the beginning of the pipeline. That way it is easier for you to modify parameters and reuse the code. 17.1 Workflows 17.1.1 Reproducible reporting with Quarto Create a new Quarto file Rstudio has ready-made templates for this Creating Quarto Documents Add a code chunk and name it. Render (or knit) the file into pdf or html format (Hint: Quarto Rstudio rendering) Import e.g., iris dataset, and add a dotplot with a title (Hint: geom_dotplot) Create another code chunk and plot. Adjust figure size and hide the code chunk from output report. Sizing chunk-options Add some text. Add R commands within the text (Hint: code-chunks) Update HTML file from the qmd file (Hint: Quarto Rstudio rendering) For tips on Quarto, see Quarto tutorial 17.2 Data containers: TreeSE 17.2.1 Constructing a data object Import data from CSV files to TreeSE (see shared data folder for example data sets). Import the data files in R Construct a TreeSE data object (see Ch. 2) Check that importing is done correctly. E.g., choose random samples and features, and check that their values equal between raw files and TreeSE. Useful functions: DataFrame, TreeSummarizedExperiment, matrix, rownames, colnames, SimpleList 17.2.2 Importing data You can also check the function reference in the mia package Import data from another format (functions: loadFromMetaphlan | loadFromMothur | loadFromQIIME2 | makeTreeSummarizedExperimentFromBiom | makeTreeSummarizedExperimentFromDADA2 …) Try out conversions between TreeSE and phyloseq data containers (makeTreeSummarizedExperimentFromPhyloseq; makephyloseqFromTreeSummarizedExperiment) 17.2.3 Basic summaries Load experimental dataset from mia (e.g. peerj13075 with the data() command; see OMA section 2.4 Demonstration Data; also see loading experimental data). Check a summary about the TreeSE object loaded (Hint: summary()) What are the dimensions? (How many samples there are, and how many taxa in each taxonomic rank?) (Hint: material in Section 2 may help) List sample and features names for the data (rownames, colnames..) 17.2.4 Taxonomic abundance table (assay) (Load example data) Fetch the list of available assays (Hints: assayNames) Fetch the counts assay, and show part of it. (Hint: assay-data) 17.2.5 Sample side information (Load example data) Fetch and show data about samples (Hint: colData) Get abundance data for all taxa for a specific sample (sample names: function colnames(tse)) example 17.2.6 Feature side information (Load example data) Fetch and show data on the (taxonomic) features of the analyzed samples (Hint: rowData) Get abundance data for all samples given a specific features (Hint: example) Optional: Create taxonomy tree based on the taxonomy mappings display its information: generate a taxonomic tree on the fly rowtree 17.2.7 Other elements Try to extract some of the other TreeSE elements. These are not always included: Experiment metadata Sample tree (colTree) Phylogenetic tree (rowTree) Feature sequences information (DNA sequence slot) 17.3 Data manipulation 17.3.1 Subsetting Subset the TreeSE object to specific samples Subset the TreeSE object to specific features Subset the TreeSE object to specific samples and features 17.3.2 Library sizes Calculate library sizes Subsample / rarify the counts (see: subsampleCounts) Useful functions: nrow, ncol, dim, summary, table, quantile, unique, addPerCellQC, agglomerateByRank 17.3.3 Prevalent and core taxonomic features Estimate prevalence for your chosen feature (row, taxonomic group) Identify all prevalent features and subset the data accordingly Report the thresholds and the dimensionality of the data before and after subsetting Visualize prevalence Useful functions: getPrevalence, getPrevalentTaxa, subsetByPrevalentTaxa 17.3.4 Data exploration Summarize sample metadata variables. (How many age groups, how they are distributed? 0%, 25%, 50%, 75%, and 100% quantiles of library size?) Create two histograms. Another shows the distribution of absolute counts, another shows how CLR transformed values are distributed. Visualize how relative abundances are distributed between taxa in samples. Useful functions: nrow, ncol, dim, summary, table, quantile, unique, transformCounts, ggplot, wilcox.test, agglomerateByRank, plotAbundance 17.3.5 Other functions Merge data objects (merge, mergeSEs) Melt the data for visualization purposes (meltAssay) 17.3.6 Transformations Transform abundance data with relative abundance and add a relative abundance assay (see data-transformation) Transform abundance data with clr transformation and add a new assay List the available assays by name Pick one of the assays and show a subset of it Subset the entire TreeSE data object, and check how this affects individual (transformed) assays Optional: If the data has phylogenetic tree, perform the phILR transformation 17.4 Abundance tables 17.4.1 Taxonomic levels List the available taxonomic ranks in the data Merge the data to Phylum level Report dimensionality before and after aggomeration Optional: Perform CLR transformation on the data; does this affect agglomeration? List full taxonomic information for some given taxa (Hint: mapTaxonomy) Useful functions: taxonomyRanks, agglomerateByRank, mergeRows 17.4.2 Alternative experiments (altExp) Create taxonomic abundance tables for all different levels (splitByRanks) Check the available alternative experiment (altExp) names before and after splitByRanks Pick specific “experiment” (taxonomic rank) from specific altExp; and a specific assay Optional: Split the data based on other features (splitOn) 17.5 Community diversity (alpha diversity) 17.5.1 Alpha diversity basics Calculate alpha diversity indices Test if data agglomeration to higher taxonomic ranks affects the indices Look for differences in alpha diversity between groups or correlation with a continuous variable Useful functions: estimateDiversity, colSums, agglomerateByRank, kruskal.test, cor 17.5.2 Alpha diversity extra Estimate Shannon diversity for the data Try also another diversity index and compare the results with a scatterplot Compare Shannon diversity between groups (boxplot) Is diversity significantly different between vegan and mixed diet? Calculate and visualize library size, compare with diversity Useful functions: estimateDiversity, colSums, geom_point, geom_boxplot 17.6 Community composition (beta diversity) 17.6.1 Beta diversity basics Visualize community variation with different methods (PCA, MDS, NMDS, etc.) with plotReduceDim and with different dissimilarities and transformations,plot also other than the first two axes. Use PERMANOVA to test differences in beta diversity. You can also try including continuous and/or categorical covariates If there are statistical differences in PERMANOVA, test PERMDISP2 (betadisper function) Do clustering Try RDA to test the variance explained by external variables 17.6.2 Beta diversity extra Install the latest development version of mia from GitHub. Load experimental dataset from mia. Create a PCoA with Aitchison dissimilarities. How much coordinate 1 explains the differences? How about coordinate 2? Create dbRDA with Bray-Curtis dissimilarities on relative abundances. Use PERMANOVA. Can differences between samples be explained with variables of sample meta data? Analyze diets’ association on beta diversity. Calculate dbRDA and then PERMANOVA. Visualize coefficients. Which taxa’s abundances differ the most between samples? Interpret your results. Is there association between community composition and location? What are those taxa that differ the most; find information from literature. Useful functions: runMDS, runRDA, anova.cca, transformCounts, agglomerateByRank, ggplot, plotReducedDim, vegan::adonis2 17.7 Differential abundance 17.7.1 Univariate analyses Get the abundances for an individual feature (taxonomic group / row) Visualize the abundances per group with boxplot / jitterplot Is the difference significant (Wilcoxon test)? Is the difference significant (linear model with covariates)? How do transformations affect the outcome (log10, clr..)? Get p-values for all features (taxa), for instance with a for loop Do multiple testing correction Compare the results from different tests with a scatterplot Useful functions: [], ggplot2::geom_boxplot, ggplot2::geom_jitter, wilcox.test, lm.test, transformCounts, p.adjust 17.7.2 Differential abundance analysis install the latest development version of mia from GitHub. Load experimental dataset from mia. Compare abundances of each taxa between groups. First, use Wilcoxon or Kruskall-Wallis test. Then use some other method dedicated to microbiome data. Summarize findings by plotting a taxa vs samples heatmap. Add column annotation that tells the group of each sample, and row annotation that tells whether the difference of certain taxa was statistically significant. Choose statistically significant taxa and visualize their abundances with boxplot &amp; jitterplot. Useful functions: wilcox.test, kruskal.test, ggplot, pheatmap, ComplexHeatMap::Heatmap, ancombc, aldex2, maaslin2, agglomerateByRank, transformCounts, subsetByPrevalentTaxa 17.8 Visualization 17.8.1 Multivariate ordination Load experimental dataset from mia. Create PCoA with Bray-Curtis dissimilarities Create PCA with Aitchison dissimilarities Visualize and compare both Test other transformations, dissimilarities, and ordination methods Useful functions: runMDS, runNMDS, transformCounts, ggplot, plotReducedDim 17.8.2 Heatmap visualization Load experimental dataset from mia. Visualize abundances with heatmap Visualize abundances with heatmap after CLR + Z transformation See the OMA book for examples. 17.9 Multiomics 17.9.1 MultiAssayExperiment (MAE) data container Create TreeSE data containers from individual CSV files. Combine TreeSE into MAE. Check that each individual experiment of MAE equals corresponding TreeSE. Take a subset of MAE (e.g., 10 first samples), and observe the subsetted MAE. Useful functions: DataFrame, TreeSummarizedExperiment, matrix, rownames, colnames, MultiAssayExperiment, ExperimentList, SimpleList 17.9.2 Multi-omic data exploration Load experimental dataset from microbiomeDataSets (e.g., HintikkaXOData). Analyze correlations between experiments. (Taxa vs lipids, Taxa vs biomarkers, Lipids vs biomarkers) Agglomerate taxa data. Apply CLR to taxa data, apply log10 to lipids and biomarkers. Perform cross-correlation analyses and visualize results with heatmaps. (Use Spearman coefficients) Is there significant correlations? Interpret your results. Useful functions: pheatmap, ComplexHeatMap::Heatmap, ggplot, transformCounts, testExperimentCrossAssociation "],["extras.html", "Chapter 18 Extra material 18.1 PERMANOVA comparison 18.2 Bayesian Multinomial Logistic-Normal Models 18.3 Interactive 3D Plots", " Chapter 18 Extra material .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } 18.1 PERMANOVA comparison Here we present two possible uses of the adonis2 function which performs PERMANOVA. The optional argument by has an effect on the statistical outcome, so its two options are compared here. # import necessary packages if (!require(gtools)){ install.packages(&quot;gtools&quot;) } if (!require(purrr)){ install.packages(&quot;purrr&quot;) } library(vegan) library(gtools) library(purrr) Let us load the enterotype TSE object and run PERMANOVA for different orders of three variables with two different approaches: by = \"margin\" or by = \"terms\". # load and prepare data library(mia) data(&quot;enterotype&quot;, package=&quot;mia&quot;) enterotype &lt;- transformCounts(enterotype, method = &quot;relabundance&quot;) # drop samples missing meta data enterotype &lt;- enterotype[ , !rowSums(is.na(colData(enterotype)[, c(&quot;Nationality&quot;, &quot;Gender&quot;, &quot;ClinicalStatus&quot;)]) &gt; 0)] # define variables and list all possible combinations vars &lt;- c(&quot;Nationality&quot;, &quot;Gender&quot;, &quot;ClinicalStatus&quot;) var_perm &lt;- permutations(n = 3, r = 3, vars) formulas &lt;- apply(var_perm, 1, function(row) purrr::reduce(row, function(x, y) paste(x, &quot;+&quot;, y))) # create empty data.frames for further storing p-values terms_df &lt;- data.frame(&quot;Formula&quot; = formulas, &quot;ClinicalStatus&quot; = rep(0, 6), &quot;Gender&quot; = rep(0, 6), &quot;Nationality&quot; = rep(0, 6)) margin_df &lt;- data.frame(&quot;Formula&quot; = formulas, &quot;ClinicalStatus&quot; = rep(0, 6), &quot;Gender&quot; = rep(0, 6), &quot;Nationality&quot; = rep(0, 6)) for (row_idx in 1:nrow(var_perm)) { # generate temporary formula (i.e. &quot;assay ~ ClinicalStatus + Nationality + Gender&quot;) tmp_formula &lt;- purrr::reduce(var_perm[row_idx, ], function(x, y) paste(x, &quot;+&quot;, y)) tmp_formula &lt;- as.formula(paste0(&#39;t(assay(enterotype, &quot;relabundance&quot;)) ~ &#39;, tmp_formula)) # multiple variables, default: by = &quot;terms&quot; set.seed(75) with_terms &lt;- adonis2(tmp_formula, by = &quot;terms&quot;, data = colData(enterotype), permutations = 99) # multiple variables, by = &quot;margin&quot; set.seed(75) with_margin &lt;- adonis2(tmp_formula, by = &quot;margin&quot;, data = colData(enterotype), permutations = 99) # extract p-values terms_p &lt;- with_terms[[&quot;Pr(&gt;F)&quot;]] terms_p &lt;- terms_p[!is.na(terms_p)] margin_p &lt;- with_margin[[&quot;Pr(&gt;F)&quot;]] margin_p &lt;- margin_p[!is.na(margin_p)] # store p-values into data.frames for (col_idx in 1:ncol(var_perm)) { terms_df[var_perm[row_idx, col_idx]][row_idx, ] &lt;- terms_p[col_idx] margin_df[var_perm[row_idx, col_idx]][row_idx, ] &lt;- margin_p[col_idx] } } The following table displays the p-values for the three variables ClinicalStatus, Gender and Nationality obtained by PERMANOVA with adonis2. Note that the p-values remain identical when by = \"margin\", but change with the order of the variables in the formula when by = \"terms\" (default). df &lt;- terms_df %&gt;% dplyr::inner_join(margin_df, by = &quot;Formula&quot;, suffix = c(&quot; (terms)&quot;, &quot; (margin)&quot;)) knitr::kable(df) Formula ClinicalStatus (terms) Gender (terms) Nationality (terms) ClinicalStatus (margin) Gender (margin) Nationality (margin) ClinicalStatus + Gender + Nationality 0.20 0.70 0.04 0.53 0.29 0.04 ClinicalStatus + Nationality + Gender 0.20 0.29 0.05 0.53 0.29 0.04 Gender + ClinicalStatus + Nationality 0.17 0.79 0.04 0.53 0.29 0.04 Gender + Nationality + ClinicalStatus 0.53 0.79 0.03 0.53 0.29 0.04 Nationality + ClinicalStatus + Gender 0.61 0.29 0.04 0.53 0.29 0.04 Nationality + Gender + ClinicalStatus 0.53 0.39 0.04 0.53 0.29 0.04 18.2 Bayesian Multinomial Logistic-Normal Models Analysis using such model could be performed with the function pibble from the fido package, wihch is in form of a Multinomial Logistic-Normal Linear Regression model; see vignette of package. The following presents such an exemplary analysis based on the data of Sprockett et al. (2020) available through microbiomeDataSets package. if (!require(fido)){ # installing the fido package devtools::install_github(&quot;jsilve24/fido&quot;) } Loading the libraries and importing data: library(fido) library(microbiomeDataSets) tse &lt;- SprockettTHData() We pick three covariates (“Sex”,“Age_Years”,“Delivery_Mode”) during this analysis as an example, and beforehand we check for missing data: library(mia) cov_names &lt;- c(&quot;Sex&quot;,&quot;Age_Years&quot;,&quot;Delivery_Mode&quot;) na_counts &lt;- apply(is.na(colData(tse)[,cov_names]), 2, sum) na_summary&lt;-as.data.frame(na_counts,row.names=cov_names) We drop missing values of the covariates: tse &lt;- tse[ , !is.na(colData(tse)$Delivery_Mode) ] tse &lt;- tse[ , !is.na(colData(tse)$Age_Years) ] We agglomerate microbiome data to Phylum: tse_phylum &lt;- agglomerateByRank(tse, &quot;Phylum&quot;) We extract the counts assay and covariate data to build the model matrix: Y &lt;- assays(tse_phylum)$counts # design matrix # taking 3 covariates sample_data&lt;-as.data.frame(colData(tse_phylum)[,cov_names]) X &lt;- t(model.matrix(~Sex+Age_Years+Delivery_Mode,data=sample_data)) Building the parameters for the pibble call to build the model; see more at vignette: n_taxa&lt;-nrow(Y) upsilon &lt;- n_taxa+3 Omega &lt;- diag(n_taxa) G &lt;- cbind(diag(n_taxa-1), -1) Xi &lt;- (upsilon-n_taxa)*G%*%Omega%*%t(G) Theta &lt;- matrix(0, n_taxa-1, nrow(X)) Gamma &lt;- diag(nrow(X)) Automatically initializing the priors and visualizing their distributions: priors &lt;- pibble(NULL, X, upsilon, Theta, Gamma, Xi) names_covariates(priors) &lt;- rownames(X) plot(priors, pars=&quot;Lambda&quot;) + ggplot2::xlim(c(-5, 5)) Estimating the posterior by including our response data Y. Note: Some computational failures could occur (see discussion) the arguments multDirichletBoot calcGradHess could be passed in such case. priors$Y &lt;- Y posterior &lt;- refit(priors, optim_method=&quot;adam&quot;, multDirichletBoot=0.5) #calcGradHess=FALSE Printing a summary about the posterior: ppc_summary(posterior) ## Proportions of Observations within 95% Credible Interval: 0.9978 Plotting the summary of the posterior distributions of the regression parameters: names_categories(posterior) &lt;- rownames(Y) plot(posterior,par=&quot;Lambda&quot;,focus.cov=rownames(X)[2:4]) Taking a closer look at “Sex” and “Delivery_Mode”: plot(posterior, par=&quot;Lambda&quot;, focus.cov = rownames(X)[c(2,4)]) 18.3 Interactive 3D Plots # Installing required packages if (!require(rgl)){ BiocManager::install(&quot;rgl&quot;) } if (!require(plotly)){ BiocManager::install(&quot;plotly&quot;) } library(knitr) library(rgl) knitr::knit_hooks$set(webgl = hook_webgl) In this section we make a 3D version of the earlier Visualizing the most dominant genus on PCoA (see 5), with the help of the plotly (Sievert 2020). # Installing the package if (!require(curatedMetagenomicData)){ BiocManager::install(&quot;curatedMetagenomicData&quot;) } # Importing necessary libraries library(curatedMetagenomicData) library(dplyr) library(DT) library(mia) library(scater) # Querying the data tse &lt;- sampleMetadata %&gt;% filter(age &gt;= 18) %&gt;% # taking only data of age 18 or above filter(!is.na(alcohol)) %&gt;% # excluding missing values returnSamples(&quot;relative_abundance&quot;) tse_Genus &lt;- agglomerateByRank(tse, rank=&quot;genus&quot;) tse_Genus &lt;- addPerSampleDominantTaxa(tse_Genus,assay_name=&quot;relative_abundance&quot;, name = &quot;dominant_taxa&quot;) # Performing PCoA with Bray-Curtis dissimilarity. tse_Genus &lt;- runMDS(tse_Genus, FUN = vegan::vegdist, ncomponents = 3, name = &quot;PCoA_BC&quot;, exprs_values = &quot;relative_abundance&quot;) # Getting the 6 top taxa top_taxa &lt;- getTopTaxa(tse_Genus,top = 6, assay_name = &quot;relative_abundance&quot;) # Naming all the rest of non top-taxa as &quot;Other&quot; most_abundant &lt;- lapply(colData(tse_Genus)$dominant_taxa, function(x){if (x %in% top_taxa) {x} else {&quot;Other&quot;}}) # Storing the previous results as a new column within colData colData(tse_Genus)$most_abundant &lt;- as.character(most_abundant) # Calculating percentage of the most abundant most_abundant_freq &lt;- table(as.character(most_abundant)) most_abundant_percent &lt;- round(most_abundant_freq/sum(most_abundant_freq)*100, 1) # Retrieving the explained variance e &lt;- attr(reducedDim(tse_Genus, &quot;PCoA_BC&quot;), &quot;eig&quot;); var_explained &lt;- e/sum(e[e&gt;0])*100 Interactive 3D visualization of the most dominant genus on PCoA. Note that labels at legend can be used to visualize one or more Genus separately (double click to isolate one from the others, or toggle to select multiple ones). library(plotly) # 3D Visualization reduced_data &lt;- as.data.frame(reducedDim(tse_Genus)[,]) names(reduced_data) &lt;- c(&quot;PC1&quot;,&quot;PC2&quot;,&quot;PC3&quot;) plot_ly(reduced_data, x=~PC1,y=~PC2,z=~PC3)%&gt;% add_markers(color=sapply(strsplit(colData(tse_Genus)$most_abundant, &quot;_&quot;), tail, 1), size=5, colors=c(&quot;black&quot;, &quot;blue&quot;, &quot;lightblue&quot;, &quot;darkgray&quot;, &quot;magenta&quot;, &quot;darkgreen&quot;, &quot;red&quot;)) %&gt;% layout(scene=list(xaxis=list(title = paste(&quot;PC1 (&quot;,round(var_explained[1],1),&quot;%)&quot;)), yaxis=list(title = paste(&quot;PC2 (&quot;,round(var_explained[2],1),&quot;%)&quot;)), zaxis=list(title = paste(&quot;PC3 (&quot;,round(var_explained[3],1),&quot;%)&quot;)))) Bibliography "],["acknowledgments.html", "Chapter 19 Acknowledgments", " Chapter 19 Acknowledgments .rebook-collapse { background-color: #eee; color: #444; cursor: pointer; padding: 18px; width: 100%; border: none; text-align: left; outline: none; font-size: 15px; } .rebook-content { padding: 0 18px; display: none; overflow: hidden; background-color: #f1f1f1; } This work would not have been possible without the countless contributions and interactions with other researchers, developers, and users. We express our gratitude to the entire Bioconductor community for developing this high-quality open research software repository for life science analytics, continuously pushing the limits in emerging fields Huber et al. (2015). The developers and contributors of this online tutorial are listed in Chapter ??. The base ecosystem of data containers, packages, and tutorials was set up as a collaborative effort by Tuomas Borman, Henrik Eckermann, Chouaib Benchraka, Chandler Ross, Shigdel Rajesh, Yağmur Şimşek, Giulio Benedetti, Sudarshan Shetty, Felix Ernst, and Leo Lahti. The work has been supported by the COST Action network on Statistical and Machine Learning Techniques for Human Microbiome Studies (ML4microbiome) (Moreno-Indias et al. 2021). The framework is based on the TreeSummarizedExperiment data container created by Ruizhu Huang and others (Huang 2020), and on the MultiAssayExperiment by Marcel Ramos et al. (Ramos et al. 2017). The idea of using these containers as a basis for microbiome data science was initially advanced by the groundwork of Domenick Braccia, Héctor Corrada Bravo and others, and subsequently brought together with other microbiome data science developers (Shetty and Lahti 2019). Ample demonstration data resources have been made available as the curatedMetagenomicData project by Edoardo Pasolli, Lucas Schiffer, Levi Waldron and others (Pasolli et al. 2017) adding important support. A number of other contributors have advanced the ecosystem further, and will be acknowledged in the individual packages, pull requests, issues, and other work. The work has drawn inspiration from many sources, most notably from the work on phyloseq by Paul McMurdie and Susan Holmes (P. McMurdie and Holmes 2013) who pioneered the work on rigorous and reproducible microbiome data science ecosystems in R/Bioconductor. The phyloseq framework continues to provide a vast array of complementary packages and methods for microbiome studies, and we aim to support full interoperability. The open source books by Susan Holmes and Wolfgang Huber, Modern Statistics for Modern Biology (Holmes and Huber 2019) and by Garret Grolemund and Hadley Wickham, the R for Data Science (Grolemund and Wickham 2017), and Richard McElreath’s Statistical Rethinking and the associated online resources by Solomon Kurz (McElreath 2020) are key references that advanced reproducible data science training and dissemination. The Orchestrating Single-Cell Analysis with Bioconductor, or OSCA book by Robert Amezquita, Aaron Lun, Stephanie Hicks, and Raphael Gottardo (R. A. Amezquita et al. 2020) has implemented closely related work on the SummarizedExperiment data container and its derivatives in the field of single cell sequencing studies. Many approaches used in this book have been derived from the OSCA framework, with various adjustments and extensions dedicated to microbiome data science. Bibliography "],["bibliography.html", "Bibliography", " Bibliography "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
